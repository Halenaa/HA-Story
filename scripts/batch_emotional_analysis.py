"""
æ‰¹é‡æƒ…æ„Ÿå¼§çº¿åˆ†æè„šæœ¬
éå†regression_testæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å®éªŒç»“æœï¼Œè¿è¡Œemotional_arc_analyzer.py
å°†ç»“æœæ±‡æ€»åˆ°CSVè¡¨æ ¼ä¸­
"""

import os
import json
import pandas as pd
import re
from datetime import datetime
import sys

# æ·»åŠ è·¯å¾„ä»¥ä¾¿å¯¼å…¥åˆ†ææ¨¡å—
sys.path.append('.')
from src.analysis.emotional_arc_analyzer import analyze_story_dual_method

def parse_folder_name(folder_name):
    """
    è§£ææ–‡ä»¶å¤¹åç§°ï¼Œæå–å®éªŒå‚æ•°
    ä¾‹ï¼šthelittleredridinghood_sciencefictionrewrite_linear_T0.7_s2
    """
    parts = folder_name.split('_')
    
    # æŸ¥æ‰¾æ¨¡å¼æ ‡è¯†
    mode_part = None
    temp_part = None
    seed_part = None
    
    for part in parts:
        if part in ['linear', 'nonlinear']:
            mode_part = part
        elif part.startswith('T') and '.' in part:
            temp_part = part
        elif part.startswith('s') and part[1:].isdigit():
            seed_part = part
    
    # æ„å»ºç»“æœ
    result = {
        'folder_name': folder_name,
        'topic': 'Little Red Riding Hood',  # ä»æ–‡ä»¶å¤¹åæ¨æ–­
        'style': 'Science Fiction Rewrite',  # ä»æ–‡ä»¶å¤¹åæ¨æ–­
        'mode': mode_part if mode_part else 'unknown',
        'temperature': float(temp_part[1:]) if temp_part else 0.0,
        'seed': int(seed_part[1:]) if seed_part else 0
    }
    
    return result

def run_batch_analysis(base_dir="/Users/haha/Story/data/output/regression_test"):
    """
    æ‰¹é‡è¿è¡Œæƒ…æ„Ÿå¼§çº¿åˆ†æ
    """
    print("ğŸš€ å¼€å§‹æ‰¹é‡æƒ…æ„Ÿå¼§çº¿åˆ†æ...")
    print(f"æ‰«æç›®å½•: {base_dir}")
    
    # æ‰«ææ‰€æœ‰æ–‡ä»¶å¤¹
    if not os.path.exists(base_dir):
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {base_dir}")
        return None
    
    folders = [f for f in os.listdir(base_dir) 
              if os.path.isdir(os.path.join(base_dir, f)) and not f.startswith('.')]
    
    print(f"ğŸ“ å‘ç° {len(folders)} ä¸ªå®éªŒæ–‡ä»¶å¤¹")
    
    # å­˜å‚¨æ‰€æœ‰ç»“æœ
    all_results = []
    success_count = 0
    failed_files = []
    
    # éå†æ¯ä¸ªæ–‡ä»¶å¤¹
    for i, folder in enumerate(folders, 1):
        print(f"\n{'='*60}")
        print(f"[{i}/{len(folders)}] å¤„ç†æ–‡ä»¶å¤¹: {folder}")
        
        # è§£ææ–‡ä»¶å¤¹å‚æ•°
        folder_params = parse_folder_name(folder)
        print(f"å‚æ•°: {folder_params['mode']} | T{folder_params['temperature']} | s{folder_params['seed']}")
        
        # æ„å»ºMDæ–‡ä»¶è·¯å¾„
        md_file_path = os.path.join(base_dir, folder, "enhanced_story_dialogue_updated.md")
        
        if not os.path.exists(md_file_path):
            print(f"âš ï¸ MDæ–‡ä»¶ä¸å­˜åœ¨: {md_file_path}")
            failed_files.append({
                'folder': folder,
                'reason': 'MDæ–‡ä»¶ä¸å­˜åœ¨',
                'path': md_file_path
            })
            continue
        
        try:
            # è¿è¡Œæƒ…æ„Ÿåˆ†æ
            print("ğŸ”„ è¿è¡Œæƒ…æ„Ÿå¼§çº¿åˆ†æ...")
            result = analyze_story_dual_method(
                md_file_path,
                output_dir='output/batch_results/'
            )
            
            if 'error' in result:
                print(f"âŒ åˆ†æå¤±è´¥: {result['error']}")
                failed_files.append({
                    'folder': folder,
                    'reason': result['error'],
                    'path': md_file_path
                })
                continue
            
            # æå–å…³é”®æŒ‡æ ‡
            primary_analysis = result['primary_analysis']
            validation_analysis = result['validation_analysis']
            correlation_analysis = result['correlation_analysis']
            
            # æ„å»ºç»“æœè®°å½•
            result_record = {
                # å®éªŒå‚æ•°
                'folder_name': folder,
                'topic': folder_params['topic'],
                'style': folder_params['style'],
                'mode': folder_params['mode'],
                'temperature': folder_params['temperature'],
                'seed': folder_params['seed'],
                
                # åŸºæœ¬ä¿¡æ¯
                'total_chapters': result['metadata']['total_chapters'],
                'analysis_timestamp': result['metadata']['analysis_timestamp'],
                
                # RoBERTaåˆ†æç»“æœ
                'roberta_classification': primary_analysis['reagan_classification']['best_match'],
                'roberta_confidence': primary_analysis['reagan_classification']['confidence'],
                'roberta_category': primary_analysis['reagan_classification']['reagan_category'],
                
                # LabMTåˆ†æç»“æœ
                'labmt_classification': validation_analysis['reagan_classification']['best_match'],
                'labmt_confidence': validation_analysis['reagan_classification']['confidence'],
                'labmt_category': validation_analysis['reagan_classification']['reagan_category'],
                
                # ç›¸å…³æ€§åˆ†æ
                'correlation_coefficient': correlation_analysis['pearson_correlation']['r'],
                'correlation_p_value': correlation_analysis['pearson_correlation']['p_value'],
                'correlation_significance': correlation_analysis['pearson_correlation']['significance'],
                'consistency_level': correlation_analysis['consistency_level'],
                'direction_consistency': correlation_analysis['direction_consistency'],
                
                # åˆ†ç±»ä¸€è‡´æ€§
                'classification_agreement': primary_analysis['reagan_classification']['best_match'] == validation_analysis['reagan_classification']['best_match'],
                
                # ç« èŠ‚å¾—åˆ†ï¼ˆå‰7ç« ï¼Œä¸å¤Ÿçš„ç”¨Noneå¡«å……ï¼‰
                'chapter_scores_roberta': [ch['roberta_score'] for ch in result['chapter_analysis']],
                'chapter_scores_labmt': [ch['labmt_score'] for ch in result['chapter_analysis']],
                
                # æ–‡ä»¶è·¯å¾„
                'source_file': md_file_path
            }
            
            # æ‰©å±•ç« èŠ‚å¾—åˆ†åˆ°å•ç‹¬åˆ—ï¼ˆä¾¿äºç»Ÿè®¡åˆ†æï¼‰
            for j in range(max(7, len(result['chapter_analysis']))):  # æœ€å¤š7ç« 
                if j < len(result['chapter_analysis']):
                    result_record[f'ch{j+1}_roberta'] = result['chapter_analysis'][j]['roberta_score']
                    result_record[f'ch{j+1}_labmt'] = result['chapter_analysis'][j]['labmt_score']
                else:
                    result_record[f'ch{j+1}_roberta'] = None
                    result_record[f'ch{j+1}_labmt'] = None
            
            all_results.append(result_record)
            success_count += 1
            
            print(f"âœ… æˆåŠŸå®Œæˆåˆ†æ")
            print(f"   RoBERTa: {result_record['roberta_classification']} ({result_record['roberta_confidence']:.3f})")
            print(f"   LabMT: {result_record['labmt_classification']} ({result_record['labmt_confidence']:.3f})")
            print(f"   ç›¸å…³æ€§: r={result_record['correlation_coefficient']:.3f} ({result_record['consistency_level']})")
            
        except Exception as e:
            print(f"âŒ åˆ†æå¼‚å¸¸: {str(e)}")
            failed_files.append({
                'folder': folder,
                'reason': f'å¼‚å¸¸: {str(e)}',
                'path': md_file_path
            })
    
    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    print(f"\n{'='*60}")
    print("ğŸ“Š æ‰¹é‡åˆ†æå®Œæˆæ±‡æ€»:")
    print(f"âœ… æˆåŠŸåˆ†æ: {success_count}/{len(folders)} ä¸ªæ–‡ä»¶")
    print(f"âŒ å¤±è´¥æ–‡ä»¶: {len(failed_files)} ä¸ª")
    
    if failed_files:
        print("\nå¤±è´¥æ–‡ä»¶åˆ—è¡¨:")
        for failure in failed_files:
            print(f"  - {failure['folder']}: {failure['reason']}")
    
    if all_results:
        # ä¿å­˜ç»“æœåˆ°CSV
        df = pd.DataFrame(all_results)
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs('output/batch_results', exist_ok=True)
        
        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        csv_filename = f'output/batch_results/batch_emotional_analysis_{timestamp}.csv'
        json_filename = f'output/batch_results/batch_emotional_analysis_{timestamp}.json'
        
        # ä¿å­˜ä¸ºCSV
        df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
        print(f"ğŸ“Š CSVç»“æœå·²ä¿å­˜: {csv_filename}")
        
        # ä¿å­˜ä¸ºJSONï¼ˆåŒ…å«å®Œæ•´æ•°æ®ï¼‰
        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump({
                'metadata': {
                    'analysis_date': datetime.now().isoformat(),
                    'total_experiments': len(folders),
                    'successful_analyses': success_count,
                    'failed_analyses': len(failed_files),
                    'failed_files': failed_files
                },
                'results': all_results
            }, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“„ JSONç»“æœå·²ä¿å­˜: {json_filename}")
        
        # æ˜¾ç¤ºåŸºæœ¬ç»Ÿè®¡
        print(f"\nğŸ“ˆ å¿«é€Ÿç»Ÿè®¡:")
        print(f"æ¸©åº¦åˆ†å¸ƒ: {df['temperature'].value_counts().to_dict()}")
        print(f"æ¨¡å¼åˆ†å¸ƒ: {df['mode'].value_counts().to_dict()}")
        print(f"RoBERTaåˆ†ç±»åˆ†å¸ƒ: {df['roberta_classification'].value_counts().to_dict()}")
        print(f"LabMTåˆ†ç±»åˆ†å¸ƒ: {df['labmt_classification'].value_counts().to_dict()}")
        print(f"å¹³å‡ç›¸å…³ç³»æ•°: {df['correlation_coefficient'].mean():.3f}")
        print(f"åˆ†ç±»ä¸€è‡´ç‡: {df['classification_agreement'].mean():.1%}")
        
        return {
            'csv_file': csv_filename,
            'json_file': json_filename,
            'dataframe': df,
            'success_count': success_count,
            'failed_count': len(failed_files),
            'failed_files': failed_files
        }
    
    return None

if __name__ == "__main__":
    print("ğŸ¯ æ‰¹é‡æƒ…æ„Ÿå¼§çº¿åˆ†æå·¥å…·")
    print("å°†åˆ†ææ‰€æœ‰regression_testå®éªŒç»“æœ")
    
    result_summary = run_batch_analysis()
    
    if result_summary:
        print(f"\nğŸ‰ æ‰¹é‡åˆ†æå®Œæˆï¼")
        print(f"ğŸ“Š CSVæ–‡ä»¶: {result_summary['csv_file']}")
        print(f"ğŸ“„ JSONæ–‡ä»¶: {result_summary['json_file']}")
        print(f"âœ… æˆåŠŸ: {result_summary['success_count']} ä¸ª")
        print(f"âŒ å¤±è´¥: {result_summary['failed_count']} ä¸ª")
    else:
        print(f"\nâŒ æ‰¹é‡åˆ†ææœªäº§ç”Ÿç»“æœ")