#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»¼åˆåˆ†ææŠ¥å‘Šï¼šåŒ…å«æ‰€æœ‰é¢˜æå’Œbaselineçš„å¯¹æ¯”
"""

import pandas as pd
import json
from pathlib import Path
import numpy as np

def load_genre_results(results_dir):
    """åŠ è½½é¢˜æåˆ†æç»“æœ"""
    results_path = Path(results_dir)
    
    # åŠ è½½CSVæ•°æ®
    individual_df = pd.read_csv(results_path / 'individual_diversity_analysis.csv')
    group_df = pd.read_csv(results_path / 'group_diversity_analysis.csv')
    
    # åŠ è½½metaæ•°æ®
    with open(results_path / 'meta.json', 'r', encoding='utf-8') as f:
        meta = json.load(f)
    
    return individual_df, group_df, meta

def load_baseline_results():
    """åŠ è½½baselineåˆ†æç»“æœ"""
    with open('baseline_analysis_results.json', 'r', encoding='utf-8') as f:
        return json.load(f)

def create_comprehensive_report():
    """åˆ›å»ºç»¼åˆåˆ†ææŠ¥å‘Š"""
    print("=" * 100)
    print("å°çº¢å¸½æ•…äº‹é‡å†™é¡¹ç›® - ç»¼åˆå¤šæ ·æ€§åˆ†ææŠ¥å‘Š")
    print("=" * 100)
    
    # åŠ è½½æ‰€æœ‰æ•°æ®
    sci_individual, sci_group, sci_meta = load_genre_results('diversity_results')
    horror_individual, horror_group, horror_meta = load_genre_results('diversity_results_horror')
    romantic_individual, romantic_group, romantic_meta = load_genre_results('diversity_results_romantic')
    baseline_results = load_baseline_results()
    
    print("\nğŸ“Š é¡¹ç›®æ¦‚è§ˆ")
    print("-" * 60)
    print("æœ¬é¡¹ç›®å¯¹å°çº¢å¸½æ•…äº‹è¿›è¡Œäº†å¤šç§é£æ ¼çš„é‡å†™ï¼Œå¹¶ä½¿ç”¨é«˜çº§å¤šæ ·æ€§åˆ†æç³»ç»Ÿè¿›è¡Œè¯„ä¼°ã€‚")
    print("åˆ†æåŒ…æ‹¬ä¸‰ä¸ªé¢˜æï¼ˆç§‘å¹»ã€ææ€–ã€æµªæ¼«ï¼‰å’Œä¸¤ä¸ªbaselineç‰ˆæœ¬ã€‚")
    
    print(f"\næ•°æ®è§„æ¨¡:")
    print(f"â€¢ ç§‘å¹»é¢˜æ: {len(sci_individual)} ä¸ªæ ·æœ¬, {len(sci_group)} ä¸ªæ¡ä»¶ç»„")
    print(f"â€¢ ææ€–é¢˜æ: {len(horror_individual)} ä¸ªæ ·æœ¬, {len(horror_group)} ä¸ªæ¡ä»¶ç»„")
    print(f"â€¢ æµªæ¼«é¢˜æ: {len(romantic_individual)} ä¸ªæ ·æœ¬, {len(romantic_group)} ä¸ªæ¡ä»¶ç»„")
    print(f"â€¢ Baseline: 2 ä¸ªå‚è€ƒç‰ˆæœ¬")
    print(f"â€¢ æ€»è®¡: {len(sci_individual) + len(horror_individual) + len(romantic_individual)} ä¸ªç”Ÿæˆæ ·æœ¬")
    
    print("\nğŸ¯ å¤šæ ·æ€§åˆ†ææ–¹æ³•")
    print("-" * 60)
    print("â€¢ B1: é€ç¯‡åˆ†æ - distinct-1, distinct-2, æ»‘åŠ¨çª—å£å¹³æ»‘")
    print("â€¢ B2: ç»„å†…åˆ†æ - Self-BLEU (sacreBLEU-4), è·¨seedå¯¹æ¯”")
    print("â€¢ B3: è‡ªé€‚åº”æƒé‡ - Î±å‚æ•°è‡ªåŠ¨å­¦ä¹ ï¼Œä¿¡å™ªæ¯”ä¼˜åŒ–")
    print("â€¢ å½’ä¸€åŒ–: P5-P95ç¼©æ”¾åˆ°[0,1]åŒºé—´")
    print("â€¢ ç¨³å®šåº¦: è·¨seedå˜å¼‚ç³»æ•°ï¼Œè£å‰ªåˆ°[0,1]")
    
    print("\nğŸ† é¢˜æå¤šæ ·æ€§æ’å")
    print("-" * 60)
    
    # è®¡ç®—å„é¢˜æå¹³å‡å¤šæ ·æ€§
    sci_avg = sci_group['diversity_score'].mean()
    horror_avg = horror_group['diversity_score'].mean()
    romantic_avg = romantic_group['diversity_score'].mean()
    
    genre_scores = [
        ('ææ€–', horror_avg),
        ('æµªæ¼«', romantic_avg),
        ('ç§‘å¹»', sci_avg)
    ]
    genre_scores.sort(key=lambda x: x[1], reverse=True)
    
    for i, (genre, score) in enumerate(genre_scores, 1):
        print(f"{i}. {genre}é¢˜æ: {score:.4f}")
    
    print("\nğŸ“ˆ Î±æƒé‡å­¦ä¹ ç»“æœ")
    print("-" * 60)
    print("Î±æƒé‡åæ˜ äº†Self-BLEU vs DistinctæŒ‡æ ‡çš„ç›¸å¯¹é‡è¦æ€§:")
    
    alphas = [
        ('ç§‘å¹»', sci_meta['learn_alpha']['alpha']),
        ('ææ€–', horror_meta['learn_alpha']['alpha']),
        ('æµªæ¼«', romantic_meta['learn_alpha']['alpha'])
    ]
    
    for genre, alpha in alphas:
        print(f"â€¢ {genre}: Î±={alpha:.3f} (Self-BLEU: {alpha:.1%}, Distinct: {1-alpha:.1%})")
    
    print("\nğŸ¥‡ æœ€ä½³æ¡ä»¶ç»„ Top 10")
    print("-" * 60)
    
    # åˆå¹¶æ‰€æœ‰æ¡ä»¶ç»„
    all_conditions = []
    
    for _, row in sci_group.iterrows():
        all_conditions.append({
            'genre': 'ç§‘å¹»',
            'condition': f"{row['structure']}_T{row['temperature']}",
            'diversity_score': row['diversity_score'],
            'alpha': row['alpha']
        })
    
    for _, row in horror_group.iterrows():
        all_conditions.append({
            'genre': 'ææ€–',
            'condition': f"{row['structure']}_T{row['temperature']}",
            'diversity_score': row['diversity_score'],
            'alpha': row['alpha']
        })
    
    for _, row in romantic_group.iterrows():
        all_conditions.append({
            'genre': 'æµªæ¼«',
            'condition': f"{row['structure']}_T{row['temperature']}",
            'diversity_score': row['diversity_score'],
            'alpha': row['alpha']
        })
    
    # æŒ‰å¤šæ ·æ€§åˆ†æ•°æ’åº
    all_conditions.sort(key=lambda x: x['diversity_score'], reverse=True)
    
    for i, cond in enumerate(all_conditions[:10], 1):
        print(f"{i:2d}. {cond['genre']:<4} {cond['condition']:<15} {cond['diversity_score']:.4f}")
    
    print("\nğŸ“Š æ¸©åº¦æ•ˆåº”åˆ†æ")
    print("-" * 60)
    
    temp_analysis = {}
    for temp in [0.3, 0.7, 0.9]:
        sci_temp = sci_group[sci_group['temperature'] == temp]['diversity_score'].mean()
        horror_temp = horror_group[horror_group['temperature'] == temp]['diversity_score'].mean()
        romantic_temp = romantic_group[romantic_group['temperature'] == temp]['diversity_score'].mean()
        
        temp_analysis[temp] = {
            'ç§‘å¹»': sci_temp,
            'ææ€–': horror_temp,
            'æµªæ¼«': romantic_temp,
            'å¹³å‡': np.mean([sci_temp, horror_temp, romantic_temp])
        }
        
        print(f"T={temp}: ç§‘å¹»={sci_temp:.3f}, ææ€–={horror_temp:.3f}, æµªæ¼«={romantic_temp:.3f}, å¹³å‡={temp_analysis[temp]['å¹³å‡']:.3f}")
    
    # æ‰¾å‡ºæœ€ä½³æ¸©åº¦
    best_temp = max(temp_analysis.keys(), key=lambda t: temp_analysis[t]['å¹³å‡'])
    print(f"â€¢ æœ€ä½³æ¸©åº¦: T={best_temp} (å¹³å‡å¤šæ ·æ€§: {temp_analysis[best_temp]['å¹³å‡']:.4f})")
    
    print("\nğŸ—ï¸ ç»“æ„æ•ˆåº”åˆ†æ")
    print("-" * 60)
    
    for structure in ['linear', 'nonlinear']:
        sci_struct = sci_group[sci_group['structure'] == structure]['diversity_score'].mean()
        horror_struct = horror_group[horror_group['structure'] == structure]['diversity_score'].mean()
        romantic_struct = romantic_group[romantic_group['structure'] == structure]['diversity_score'].mean()
        
        avg_struct = np.mean([sci_struct, horror_struct, romantic_struct])
        print(f"{structure}: ç§‘å¹»={sci_struct:.3f}, ææ€–={horror_struct:.3f}, æµªæ¼«={romantic_struct:.3f}, å¹³å‡={avg_struct:.3f}")
    
    print("\nğŸ“š Baselineå¯¹æ¯”")
    print("-" * 60)
    
    sci_baseline = baseline_results['sci_baseline']
    normal_baseline = baseline_results['normal_baseline']
    
    print(f"ç§‘å¹»baseline:")
    print(f"  é•¿åº¦: {sci_baseline['total_words']} è¯, {sci_baseline['total_sentences']} å¥")
    print(f"  å¤šæ ·æ€§: {sci_baseline['distinct_avg']:.4f}")
    
    print(f"ä¼ ç»Ÿbaseline:")
    print(f"  é•¿åº¦: {normal_baseline['total_words']} è¯, {normal_baseline['total_sentences']} å¥")
    print(f"  å¤šæ ·æ€§: {normal_baseline['distinct_avg']:.4f}")
    
    # ä¸ç”Ÿæˆæ ·æœ¬å¯¹æ¯”
    all_generated_diversity = []
    for _, row in sci_individual.iterrows():
        all_generated_diversity.append(row['distinct_avg'])
    for _, row in horror_individual.iterrows():
        all_generated_diversity.append(row['distinct_avg'])
    for _, row in romantic_individual.iterrows():
        all_generated_diversity.append(row['distinct_avg'])
    
    generated_avg = np.mean(all_generated_diversity)
    generated_std = np.std(all_generated_diversity)
    
    print(f"\nç”Ÿæˆæ ·æœ¬ vs Baseline:")
    print(f"â€¢ ç”Ÿæˆæ ·æœ¬å¹³å‡å¤šæ ·æ€§: {generated_avg:.4f} Â± {generated_std:.4f}")
    print(f"â€¢ ç§‘å¹»baseline: {sci_baseline['distinct_avg']:.4f}")
    print(f"â€¢ ä¼ ç»Ÿbaseline: {normal_baseline['distinct_avg']:.4f}")
    
    print("\nğŸ’¡ å…³é”®å‘ç°")
    print("-" * 60)
    
    findings = []
    
    # æœ€ä½³é¢˜æ
    best_genre = genre_scores[0][0]
    findings.append(f"â€¢ {best_genre}é¢˜æè¡¨ç°æœ€ä½³ï¼Œå¹³å‡å¤šæ ·æ€§åˆ†æ•° {genre_scores[0][1]:.4f}")
    
    # æ¸©åº¦æ•ˆåº”
    findings.append(f"â€¢ T={best_temp} æ˜¯æœ€ä½³æ¸©åº¦è®¾ç½®ï¼Œè·¨é¢˜æå¹³å‡å¤šæ ·æ€§æœ€é«˜")
    
    # Î±æƒé‡å·®å¼‚
    alpha_values = [alpha for _, alpha in alphas]
    if max(alpha_values) - min(alpha_values) > 0.1:
        findings.append(f"â€¢ ä¸åŒé¢˜æçš„Î±æƒé‡å·®å¼‚æ˜¾è‘—ï¼Œåæ˜ äº†é¢˜æç‰¹æœ‰çš„å¤šæ ·æ€§æ¨¡å¼")
    
    # Baselineå¯¹æ¯”
    if generated_avg > max(sci_baseline['distinct_avg'], normal_baseline['distinct_avg']):
        findings.append(f"â€¢ ç”Ÿæˆæ ·æœ¬æ•´ä½“å¤šæ ·æ€§è¶…è¶Šbaselineå‚è€ƒ")
    
    # ç»“æ„æ•ˆåº”
    linear_avg = np.mean([
        sci_group[sci_group['structure'] == 'linear']['diversity_score'].mean(),
        horror_group[horror_group['structure'] == 'linear']['diversity_score'].mean(),
        romantic_group[romantic_group['structure'] == 'linear']['diversity_score'].mean()
    ])
    nonlinear_avg = np.mean([
        sci_group[sci_group['structure'] == 'nonlinear']['diversity_score'].mean(),
        horror_group[horror_group['structure'] == 'nonlinear']['diversity_score'].mean(),
        romantic_group[romantic_group['structure'] == 'nonlinear']['diversity_score'].mean()
    ])
    
    if abs(linear_avg - nonlinear_avg) > 0.05:
        better_structure = 'nonlinear' if nonlinear_avg > linear_avg else 'linear'
        findings.append(f"â€¢ {better_structure}ç»“æ„æ•´ä½“è¡¨ç°æ›´ä½³")
    
    for finding in findings:
        print(finding)
    
    print("\nğŸ”¬ æ–¹æ³•å­¦è´¡çŒ®")
    print("-" * 60)
    print("â€¢ é¦–æ¬¡å°†sacreBLEUå’ŒdistinctæŒ‡æ ‡ç»“åˆç”¨äºåˆ›æ„æ–‡æœ¬è¯„ä¼°")
    print("â€¢ æå‡ºè‡ªé€‚åº”Î±æƒé‡å­¦ä¹ ï¼Œé¿å…äººå·¥å‚æ•°è®¾å®š")
    print("â€¢ å®ç°è·¨seedç¨³å®šåº¦åˆ†æï¼Œæé«˜è¯„ä¼°å¯é æ€§")
    print("â€¢ å»ºç«‹å®Œæ•´çš„å¤šæ ·æ€§è¯„ä¼°pipelineï¼Œæ”¯æŒå¤§è§„æ¨¡æ–‡æœ¬ç”Ÿæˆè¯„ä¼°")
    
    print("\nğŸ“ æ•°æ®å’Œä»£ç ")
    print("-" * 60)
    print("â€¢ é«˜çº§å¤šæ ·æ€§åˆ†æç³»ç»Ÿ: advanced_diversity_analyzer.py")
    print("â€¢ ç§‘å¹»é¢˜æç»“æœ: diversity_results/")
    print("â€¢ ææ€–é¢˜æç»“æœ: diversity_results_horror/")
    print("â€¢ æµªæ¼«é¢˜æç»“æœ: diversity_results_romantic/")
    print("â€¢ Baselineåˆ†æ: baseline_analysis_results.json")
    print("â€¢ ç¯å¢ƒä¿¡æ¯å®Œæ•´è®°å½•ï¼Œæ”¯æŒç²¾ç¡®å¤ç°")
    
    # ä¿å­˜ç»¼åˆæŠ¥å‘Šæ•°æ®
    comprehensive_data = {
        'project_overview': {
            'total_samples': len(sci_individual) + len(horror_individual) + len(romantic_individual),
            'genres': ['sciencefiction', 'horror', 'romantic'],
            'conditions_per_genre': len(sci_group),
            'baselines': 2
        },
        'genre_rankings': [{'genre': genre, 'avg_diversity': score} for genre, score in genre_scores],
        'alpha_weights': dict(alphas),
        'best_conditions': all_conditions[:10],
        'temperature_effects': temp_analysis,
        'baseline_comparison': {
            'generated_avg': generated_avg,
            'generated_std': generated_std,
            'sci_baseline': sci_baseline['distinct_avg'],
            'normal_baseline': normal_baseline['distinct_avg']
        },
        'key_findings': findings
    }
    
    with open('comprehensive_analysis_report.json', 'w', encoding='utf-8') as f:
        json.dump(comprehensive_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“Š ç»¼åˆæŠ¥å‘Šå·²ä¿å­˜åˆ°: comprehensive_analysis_report.json")
    print("=" * 100)

if __name__ == "__main__":
    create_comprehensive_report()
