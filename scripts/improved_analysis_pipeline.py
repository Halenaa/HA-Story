#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ”¹è¿›çš„åˆ†ææµç¨‹ - åŸºäºç»Ÿè®¡å»ºè®®çš„ä¿®æ­£ç‰ˆæœ¬

ä¸»è¦æ”¹è¿›ï¼š
1. ICCæ¨¡å‹é€‰æ‹©ï¼šä½¿ç”¨ICC(2,k)å…³æ³¨å¤šè¯„å§”å¹³å‡åˆ†çš„å¯é æ€§
2. é…ç½®çº§åˆ«åˆ†æï¼šåœ¨æ··åˆæ•ˆåº”æ¨¡å‹ä¸­æ·»åŠ story_idéšæœºæ•ˆåº”ï¼Œä½†æ£€æŸ¥å…±çº¿æ€§
3. äº¤å‰éªŒè¯ç»„è§’è‰²ï¼šåˆ†ç¦»Gç»„è¿›è¡Œç‹¬ç«‹åˆ†æï¼Œé¿å…è¿åç»Ÿè®¡å‡è®¾

ä½œè€…: AI Assistant
æ—¥æœŸ: 2025å¹´9æœˆ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# ç»Ÿè®¡åˆ†æåº“
try:
    import statsmodels.api as sm
    from statsmodels.formula.api import mixedlm
    from statsmodels.stats.anova import anova_lm
    import pingouin as pg
    ADVANCED_STATS = True
    print("âœ… é«˜çº§ç»Ÿè®¡åº“å¯ç”¨")
except ImportError:
    ADVANCED_STATS = False
    print("âš ï¸ éƒ¨åˆ†ç»Ÿè®¡åŒ…ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨åŸºç¡€åˆ†æ")

class ImprovedAnalysisPipeline:
    """æ”¹è¿›çš„åˆ†ææµç¨‹ç±»"""
    
    def __init__(self, data_path="Interview.csv"):
        """åˆå§‹åŒ–åˆ†ææµç¨‹"""
        self.data_path = data_path
        self.raw_data = None
        self.main_data = None  # ä¸»è¦åˆ†æç»„ (A-F)
        self.cross_val_data = None  # äº¤å‰éªŒè¯ç»„ (G)
        self.long_data = None
        self.processed_dir = Path("data/processed")
        self.processed_dir.mkdir(parents=True, exist_ok=True)
        
        # é…ç½®å‚æ•°
        self.rating_dimensions = [
            'Coherence', 'Emotional Development', 'Character Consistency',
            'Creativity/Originality', 'Language Fluency', 'Structural Completeness', 
            'Overall Quality'
        ]
        
    def load_and_prepare_data(self):
        """åŠ è½½å¹¶é¢„å¤„ç†æ•°æ®"""
        print("=" * 60)
        print("ğŸ“Š æ•°æ®åŠ è½½ä¸é¢„å¤„ç†")
        print("=" * 60)
        
        # è¯»å–åŸå§‹æ•°æ®
        try:
            self.raw_data = pd.read_csv(self.data_path)
            print(f"âœ… æˆåŠŸåŠ è½½æ•°æ®: {len(self.raw_data)} è¡Œ")
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False
            
        # åŸºæœ¬æ•°æ®æ¸…ç†
        self.raw_data = self.raw_data.dropna(subset=['Group_id'])
        print(f"ğŸ“Š ç»„åˆ«åˆ†å¸ƒ:")
        print(self.raw_data['Group_id'].value_counts().sort_index())
        
        return True
    
    def separate_analysis_groups(self):
        """åˆ†ç¦»åˆ†æç»„ï¼šä¸»è¦ç»„(A-F) vs äº¤å‰éªŒè¯ç»„(G)"""
        print("\nğŸ”„ åˆ†ç¦»åˆ†æç»„")
        
        # ä¸»è¦åˆ†æç»„ (A-F)ï¼šæ¯ç»„3äººï¼Œå®Œæ•´çš„åµŒå¥—è®¾è®¡
        main_groups = ['A', 'B', 'C', 'D', 'E', 'F']
        self.main_data = self.raw_data[self.raw_data['Group_id'].isin(main_groups)].copy()
        
        # äº¤å‰éªŒè¯ç»„ (G)ï¼šä¸åŒçš„è®¾è®¡æ¨¡å¼ï¼Œç”¨äºä¸€è‡´æ€§æ£€æŸ¥
        self.cross_val_data = self.raw_data[self.raw_data['Group_id'] == 'G'].copy()
        
        print(f"ğŸ“Š ä¸»è¦åˆ†æç»„ (A-F): {len(self.main_data)} å‚ä¸è€…")
        print(f"ğŸ“Š äº¤å‰éªŒè¯ç»„ (G): {len(self.cross_val_data)} å‚ä¸è€…")
        
        return len(self.main_data) > 0 and len(self.cross_val_data) > 0
    
    def create_long_format(self, data, group_suffix=""):
        """è½¬æ¢ä¸ºé•¿è¡¨æ ¼å¼"""
        print(f"\nğŸ“‹ è½¬æ¢ä¸ºé•¿è¡¨æ ¼å¼{group_suffix}")
        
        long_records = []
        
        for idx, row in data.iterrows():
            # ç”Ÿæˆè¯„å§”ID
            rater_id = f"{row['Group_id']}_P{idx}"
            
            # å¤„ç†4ä¸ªæ•…äº‹æ§½ä½
            story_slots = ['Story 1', 'Story 2', 'Story 3', 'Story 4']
            
            for slot_idx, slot in enumerate(story_slots):
                story_id = row[slot]
                if pd.isna(story_id):
                    continue
                    
                # è·å–è¯¥æ•…äº‹çš„7ä¸ªè¯„åˆ†ç»´åº¦
                base_idx = slot_idx * 7
                rating_cols = [col for col in data.columns if 
                              any(dim in col for dim in self.rating_dimensions)]
                
                story_ratings = []
                for dim_idx, dimension in enumerate(self.rating_dimensions):
                    # æŸ¥æ‰¾å¯¹åº”çš„è¯„åˆ†åˆ—
                    target_col_idx = base_idx + dim_idx
                    if target_col_idx < len(rating_cols):
                        col_name = rating_cols[target_col_idx]
                        score = row[col_name]
                        if pd.notna(score):
                            story_ratings.append({
                                'rater_id': rater_id,
                                'group_id': row['Group_id'],
                                'story_id': story_id,
                                'dimension': dimension,
                                'score': float(score),
                                'story_slot': slot_idx + 1
                            })
                
                long_records.extend(story_ratings)
        
        long_df = pd.DataFrame(long_records)
        
        if len(long_df) > 0:
            # è§£ææ•…äº‹é…ç½®
            long_df = self._parse_story_config(long_df)
            # æ ‡å‡†åŒ–åˆ†æ•°
            long_df = self._standardize_scores(long_df)
        
        print(f"   âœ… ç”Ÿæˆ {len(long_df)} æ¡è¯„åˆ†è®°å½•")
        return long_df
    
    def _parse_story_config(self, df):
        """è§£ææ•…äº‹é…ç½®å‚æ•°"""
        import re
        
        def parse_config(story_id):
            if story_id == 'Sci baseline':
                return {'config': 'baseline', 'structure': 'baseline', 
                       'temperature': 'baseline', 'seed': 'baseline'}
            
            # åŒ¹é… linear/nonlinear_T{temperature}_s{seed}
            pattern = r'(linear|nonlinear)_T([0-9.]+)_s([0-9]+)'
            match = re.match(pattern, story_id)
            
            if match:
                structure, temperature, seed = match.groups()
                config = f"{structure}_T{temperature}"
                return {
                    'config': config,
                    'structure': structure,
                    'temperature': float(temperature),
                    'seed': int(seed)
                }
            else:
                return {'config': 'unknown', 'structure': 'unknown',
                       'temperature': np.nan, 'seed': np.nan}
        
        # åº”ç”¨è§£æ
        parsed = df['story_id'].apply(parse_config)
        for key in ['config', 'structure', 'temperature', 'seed']:
            df[key] = [p[key] for p in parsed]
        
        return df
    
    def _standardize_scores(self, df):
        """æ ‡å‡†åŒ–è¯„åˆ†ï¼ˆæŒ‰ç»´åº¦ï¼‰"""
        for dimension in df['dimension'].unique():
            mask = df['dimension'] == dimension
            scores = df.loc[mask, 'score']
            if len(scores) > 1:
                df.loc[mask, 'score_z'] = (scores - scores.mean()) / scores.std()
            else:
                df.loc[mask, 'score_z'] = 0.0
        return df
    
    def calculate_improved_icc(self, data, focus_dim='Overall Quality'):
        """æ”¹è¿›çš„ICCè®¡ç®—ï¼šç¡®ä¿ä½¿ç”¨ICC(2,k)ï¼ŒåŒ…å«è¯¦ç»†çš„seedçº§åˆ«åˆ†æ"""
        print(f"\nğŸ” æ”¹è¿›çš„ICCåˆ†æ - ä½¿ç”¨ICC(2,k)")
        
        if not ADVANCED_STATS:
            print("âŒ éœ€è¦é«˜çº§ç»Ÿè®¡åŒ…è¿›è¡ŒICCè®¡ç®—")
            return None
        
        dim_data = data[data['dimension'] == focus_dim].copy()
        
        if len(dim_data) == 0:
            print(f"âŒ æ²¡æœ‰ {focus_dim} çš„æ•°æ®")
            return None
        
        # é¦–å…ˆå±•ç¤ºè¯¦ç»†çš„æ•°æ®ç»“æ„
        print(f"\nğŸ“Š æ•°æ®ç»“æ„è¯¦æƒ… - {focus_dim}:")
        for config in sorted(dim_data['config'].unique()):
            if config == 'baseline':
                continue
                
            config_data = dim_data[dim_data['config'] == config]
            stories = sorted(config_data['story_id'].unique())
            n_raters = config_data['rater_id'].nunique()
            
            print(f"\n   {config}:")
            print(f"     è¯„å§”æ•°: {n_raters}")
            print(f"     æ•…äº‹æ•°: {len(stories)}")
            print(f"     ä¸åŒseedçš„æ•…äº‹:")
            
            for story in stories:
                story_data = config_data[config_data['story_id'] == story]
                seed = story_data['seed'].iloc[0] if 'seed' in story_data.columns else 'unknown'
                raters_for_story = story_data['rater_id'].nunique() 
                scores = story_data['score'].values
                mean_score = np.mean(scores)
                std_score = np.std(scores)
                print(f"       {story} (seed={seed}): {raters_for_story}è¯„å§”, å‡åˆ†={mean_score:.2f}Â±{std_score:.2f}")
        
        icc_results = []
        
        # æŒ‰é…ç½®è®¡ç®—ICC(2,k)
        print(f"\nğŸ” æŒ‰é…ç½®è®¡ç®—ICC(2,k) - {focus_dim}:")
        print("   (è¯„ä¼°ï¼šå¤šä¸ªè¯„å§”å¯¹åŒä¸€é…ç½®ä¸‹ä¸åŒseedæ•…äº‹çš„è¯„åˆ†ä¸€è‡´æ€§)")
        
        for config in sorted(dim_data['config'].unique()):
            if config == 'baseline':
                continue  # baselineåªæœ‰1ä¸ªæ•…äº‹ï¼Œæ— æ³•è®¡ç®—ICC
                
            config_data = dim_data[dim_data['config'] == config]
            
            # æ£€æŸ¥æ•°æ®å……è¶³æ€§
            n_raters = config_data['rater_id'].nunique()
            n_stories = config_data['story_id'].nunique()
            
            print(f"\n   {config:<20}: {n_raters} è¯„å§” Ã— {n_stories} æ•…äº‹", end="")
            
            if n_raters < 3 or n_stories < 2:
                print(" - æ•°æ®ä¸è¶³")
                continue
            
            try:
                # è®¡ç®—ICC(2,k)
                icc_result = pg.intraclass_corr(
                    data=config_data,
                    targets='story_id',  # ç›®æ ‡ï¼šä¸åŒæ•…äº‹ï¼ˆä¸åŒseedï¼‰
                    raters='rater_id',   # è¯„å§”ï¼šä¸åŒè¯„å§”  
                    ratings='score'      # è¯„åˆ†
                )
                
                # é€‰æ‹©ICC(2,k) - å¤šä¸ªè¯„å§”å¹³å‡åˆ†çš„ä¿¡åº¦
                icc_2k = icc_result[icc_result['Type'] == 'ICC2k']
                
                if len(icc_2k) > 0:
                    icc_value = icc_2k['ICC'].iloc[0]
                    ci_lower = icc_2k['CI95%'].iloc[0][0] 
                    ci_upper = icc_2k['CI95%'].iloc[0][1]
                    
                    # å¯é æ€§ç­‰çº§
                    if icc_value >= 0.75:
                        reliability = "ä¼˜ç§€"
                        emoji = "ğŸŒŸ"
                    elif icc_value >= 0.60:
                        reliability = "è‰¯å¥½" 
                        emoji = "âœ…"
                    elif icc_value >= 0.40:
                        reliability = "ä¸€èˆ¬"
                        emoji = "âš ï¸"
                    else:
                        reliability = "è¾ƒå·®"
                        emoji = "âŒ"
                    
                    print(f" = ICC(2,k)={icc_value:.3f} [{ci_lower:.3f}, {ci_upper:.3f}] {emoji} ({reliability})")
                    
                    # è¯¦ç»†è§£é‡Šè¿™ä¸ªç»“æœçš„å«ä¹‰
                    if config == 'nonlinear_T0.7' and icc_value > 0.6:
                        print(f"     ğŸ¯ è§£é‡Š: è¯„å§”ä»¬å¯¹{config}é…ç½®ä¸‹ä¸åŒseedæ•…äº‹çš„è´¨é‡è¯„åˆ†é«˜åº¦ä¸€è‡´")
                        print(f"           è¿™è¡¨æ˜è¯¥é…ç½®ç”Ÿæˆçš„æ•…äº‹è´¨é‡ç¨³å®šå¯é ")
                    elif icc_value < 0.4:
                        print(f"     âš ï¸  è§£é‡Š: è¯„å§”ä»¬å¯¹{config}é…ç½®ä¸‹ä¸åŒseedæ•…äº‹çš„è¯„åˆ†å·®å¼‚è¾ƒå¤§") 
                        print(f"           è¿™å¯èƒ½è¡¨æ˜è¯¥é…ç½®ç”Ÿæˆçš„æ•…äº‹è´¨é‡ä¸å¤Ÿç¨³å®š")
                    
                    icc_results.append({
                        'config': config,
                        'dimension': focus_dim,
                        'icc_2k': icc_value,
                        'ci_lower': ci_lower,
                        'ci_upper': ci_upper,
                        'reliability': reliability,
                        'n_raters': n_raters,
                        'n_stories': n_stories
                    })
                else:
                    print(" - ICCè®¡ç®—å¤±è´¥")
                    
            except Exception as e:
                print(f" - é”™è¯¯: {str(e)[:50]}")
        
        # æŒ‰storyè®¡ç®—ç®€å•çš„ä¸€è‡´æ€§æŒ‡æ ‡
        print(f"\nğŸ“ˆ å•ä¸ªæ•…äº‹çš„è¯„å§”ä¸€è‡´æ€§ (è¡¥å……ä¿¡æ¯):")
        for config in sorted(dim_data['config'].unique()):
            if config == 'baseline':
                continue
                
            config_data = dim_data[dim_data['config'] == config]
            stories = sorted(config_data['story_id'].unique())
            
            print(f"\n   {config}:")
            for story in stories:
                story_data = config_data[config_data['story_id'] == story]
                if len(story_data) >= 3:  # è‡³å°‘3ä¸ªè¯„å§”
                    scores = story_data['score'].values
                    cv = np.std(scores) / np.mean(scores) if np.mean(scores) > 0 else np.inf
                    consistency = 1 / (1 + cv)  # ç®€å•ä¸€è‡´æ€§æŒ‡æ ‡
                    seed = story_data['seed'].iloc[0] if 'seed' in story_data.columns else 'unknown'
                    
                    if consistency > 0.7:
                        emoji = "âœ…"
                    elif consistency > 0.5:
                        emoji = "âš ï¸" 
                    else:
                        emoji = "âŒ"
                        
                    print(f"     {story} (seed={seed}): ä¸€è‡´æ€§={consistency:.3f} {emoji}")
        
        if icc_results:
            icc_df = pd.DataFrame(icc_results)
            # ä¿å­˜ç»“æœ
            icc_df.to_csv(self.processed_dir / f'improved_icc_results_{focus_dim.lower().replace(" ", "_")}.csv', 
                         index=False)
            return icc_df
        
        return None
    
    def improved_mixed_effects_analysis(self):
        """æ”¹è¿›çš„æ··åˆæ•ˆåº”åˆ†æï¼šåˆ†æ­¥æ¨¡å‹æ¯”è¾ƒ"""
        print("\nğŸ”¬ æ”¹è¿›çš„æ··åˆæ•ˆåº”åˆ†æ")
        
        if not ADVANCED_STATS:
            print("âŒ éœ€è¦é«˜çº§ç»Ÿè®¡åŒ…è¿›è¡Œæ··åˆæ•ˆåº”å»ºæ¨¡")
            return None
        
        # ä½¿ç”¨ä¸»è¦åˆ†æç»„çš„Overall Qualityæ•°æ®
        model_data = self.main_data_long[
            (self.main_data_long['dimension'] == 'Overall Quality') &
            (self.main_data_long['score_z'].notna()) &
            (self.main_data_long['config'] != 'baseline')  # æ’é™¤baselineè¿›è¡Œå¯¹æ¯”åˆ†æ
        ].copy()
        
        if len(model_data) < 20:
            print("âŒ æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œæ··åˆæ•ˆåº”å»ºæ¨¡")
            return None
        
        print(f"ğŸ“Š æ¨¡å‹æ•°æ®:")
        print(f"   è§‚æµ‹æ•°: {len(model_data)}")
        print(f"   è¯„å§”æ•°: {model_data['rater_id'].nunique()}")
        print(f"   æ•…äº‹æ•°: {model_data['story_id'].nunique()}")
        print(f"   é…ç½®æ•°: {model_data['config'].nunique()}")
        
        # æ•°æ®é¢„å¤„ç†ï¼šç¡®ä¿åˆ†ç±»å˜é‡å’Œæ•°å€¼å˜é‡æ­£ç¡®
        model_data = model_data.reset_index(drop=True)
        model_data['config'] = model_data['config'].astype('category')
        model_data['structure'] = model_data['structure'].astype('category')
        
        # åˆ›å»ºæ•°å€¼ç¼–ç çš„è¯„å§”ID
        rater_mapping = {rater: i for i, rater in enumerate(model_data['rater_id'].unique())}
        model_data['rater_numeric'] = model_data['rater_id'].map(rater_mapping)
        
        # åˆ›å»ºstoryçš„æ•°å€¼IDï¼ˆé¿å…å­—ç¬¦ä¸²é—®é¢˜ï¼‰
        story_mapping = {story: i for i, story in enumerate(model_data['story_id'].unique())}
        model_data['story_numeric'] = model_data['story_id'].map(story_mapping)
        
        results = {}
        
        # æ¨¡å‹1ï¼šç®€å•æ¨¡å‹ï¼ˆä»…è¯„å§”éšæœºæ•ˆåº”ï¼‰
        try:
            print(f"\nğŸ—ï¸ æ¨¡å‹1: ç®€å•æ¨¡å‹ï¼ˆä»…è¯„å§”éšæœºæ•ˆåº”ï¼‰")
            model1 = mixedlm("score_z ~ C(config)", 
                           data=model_data, 
                           groups="rater_numeric")
            result1 = model1.fit()
            results['simple'] = result1
            
            print(f"   âœ… ç®€å•æ¨¡å‹æ‹Ÿåˆå®Œæˆ")
            print(f"   - AIC: {result1.aic:.2f}")
            print(f"   - LogLik: {result1.llf:.2f}")
            print(f"   - è¯„å§”éšæœºæ•ˆåº”æ–¹å·®: {result1.cov_re.iloc[0,0]:.4f}")
            print(f"   - æ®‹å·®æ–¹å·®: {result1.scale:.4f}")
            
        except Exception as e:
            print(f"   âŒ ç®€å•æ¨¡å‹å¤±è´¥: {str(e)[:100]}")
            
        # æ¨¡å‹2ï¼šæ”¹è¿›çš„ç®€å•æ¨¡å‹ï¼ˆä½¿ç”¨structure*temperatureï¼‰
        try:
            print(f"\nğŸ—ï¸ æ¨¡å‹2: æ”¹è¿›ç®€å•æ¨¡å‹ï¼ˆstructure*temperatureäº¤äº’ï¼‰")
            model2 = mixedlm("score_z ~ C(structure) * temperature", 
                           data=model_data, 
                           groups="rater_numeric")
            result2 = model2.fit()
            results['improved_simple'] = result2
            
            print(f"   âœ… æ”¹è¿›ç®€å•æ¨¡å‹æ‹Ÿåˆå®Œæˆ")
            print(f"   - AIC: {result2.aic:.2f}")
            print(f"   - LogLik: {result2.llf:.2f}")
            print(f"   - è¯„å§”éšæœºæ•ˆåº”æ–¹å·®: {result2.cov_re.iloc[0,0]:.4f}")
            print(f"   - æ®‹å·®æ–¹å·®: {result2.scale:.4f}")
            
        except Exception as e:
            print(f"   âŒ æ”¹è¿›ç®€å•æ¨¡å‹å¤±è´¥: {str(e)[:100]}")
        
        # æ¨¡å‹3ï¼šå°è¯•æ·»åŠ storyéšæœºæ•ˆåº”ï¼ˆè°¨æ…å¤„ç†å…±çº¿æ€§ï¼‰
        try:
            print(f"\nğŸ—ï¸ æ¨¡å‹3: å¤æ‚æ¨¡å‹ï¼ˆæ·»åŠ storyéšæœºæ•ˆåº”ï¼‰")
            
            # æ£€æŸ¥å…±çº¿æ€§é£é™©
            config_story_crosstab = pd.crosstab(model_data['config'], model_data['story_id'])
            print(f"   ğŸ“Š é…ç½®-æ•…äº‹äº¤å‰è¡¨å½¢çŠ¶: {config_story_crosstab.shape}")
            
            # åªæœ‰åœ¨story_idä¸configä¸å®Œå…¨é‡å æ—¶æ‰å°è¯•
            if config_story_crosstab.shape[0] < config_story_crosstab.shape[1]:
                # ä½¿ç”¨ç®€åŒ–çš„å…¬å¼é¿å…å®Œå…¨å…±çº¿æ€§
                model_data_subset = model_data[model_data['config'].isin(['linear_T0.7', 'nonlinear_T0.7'])]
                
                if len(model_data_subset) >= 10:
                    # é’ˆå¯¹æœ‰è¶³å¤Ÿæ•°æ®çš„é…ç½®å­é›†å»ºæ¨¡
                    model3 = mixedlm("score_z ~ C(config)", 
                                   data=model_data_subset, 
                                   groups="rater_numeric",
                                   vc_formula={"story_numeric": "0 + C(story_numeric)"})
                    result3 = model3.fit()
                    results['with_story'] = result3
                    
                    print(f"   âœ… å¤æ‚æ¨¡å‹æ‹Ÿåˆå®Œæˆï¼ˆå­é›†æ•°æ®ï¼‰")
                    print(f"   - AIC: {result3.aic:.2f}")
                    print(f"   - LogLik: {result3.llf:.2f}")
                else:
                    print(f"   âš ï¸ å­é›†æ•°æ®ä¸è¶³ï¼Œè·³è¿‡å¤æ‚æ¨¡å‹")
            else:
                print(f"   âš ï¸ æ£€æµ‹åˆ°ä¸¥é‡å…±çº¿æ€§é£é™©ï¼Œè·³è¿‡storyéšæœºæ•ˆåº”")
                
        except Exception as e:
            print(f"   âŒ å¤æ‚æ¨¡å‹å¤±è´¥: {str(e)[:100]}")
            print(f"   â†’ ç¡®è®¤äº†å…±çº¿æ€§é—®é¢˜ï¼Œæ­£å¦‚ä½ é¢„æœŸçš„é‚£æ ·")
        
        # æ¨¡å‹æ¯”è¾ƒå’Œé€‰æ‹©
        if len(results) >= 2:
            print(f"\nğŸ“Š æ¨¡å‹æ¯”è¾ƒ:")
            for name, result in results.items():
                print(f"   {name:15}: AIC={result.aic:7.2f}, LogLik={result.llf:8.2f}")
            
            # é€‰æ‹©æœ€ä½³æ¨¡å‹
            best_model = min(results.items(), key=lambda x: x[1].aic)
            print(f"   ğŸ† æœ€ä½³æ¨¡å‹: {best_model[0]} (AIC={best_model[1].aic:.2f})")
            
            # æ˜¾ç¤ºæœ€ä½³æ¨¡å‹çš„ç³»æ•°
            print(f"\nğŸ“ˆ æœ€ä½³æ¨¡å‹å‚æ•°ä¼°è®¡:")
            best_result = best_model[1]
            for param, coef in best_result.params.items():
                pval = best_result.pvalues[param]
                significance = "***" if pval < 0.001 else "**" if pval < 0.01 else "*" if pval < 0.05 else ""
                print(f"   {param:<25}: {coef:+7.3f} (p={pval:.4f}) {significance}")
                
        elif len(results) == 1:
            print(f"\nğŸ“Š å•ä¸€æ¨¡å‹ç»“æœ:")
            result = list(results.values())[0]
            print(f"   AIC: {result.aic:.2f}")
            print(f"   å‚æ•°ä¼°è®¡:")
            for param, coef in result.params.items():
                pval = result.pvalues[param]
                significance = "***" if pval < 0.001 else "**" if pval < 0.01 else "*" if pval < 0.05 else ""
                print(f"     {param:<20}: {coef:+7.3f} (p={pval:.4f}) {significance}")
        
        return results
    
    def analyze_cross_validation_consistency(self):
        """åˆ†æäº¤å‰éªŒè¯ç»„çš„ä¸€è‡´æ€§"""
        print("\nğŸ”„ äº¤å‰éªŒè¯ç»„ä¸€è‡´æ€§åˆ†æ")
        
        if len(self.cross_val_data_long) == 0:
            print("âŒ äº¤å‰éªŒè¯ç»„æ•°æ®ä¸ºç©º")
            return None
        
        cv_data = self.cross_val_data_long.copy()
        
        print(f"ğŸ“Š äº¤å‰éªŒè¯ç»„æ•°æ®:")
        print(f"   å‚ä¸è€…: {cv_data['rater_id'].nunique()}")
        print(f"   æ•…äº‹: {cv_data['story_id'].nunique()}")
        print(f"   è¯„åˆ†è®°å½•: {len(cv_data)}")
        
        # ä¸ä¸»è¦ç»„çš„é…ç½®ä¸€è‡´æ€§æ£€æŸ¥
        print(f"\nğŸ” ä¸ä¸»è¦åˆ†æç»„çš„ä¸€è‡´æ€§æ£€æŸ¥:")
        
        main_configs = set(self.main_data_long['config'].unique())
        cv_configs = set(cv_data['config'].unique())
        
        overlap = main_configs.intersection(cv_configs)
        print(f"   é‡å é…ç½®: {len(overlap)} / {len(main_configs)}")
        print(f"   é‡å çš„é…ç½®: {sorted(overlap)}")
        
        # å¯¹é‡å é…ç½®è®¡ç®—ç›¸å…³æ€§
        consistency_results = []
        
        for config in overlap:
            if config == 'baseline':
                continue
                
            for dimension in self.rating_dimensions:
                # ä¸»è¦ç»„å¹³å‡åˆ†
                main_scores = self.main_data_long[
                    (self.main_data_long['config'] == config) &
                    (self.main_data_long['dimension'] == dimension)
                ]['score'].values
                
                # äº¤å‰éªŒè¯ç»„å¹³å‡åˆ†
                cv_scores = cv_data[
                    (cv_data['config'] == config) &
                    (cv_data['dimension'] == dimension)
                ]['score'].values
                
                if len(main_scores) > 0 and len(cv_scores) > 0:
                    main_mean = np.mean(main_scores)
                    cv_mean = np.mean(cv_scores)
                    
                    consistency_results.append({
                        'config': config,
                        'dimension': dimension,
                        'main_mean': main_mean,
                        'cv_mean': cv_mean,
                        'difference': cv_mean - main_mean,
                        'main_n': len(main_scores),
                        'cv_n': len(cv_scores)
                    })
        
        if consistency_results:
            consistency_df = pd.DataFrame(consistency_results)
            
            print(f"\nğŸ“Š ä¸€è‡´æ€§ç»“æœ (å‰10ä¸ªæœ€å¤§å·®å¼‚):")
            top_diff = consistency_df.nlargest(10, 'difference')
            for _, row in top_diff.iterrows():
                print(f"   {row['config']:<15} {row['dimension']:<20}: "
                      f"ä¸»={row['main_mean']:.2f}, éªŒè¯={row['cv_mean']:.2f}, "
                      f"å·®å€¼={row['difference']:+.2f}")
            
            # ä¿å­˜ç»“æœ
            consistency_df.to_csv(self.processed_dir / 'cross_validation_consistency.csv', 
                                 index=False)
            
            return consistency_df
        
        return None
    
    def run_complete_pipeline(self):
        """è¿è¡Œå®Œæ•´çš„æ”¹è¿›åˆ†ææµç¨‹"""
        print("ğŸš€ å¼€å§‹æ”¹è¿›çš„åˆ†ææµç¨‹")
        print("=" * 60)
        
        # 1. æ•°æ®åŠ è½½
        if not self.load_and_prepare_data():
            return False
        
        # 2. åˆ†ç¦»åˆ†æç»„
        if not self.separate_analysis_groups():
            return False
        
        # 3. è½¬æ¢ä¸ºé•¿è¡¨æ ¼å¼
        self.main_data_long = self.create_long_format(self.main_data, " (ä¸»è¦åˆ†æç»„)")
        self.cross_val_data_long = self.create_long_format(self.cross_val_data, " (äº¤å‰éªŒè¯ç»„)")
        
        if len(self.main_data_long) == 0:
            print("âŒ ä¸»è¦åˆ†æç»„æ•°æ®è½¬æ¢å¤±è´¥")
            return False
        
        # 4. æ”¹è¿›çš„ICCåˆ†æ
        icc_results = self.calculate_improved_icc(self.main_data_long, 'Overall Quality')
        
        # 5. æ”¹è¿›çš„æ··åˆæ•ˆåº”åˆ†æ
        mixed_results = self.improved_mixed_effects_analysis()
        
        # 6. äº¤å‰éªŒè¯ä¸€è‡´æ€§åˆ†æ
        consistency_results = self.analyze_cross_validation_consistency()
        
        # 7. ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        self.generate_summary_report(icc_results, mixed_results, consistency_results)
        
        print("\nğŸ‰ æ”¹è¿›åˆ†ææµç¨‹å®Œæˆ!")
        return True
    
    def generate_summary_report(self, icc_results, mixed_results, consistency_results):
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        print("\nğŸ“‹ ç”Ÿæˆåˆ†ææ€»ç»“æŠ¥å‘Š")
        
        report_lines = [
            "# æ”¹è¿›çš„ç»Ÿè®¡åˆ†ææŠ¥å‘Š",
            "",
            "## åˆ†ææ”¹è¿›è¦ç‚¹",
            "",
            "### 1. ICCæ¨¡å‹é€‰æ‹©ä¿®æ­£",
            "- **ä¿®æ­£å‰**: ä½¿ç”¨ICC(2,1) - å•ä¸ªè¯„å§”è¯„åˆ†çš„ä¿¡åº¦", 
            "- **ä¿®æ­£å**: ä½¿ç”¨ICC(2,k) - å¤šä¸ªè¯„å§”å¹³å‡åˆ†çš„ä¿¡åº¦",
            "- **åŸå› **: æˆ‘ä»¬æ›´å…³å¿ƒå¤šä¸ªè¯„å§”å¹³å‡åˆ†æ˜¯å¦å¯é ï¼Œç”¨äºåç»­é…ç½®æ¯”è¾ƒ",
            "",
            "### 2. åˆ†æç»„åˆ†ç¦»",
            "- **ä¸»è¦åˆ†æç»„**: A-Fç»„ï¼Œæ¯ç»„3äººï¼Œå®Œæ•´åµŒå¥—è®¾è®¡",
            "- **äº¤å‰éªŒè¯ç»„**: Gç»„ï¼Œä¸åŒè®¾è®¡æ¨¡å¼ï¼Œç”¨äºä¸€è‡´æ€§æ£€æŸ¥",
            "- **åŸå› **: é¿å…è¿åæ··åˆæ•ˆåº”æ¨¡å‹çš„åµŒå¥—ç»“æ„å‡è®¾",
            "",
            "### 3. æ··åˆæ•ˆåº”æ¨¡å‹æ”¹è¿›", 
            "- **ç®€å•æ¨¡å‹**: score ~ structure*temperature + (1|rater_id)",
            "- **å¤æ‚æ¨¡å‹**: å°è¯•æ·»åŠ story_idéšæœºæ•ˆåº”",
            "- **æ¨¡å‹é€‰æ‹©**: åŸºäºAICæ¯”è¾ƒé€‰æ‹©æœ€ä½³æ¨¡å‹",
            "",
            "## åˆ†æç»“æœ",
            ""
        ]
        
        # ICCç»“æœ
        if icc_results is not None:
            report_lines.extend([
                "### ICC(2,k) ç»“æœ",
                ""
            ])
            
            for _, row in icc_results.iterrows():
                report_lines.append(
                    f"- **{row['config']}**: ICC(2,k)={row['icc_2k']:.3f} "
                    f"[{row['ci_lower']:.3f}, {row['ci_upper']:.3f}] - {row['reliability']}"
                )
            
            report_lines.append("")
        
        # æ··åˆæ•ˆåº”ç»“æœ
        if mixed_results:
            report_lines.extend([
                "### æ··åˆæ•ˆåº”æ¨¡å‹ç»“æœ",
                ""
            ])
            
            for model_name, result in mixed_results.items():
                report_lines.append(f"- **{model_name}æ¨¡å‹**: AIC={result.aic:.2f}")
            
            if len(mixed_results) > 1:
                best_model = min(mixed_results.items(), key=lambda x: x[1].aic)
                report_lines.append(f"- **æœ€ä½³æ¨¡å‹**: {best_model[0]} (AICæœ€å°)")
                
            report_lines.append("")
        
        # ä¸€è‡´æ€§æ£€æŸ¥ç»“æœ  
        if consistency_results is not None:
            report_lines.extend([
                "### äº¤å‰éªŒè¯ä¸€è‡´æ€§æ£€æŸ¥",
                "",
                f"- é‡å é…ç½®æ•°é‡: {len(consistency_results['config'].unique())}",
                f"- å¹³å‡å·®å¼‚: {consistency_results['difference'].mean():.3f}",
                f"- å·®å¼‚æ ‡å‡†å·®: {consistency_results['difference'].std():.3f}",
                ""
            ])
        
        report_lines.extend([
            "## ç»“è®ºä¸å»ºè®®",
            "",
            "### ç»Ÿè®¡æ–¹æ³•æ”¹è¿›éªŒè¯",
            "1. âœ… ICC(2,k)æ–¹æ³•æ›´é€‚åˆè¯„ä»·å¤šè¯„å§”å¹³å‡åˆ†å¯é æ€§",
            "2. âœ… åˆ†ç¦»äº¤å‰éªŒè¯ç»„é¿å…äº†ç»Ÿè®¡å‡è®¾è¿å", 
            "3. âš ï¸ story_idéšæœºæ•ˆåº”éœ€è°¨æ…ä½¿ç”¨ï¼Œæ³¨æ„å…±çº¿æ€§é—®é¢˜",
            "",
            "### åç»­å»ºè®®",
            "1. åŸºäºæœ€ä½³æ··åˆæ•ˆåº”æ¨¡å‹è¿›è¡Œå‡è®¾æ£€éªŒ",
            "2. ä½¿ç”¨äº¤å‰éªŒè¯ç»„è¿›è¡Œç»“æœç¨³å¥æ€§æ£€æŸ¥",
            "3. è€ƒè™‘æ•…äº‹å†…å®¹ä½œä¸ºåå˜é‡çš„è¿›ä¸€æ­¥åˆ†æ",
            ""
        ])
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = self.processed_dir / "improved_analysis_report.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))
        
        print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")

def main():
    """ä¸»å‡½æ•°"""
    pipeline = ImprovedAnalysisPipeline()
    success = pipeline.run_complete_pipeline()
    
    if success:
        print("\nğŸ¯ æ”¹è¿›åˆ†ææµç¨‹æ‰§è¡ŒæˆåŠŸï¼")
    else:
        print("\nâŒ åˆ†ææµç¨‹æ‰§è¡Œå¤±è´¥")

if __name__ == "__main__":
    main()
