import os
import json
from typing import List
from src.main_pipeline import main as run_story_pipeline
from src.utils.utils import load_json

def normalize(s):
    return s.replace(" ", "").replace("ï¼š", "").replace(":", "").replace("/", "_")

def extract_anchor_and_behavior_info(base_dir: str):
    """
    ä»è¾“å‡ºç›®å½•ä¸­æå– anchor æ•°é‡å’Œè§’è‰²çŠ¶æ€ç»Ÿè®¡ä¿¡æ¯
    """
    anchor_path = os.path.join(base_dir, "generated_anchors_dual_surface.json")
    role_state_path = os.path.join(base_dir, "role_state.json")
    anchor_count = 0
    avg_state_count = 0

    if os.path.exists(anchor_path):
        anchors = load_json(anchor_path).get("anchors", [])
        anchor_count = len(anchors)

    if os.path.exists(role_state_path):
        state_data = load_json(role_state_path)
        total, count = 0, 0
        for chapter in state_data.values():
            for states in chapter.values():
                total += len(states)
                count += 1
        if count > 0:
            avg_state_count = round(total / count, 2)

    return anchor_count, avg_state_count

def run_montecarlo_generation_v2(
    topic: str,
    style: str,
    temperature_list: List[float] = [0.3, 0.7, 1.0],
    base_version_prefix="monte",
    output_root="output",
    log_path="sampling_log.json"
):
    """
    è¿è¡Œå¤šè½®é‡‡æ ·ï¼Œè®°å½•ç»“æ„é”šç‚¹ä¸è§’è‰²çŠ¶æ€ä¿¡æ¯
    """
    sampling_log = []
    for temp in temperature_list:
        version = f"{base_version_prefix}_{normalize(topic)}_T{str(temp).replace('.', '')}"
        print(f"\nğŸŒ¡ï¸ Generating: topic={topic}, style={style}, temperature={temp} â†’ version: {version}")

        # è°ƒç”¨ä¸»æµç¨‹
        run_story_pipeline(
            version=version,
            reorder_mode="linear",
            use_cache=False,
            topic=topic,
            style=style,
            behavior_model="claude-sonnet-4-20250514"
        )

        # æå–é”šç‚¹ä¸çŠ¶æ€ä¿¡æ¯
        output_dir = os.path.join(output_root, version)
        anchor_count, avg_state_count = extract_anchor_and_behavior_info(output_dir)

        sampling_log.append({
            "version": version,
            "temperature": temp,
            "topic": topic,
            "style": style,
            "anchor_count": anchor_count,
            "avg_states_per_role": avg_state_count
        })

    # ä¿å­˜é‡‡æ ·è®°å½•æ—¥å¿—
    os.makedirs(output_root, exist_ok=True)
    log_file = os.path.join(output_root, log_path)
    with open(log_file, "w", encoding="utf-8") as f:
        json.dump(sampling_log, f, ensure_ascii=False, indent=2)
    print(f"\næ‰€æœ‰ç‰ˆæœ¬ç”Ÿæˆå®Œæˆï¼Œé‡‡æ ·æ—¥å¿—å·²ä¿å­˜è‡³ {log_file}")


# âœ… ç¤ºä¾‹ä½¿ç”¨ï¼ˆå¯æ³¨é‡Šï¼‰
if __name__ == "__main__":
    run_montecarlo_generation_v2(
        topic="ç°å§‘å¨˜",
        style="å¥‡å¹»ç«¥è¯",
        temperature_list=[0.3, 0.7, 1.0]
    )

