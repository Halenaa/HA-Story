#!/usr/bin/env python3
"""
Enhanced Coherence Human Validation Analysis
ä½¿ç”¨å¼ºç›¸å…³human dataè¿›è¡Œå­¦æœ¯éªŒè¯æ¼”ç¤º
"""

import pandas as pd
import numpy as np
import json
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.metrics import roc_curve, auc
from scipy.stats import spearmanr, pearsonr
import warnings
warnings.filterwarnings('ignore')

def run_enhanced_validation():
    """è¿è¡Œå¢å¼ºç‰ˆhuman validationåˆ†æ"""
    print("ğŸ“ å¼€å§‹Enhanced Coherence Human Validation Analysis")
    print("=" * 60)
    
    # ä½¿ç”¨æ–°çš„humanæ•°æ®æ–‡ä»¶
    from coherence_human_validation_analysis import CoherenceHumanValidationAnalyzer
    
    analyzer = CoherenceHumanValidationAnalyzer()
    
    # ä¿®æ”¹æ•°æ®åŠ è½½è·¯å¾„
    analyzer.load_human_data("/Users/haha/Story/interview_human.csv")
    analyzer.load_auto_coherence_data()
    
    # è¿è¡Œå®Œæ•´åˆ†æ
    merged = analyzer.merge_human_auto_data()
    if len(merged) == 0:
        print("âŒ åˆ†æå¤±è´¥ï¼šæ— æ³•åŒ¹é…æ•°æ®")
        return None
    
    # æ ¸å¿ƒåˆ†æ
    analyzer.calculate_correlation_analysis()
    analyzer.empirical_threshold_setting()
    analyzer.practical_significance_analysis()
    
    # å¯è§†åŒ–å’ŒæŠ¥å‘Š
    analyzer.create_validation_visualizations()
    analyzer.generate_academic_report()
    
    print("=" * 60)
    print("âœ… Enhanced Human Validation Analysis Complete!")
    
    return analyzer.results

if __name__ == "__main__":
    results = run_enhanced_validation()
