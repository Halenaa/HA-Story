#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æå–æ‰€æœ‰åˆ†æžæ•°æ®å’Œè¾“å‡ºç»“æžœ
"""

import json
import pandas as pd
from datetime import datetime
from pathlib import Path
import os

def extract_all_data():
    """æå–æ‰€æœ‰æ•°æ®å’Œåˆ†æžç»“æžœ"""
    
    content_lines = []
    content_lines.append('# ðŸ“Š é—®å·å®žéªŒæ•°æ®åˆ†æž - å®Œæ•´æ•°æ®é›†åˆ')
    content_lines.append(f'**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")}')
    content_lines.append('**æ•°æ®æ¥æº**: åŽŸå§‹é—®å· + åˆ†æžç»“æžœ + Notebookè¾“å‡º')
    content_lines.append('=' * 80)
    content_lines.append('')

    # 1. è¯»å–åŽŸå§‹é—®å·æ•°æ®
    print('ðŸ“– è¯»å–åŽŸå§‹é—®å·æ•°æ®...')
    try:
        df_raw = pd.read_csv('Interview.csv')
        content_lines.append('# ðŸ“„ ä¸€ã€åŽŸå§‹é—®å·æ•°æ® (Interview.csv)')
        content_lines.append('')
        content_lines.append(f'**æ•°æ®è§„æ¨¡**: {df_raw.shape[0]}è¡Œå‚ä¸Žè€… Ã— {df_raw.shape[1]}åˆ—æ•°æ®')
        content_lines.append('')
        
        content_lines.append('## ðŸ” æ•°æ®é¢„è§ˆ (å‰5è¡Œ):')
        content_lines.append('```')
        content_lines.append(df_raw.head().to_string())
        content_lines.append('```')
        content_lines.append('')
        
        content_lines.append('## ðŸ“‹ æ‰€æœ‰åˆ—å:')
        content_lines.append('```')
        for i, col in enumerate(df_raw.columns):
            content_lines.append(f'{i+1:2d}. {col}')
        content_lines.append('```')
        content_lines.append('')
        
        # è¯†åˆ«å…³é”®æ•°æ®
        story_cols = [col for col in df_raw.columns if 'Story' in col]
        rating_cols = [col for col in df_raw.columns if any(keyword in col.lower() for keyword in ['coherent', 'emotional', 'quality', 'creative', 'fluency', 'structural', 'character'])]
        ranking_cols = [col for col in df_raw.columns if 'ranking' in col.lower()]
        
        content_lines.append('## ðŸ“Š æ•°æ®ç»“æž„åˆ†æž:')
        content_lines.append('```')
        content_lines.append(f'å‚ä¸Žè€…æ•°é‡: {len(df_raw)}')
        content_lines.append(f'æ•…äº‹ç›¸å…³åˆ—: {len(story_cols)}ä¸ª {story_cols}')
        content_lines.append(f'è¯„åˆ†ç›¸å…³åˆ—: {len(rating_cols)}ä¸ª')
        content_lines.append(f'æŽ’åç›¸å…³åˆ—: {len(ranking_cols)}ä¸ª')
        content_lines.append('```')
        content_lines.append('')
        
        # æ˜¾ç¤ºæ•…äº‹é…ç½®åˆ†å¸ƒ
        if story_cols:
            content_lines.append('## ðŸŽ¯ æ•…äº‹é…ç½®åˆ†å¸ƒ:')
            content_lines.append('```')
            for col in story_cols:
                unique_vals = df_raw[col].value_counts()
                content_lines.append(f'\n{col}:')
                for val, count in unique_vals.items():
                    content_lines.append(f'  {val}: {count}ä¸ªå‚ä¸Žè€…')
            content_lines.append('```')
            content_lines.append('')
        
        print(f'âœ… åŽŸå§‹æ•°æ®: {df_raw.shape[0]}x{df_raw.shape[1]}')
        
    except Exception as e:
        content_lines.append(f'âŒ æ— æ³•è¯»å–åŽŸå§‹æ•°æ®: {e}')
        content_lines.append('')
        print(f'âŒ åŽŸå§‹æ•°æ®è¯»å–å¤±è´¥: {e}')

    # 2. è¯»å–æ‰€æœ‰å¤„ç†åŽçš„æ•°æ®
    print('ðŸ“Š è¯»å–åˆ†æžç»“æžœæ•°æ®...')
    content_lines.append('# ðŸ“Š äºŒã€åˆ†æžç»“æžœæ•°æ®æ–‡ä»¶')
    content_lines.append('')
    
    processed_dir = Path('data/processed')
    if processed_dir.exists():
        csv_files = list(processed_dir.glob('*.csv'))
        csv_files.sort()  # æŒ‰æ–‡ä»¶åæŽ’åº
        
        content_lines.append(f'**å¤„ç†åŽæ–‡ä»¶æ€»æ•°**: {len(csv_files)}ä¸ª')
        content_lines.append('')
        
        for i, csv_file in enumerate(csv_files, 1):
            try:
                df = pd.read_csv(csv_file)
                
                content_lines.append(f'## ðŸ“‹ {i}. {csv_file.name}')
                content_lines.append(f'**æ–‡ä»¶å¤§å°**: {csv_file.stat().st_size:,} bytes')
                content_lines.append(f'**æ•°æ®ç»´åº¦**: {df.shape[0]}è¡Œ Ã— {df.shape[1]}åˆ—')
                content_lines.append('')
                
                # åˆ—å
                content_lines.append('**åˆ—ååˆ—è¡¨**:')
                content_lines.append('```')
                content_lines.append(' | '.join(df.columns))
                content_lines.append('```')
                content_lines.append('')
                
                # æ•°æ®é¢„è§ˆ
                if len(df) > 0:
                    max_rows = min(15, len(df))  # æœ€å¤šæ˜¾ç¤º15è¡Œ
                    content_lines.append(f'**æ•°æ®é¢„è§ˆ (å‰{max_rows}è¡Œ)**:')
                    content_lines.append('```')
                    content_lines.append(df.head(max_rows).to_string())
                    content_lines.append('```')
                    content_lines.append('')
                    
                    # æ•°å€¼ç»Ÿè®¡
                    numeric_cols = df.select_dtypes(include=['number']).columns
                    if len(numeric_cols) > 0:
                        content_lines.append('**æ•°å€¼åˆ—ç»Ÿè®¡**:')
                        content_lines.append('```')
                        content_lines.append(df[numeric_cols].describe().to_string())
                        content_lines.append('```')
                        content_lines.append('')
                    
                    # åˆ†ç±»ç»Ÿè®¡
                    categorical_cols = df.select_dtypes(include=['object']).columns
                    if len(categorical_cols) > 0 and len(categorical_cols) <= 3:  # åªæ˜¾ç¤ºå°‘æ•°åˆ†ç±»åˆ—
                        content_lines.append('**åˆ†ç±»åˆ—åˆ†å¸ƒ**:')
                        content_lines.append('```')
                        for col in categorical_cols:
                            if df[col].nunique() <= 20:  # åªæ˜¾ç¤ºç±»åˆ«ä¸å¤ªå¤šçš„åˆ—
                                counts = df[col].value_counts()
                                content_lines.append(f'\n{col}:')
                                for val, count in counts.head(10).items():
                                    content_lines.append(f'  {val}: {count}')
                        content_lines.append('```')
                        content_lines.append('')
                
                content_lines.append('---')
                content_lines.append('')
                print(f'âœ… {csv_file.name}: {df.shape[0]}x{df.shape[1]}')
                
            except Exception as e:
                content_lines.append(f'âŒ è¯»å– {csv_file.name} å¤±è´¥: {e}')
                content_lines.append('')
                print(f'âŒ {csv_file.name} è¯»å–å¤±è´¥: {e}')
    else:
        content_lines.append('âš ï¸ data/processed/ ç›®å½•ä¸å­˜åœ¨')
        content_lines.append('')
    
    # 3. ä»Žnotebookæå–æœ‰æ„ä¹‰çš„è¾“å‡º
    print('ðŸ“ æå–notebookè¾“å‡º...')
    try:
        with open('interview_analysis_v2.ipynb', 'r', encoding='utf-8') as f:
            notebook = json.load(f)
        
        content_lines.append('# ðŸ”§ ä¸‰ã€Notebookæ‰§è¡Œè¾“å‡º')
        content_lines.append('')
        
        output_count = 0
        for i, cell in enumerate(notebook['cells']):
            if cell['cell_type'] == 'code':
                outputs = cell.get('outputs', [])
                if outputs:
                    # èŽ·å–æ ‡é¢˜
                    source = cell.get('source', [])
                    title = 'Code Cell'
                    if source and isinstance(source, list):
                        first_line = source[0].strip()
                        if first_line.startswith('#'):
                            title = first_line.replace('#', '').strip()[:80]
                    
                    content_lines.append(f'## ðŸ“‹ Cell {i}: {title}')
                    content_lines.append('')
                    
                    for output in outputs:
                        if output.get('output_type') == 'stream':
                            text = ''.join(output.get('text', []))
                            if text.strip():
                                content_lines.append('```')
                                content_lines.append(text.strip())
                                content_lines.append('```')
                                content_lines.append('')
                        elif output.get('output_type') == 'error':
                            content_lines.append('âŒ **æ‰§è¡Œé”™è¯¯**:')
                            content_lines.append('```')
                            error_text = '\n'.join(output.get('traceback', []))
                            content_lines.append(error_text)
                            content_lines.append('```')
                            content_lines.append('')
                    
                    content_lines.append('---')
                    content_lines.append('')
                    output_count += 1
        
        content_lines.append(f'**æ€»è®¡**: æ‰¾åˆ° {output_count} ä¸ªæœ‰è¾“å‡ºçš„cells')
        content_lines.append('')
        print(f'âœ… Notebook: {output_count}ä¸ªè¾“å‡ºcells')
        
    except Exception as e:
        content_lines.append(f'âŒ æ— æ³•è¯»å–notebook: {e}')
        content_lines.append('')
        print(f'âŒ Notebookè¯»å–å¤±è´¥: {e}')
    
    # 4. ç”Ÿæˆæ€»ç»“
    content_lines.append('# ðŸ“‹ å››ã€æ•°æ®é›†åˆæ€»ç»“')
    content_lines.append('')
    content_lines.append(f'- **åŽŸå§‹æ•°æ®**: Interview.csv')
    content_lines.append(f'- **å¤„ç†åŽæ–‡ä»¶**: {len(list(Path("data/processed").glob("*.csv")) if Path("data/processed").exists() else [])}ä¸ªCSVæ–‡ä»¶')
    content_lines.append(f'- **åˆ†æžè¾“å‡º**: Notebookæ‰§è¡Œç»“æžœ')
    content_lines.append(f'- **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")}')
    content_lines.append('')
    content_lines.append('ðŸŽ¯ **è¿™ä¸ªæ–‡ä»¶åŒ…å«äº†å®Œæ•´çš„æ•°æ®æ”¯æ’‘ï¼Œå¯ä»¥ç›´æŽ¥åˆ†äº«ç»™å…¶ä»–äººæŸ¥çœ‹ï¼**')
    content_lines.append('')
    
    return '\n'.join(content_lines)

if __name__ == '__main__':
    try:
        print('ðŸš€ å¼€å§‹æå–æ‰€æœ‰æ•°æ®...')
        full_content = extract_all_data()
        
        # ä¿å­˜æ–‡ä»¶
        output_file = 'ðŸ“Š å®Œæ•´æ•°æ®é›†åˆ_æ‰€æœ‰è¾“å‡º.md'
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(full_content)
        
        # æ˜¾ç¤ºç»“æžœ
        size = os.path.getsize(output_file)
        lines = len(full_content.split('\n'))
        
        print(f'\nðŸŽ‰ æ•°æ®é›†åˆç”Ÿæˆå®Œæˆï¼')
        print(f'ðŸ“ æ–‡ä»¶: {output_file}')
        print(f'ðŸ“Š å¤§å°: {size:,} bytes')
        print(f'ðŸ“„ è¡Œæ•°: {lines:,} è¡Œ')
        print('')
        print('âœ… æ–‡ä»¶åŒ…å«:')
        print('   ðŸ“‹ åŽŸå§‹é—®å·æ•°æ® + åˆ—å + æ•°æ®é¢„è§ˆ')
        print('   ðŸ“Š æ‰€æœ‰10ä¸ªåˆ†æžç»“æžœCSVæ–‡ä»¶çš„å®Œæ•´å†…å®¹')
        print('   ðŸ”§ Notebookä¸­çš„å®žé™…æ‰§è¡Œè¾“å‡º')
        print('   ðŸ“ˆ è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯å’Œæ•°æ®åˆ†å¸ƒ')
        print('')
        print('ðŸŽ¯ è¿™ä¸ªæ–‡ä»¶æœ‰å®Œæ•´çš„æ•°æ®æ”¯æ’‘ï¼Œå¯ä»¥ç›´æŽ¥åˆ†äº«ï¼')
        
    except Exception as e:
        print(f'âŒ ç”Ÿæˆå¤±è´¥: {e}')
        import traceback
        traceback.print_exc()
