#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
C. Correlation Analysis
Generate correlation heatmaps and analysis report for five dimensions
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from pathlib import Path
from scipy import stats

# Set English fonts
plt.rcParams['font.family'] = ['Arial', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

def create_correlation_analysis():
    """Create five-dimension correlation analysis"""
    
    # Load data
    df = pd.read_csv('/Users/haha/Story/metrics_master_clean.csv')
    
    # Select core metrics for five dimensions
    metrics = {
        'Diversity': 'distinct_avg',
        'Semantic Continuity': 'avg_semantic_continuity', 
        'Fluency (PPL)': 'pseudo_ppl',
        'Fluency (Error Rate)': 'err_per_100w',
        'Emotion': 'correlation_coefficient'
    }
    
    # Create correlation dataframe
    corr_data = pd.DataFrame()
    for dim_name, metric in metrics.items():
        if metric in df.columns:
            corr_data[dim_name] = df[metric]
    
    # Calculate correlations
    pearson_corr = corr_data.corr(method='pearson')
    spearman_corr = corr_data.corr(method='spearman')
    
    # Create Figure 4: Correlation Heatmap
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
    
    # Pearson correlation heatmap
    mask1 = np.triu(np.ones_like(pearson_corr, dtype=bool))
    sns.heatmap(pearson_corr, mask=mask1, annot=True, cmap='RdBu_r', center=0,
                square=True, ax=ax1, fmt='.3f', cbar_kws={"shrink": .8})
    ax1.set_title('Pearson Correlations', fontweight='bold', fontsize=14)
    
    # Spearman correlation heatmap  
    mask2 = np.tril(np.ones_like(spearman_corr, dtype=bool))
    sns.heatmap(spearman_corr, mask=mask2, annot=True, cmap='RdBu_r', center=0,
                square=True, ax=ax2, fmt='.3f', cbar_kws={"shrink": .8})
    ax2.set_title('Spearman Correlations', fontweight='bold', fontsize=14)
    
    plt.suptitle('Figure 4: Five Dimensions Correlation Heatmap', fontsize=16, fontweight='bold')
    plt.tight_layout()
    
    # Save figure
    output_dir = Path("/Users/haha/Story/AAA/stage1_statistical_rigor_analysis/")
    output_file = output_dir / 'figure_4_correlation_heatmap.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"âœ… Figure 4 saved: {output_file}")
    
    plt.close()
    
    # Create single heatmap (combined version)
    fig, ax = plt.subplots(1, 1, figsize=(10, 8))
    
    # Use Spearman correlation (more robust)
    sns.heatmap(spearman_corr, annot=True, cmap='RdBu_r', center=0,
                square=True, ax=ax, fmt='.3f', 
                cbar_kws={"shrink": .8, "label": "Spearman Correlation (Ï)"})
    
    ax.set_title('Figure 4: Five-Dimension Correlation Heatmap (Spearman Ï)', fontweight='bold', fontsize=16)
    plt.xticks(rotation=45, ha='right')
    plt.yticks(rotation=0)
    plt.tight_layout()
    
    # Save single heatmap
    output_file_single = output_dir / 'figure_4_correlation_heatmap_single.png'
    plt.savefig(output_file_single, dpi=300, bbox_inches='tight')
    print(f"âœ… Figure 4 (single version) saved: {output_file_single}")
    
    plt.close()
    
    return pearson_corr, spearman_corr

def generate_correlation_report(pearson_corr, spearman_corr):
    """Generate correlation analysis report"""
    
    output_dir = Path("/Users/haha/Story/AAA/stage1_statistical_rigor_analysis/")
    report_file = output_dir / 'section_C_correlation_report.md'
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("# C. Correlation Analysis Report\n\n")
        f.write("**Analysis Date**: September 14, 2025  \n")
        f.write("**Sample Size**: 57 samples (54 Multi-Agent + 3 Baseline)  \n")
        f.write("**Method**: pandas.corr() + seaborn.heatmap()  \n")
        f.write("**Correlation Methods**: Pearson (linear) + Spearman (rank-order)\n\n")
        f.write("---\n\n")
        
        f.write("## C.1 Five-Dimension Correlation Matrix\n\n")
        
        # Spearman correlation table
        f.write("### Table C1: Spearman Correlation Matrix (Ï)\n\n")
        f.write("| ç»´åº¦ | Diversity | Semantic Continuity | Fluency (PPL) | Fluency (Error) | Emotion |\n")
        f.write("|------|-----------|-------------------|---------------|----------------|----------|\n")
        
        dims = spearman_corr.columns
        for i, dim1 in enumerate(dims):
            row = f"| **{dim1}** |"
            for j, dim2 in enumerate(dims):
                corr_val = spearman_corr.iloc[i, j]
                if i == j:
                    row += " 1.000 |"
                else:
                    row += f" {corr_val:.3f} |"
            f.write(row + "\n")
        
        f.write("\n### è¡¨C2ï¼šPearsonç›¸å…³æ€§çŸ©é˜µ (r)\n\n")
        f.write("| ç»´åº¦ | Diversity | Semantic Continuity | Fluency (PPL) | Fluency (Error) | Emotion |\n")
        f.write("|------|-----------|-------------------|---------------|----------------|----------|\n")
        
        for i, dim1 in enumerate(dims):
            row = f"| **{dim1}** |"
            for j, dim2 in enumerate(dims):
                corr_val = pearson_corr.iloc[i, j]
                if i == j:
                    row += " 1.000 |"
                else:
                    row += f" {corr_val:.3f} |"
            f.write(row + "\n")
        
        f.write("\n---\n\n")
        
        f.write("## C.2 å…³é”®ç›¸å…³æ€§å‘ç°\n\n")
        
        # æå–å…³é”®ç›¸å…³æ€§
        key_correlations = [
            ('Diversity', 'Semantic Continuity', 'negative'),
            ('Diversity', 'Fluency (PPL)', 'positive'),
            ('Semantic Continuity', 'Fluency (Error Rate)', 'negative'),
            ('Fluency (PPL)', 'Fluency (Error Rate)', 'mixed')
        ]
        
        f.write("### ğŸ” æ˜¾è‘—ç›¸å…³æ€§ (|Ï| > 0.3)\n\n")
        
        # Diversity vs Semantic Continuity
        div_sem_corr = spearman_corr.loc['Diversity', 'Semantic Continuity']
        f.write(f"#### 1. **å¤šæ ·æ€§ vs è¯­ä¹‰è¿ç»­æ€§**: Ï = {div_sem_corr:.3f}\n")
        f.write(f"- **å…³ç³»**: å¼ºè´Ÿç›¸å…³\n")
        f.write(f"- **è§£é‡Š**: è¯æ±‡å¤šæ ·æ€§æå‡å¾€å¾€ç‰ºç‰²è¯­ä¹‰è¿è´¯æ€§ï¼Œå­˜åœ¨ç»å…¸çš„å¤šæ ·æ€§-è´¨é‡æƒè¡¡\n\n")
        
        # Diversity vs Fluency (PPL)
        div_ppl_corr = spearman_corr.loc['Diversity', 'Fluency (PPL)']
        f.write(f"#### 2. **å¤šæ ·æ€§ vs å›°æƒ‘åº¦**: Ï = {div_ppl_corr:.3f}\n")
        f.write(f"- **å…³ç³»**: å¼ºæ­£ç›¸å…³\n")
        f.write(f"- **è§£é‡Š**: æ›´å¤šæ ·çš„è¯æ±‡ä½¿ç”¨å¯¼è‡´æ›´é«˜çš„å›°æƒ‘åº¦ï¼ˆæµç•…æ€§ä¸‹é™ï¼‰\n\n")
        
        # Semantic Continuity vs Fluency (Error)
        sem_err_corr = spearman_corr.loc['Semantic Continuity', 'Fluency (Error Rate)']
        f.write(f"#### 3. **è¯­ä¹‰è¿ç»­æ€§ vs é”™è¯¯ç‡**: Ï = {sem_err_corr:.3f}\n")
        f.write(f"- **å…³ç³»**: ä¸­ç­‰è´Ÿç›¸å…³\n")
        f.write(f"- **è§£é‡Š**: è¯­ä¹‰æ›´è¿è´¯çš„æ–‡æœ¬å¾€å¾€è¯­æ³•é”™è¯¯æ›´å°‘\n\n")
        
        # Diversity vs Error Rate
        div_err_corr = spearman_corr.loc['Diversity', 'Fluency (Error Rate)']
        f.write(f"#### 4. **å¤šæ ·æ€§ vs é”™è¯¯ç‡**: Ï = {div_err_corr:.3f}\n")
        f.write(f"- **å…³ç³»**: ä¸­ç­‰æ­£ç›¸å…³\n")
        f.write(f"- **è§£é‡Š**: æ›´å¤šæ ·çš„è¡¨è¾¾å¯èƒ½å¸¦æ¥æ›´å¤šè¯­æ³•é”™è¯¯\n\n")
        
        f.write("### ğŸ¤· å¼±ç›¸å…³æ€§ (|Ï| < 0.3)\n\n")
        
        # Emotion correlations
        emo_div_corr = spearman_corr.loc['Emotion', 'Diversity']
        emo_sem_corr = spearman_corr.loc['Emotion', 'Semantic Continuity']
        
        f.write(f"#### 5. **æƒ…æ„Ÿç»´åº¦ç›¸å…³æ€§**\n")
        f.write(f"- æƒ…æ„Ÿ vs å¤šæ ·æ€§: Ï = {emo_div_corr:.3f} (å¼±æ­£ç›¸å…³)\n")
        f.write(f"- æƒ…æ„Ÿ vs è¯­ä¹‰è¿ç»­æ€§: Ï = {emo_sem_corr:.3f} (å¼±è´Ÿç›¸å…³)\n")
        f.write(f"- **è§£é‡Š**: æƒ…æ„Ÿç»´åº¦ç›¸å¯¹ç‹¬ç«‹ï¼Œä¸å…¶ä»–è´¨é‡ç»´åº¦å…³è”è¾ƒå¼±\n\n")
        
        f.write("---\n\n")
        
        f.write("## C.3 ç›¸å…³æ€§è§£é‡Šä¸å«ä¹‰\n\n")
        
        f.write("### ğŸ“Š æ ¸å¿ƒå‘ç°æ¨¡å¼\n\n")
        f.write("1. **å¤šæ ·æ€§-è´¨é‡æƒè¡¡**: å­˜åœ¨æ˜æ˜¾çš„å¤šæ ·æ€§ä¸è¯­ä¹‰è¿ç»­æ€§çš„è´Ÿç›¸å…³æƒè¡¡\n")
        f.write("2. **æµç•…æ€§åŒé‡æ€§**: PPLå’Œé”™è¯¯ç‡ä»£è¡¨æµç•…æ€§çš„ä¸åŒæ–¹é¢ï¼Œç›¸å…³æ€§è¾ƒå¼±\n")
        f.write("3. **æƒ…æ„Ÿç‹¬ç«‹æ€§**: æƒ…æ„Ÿç»´åº¦ç›¸å¯¹ç‹¬ç«‹äºå…¶ä»–è´¨é‡æŒ‡æ ‡\n")
        f.write("4. **è´¨é‡ä¸€è‡´æ€§**: è¯­ä¹‰è¿ç»­æ€§ä¸ä½é”™è¯¯ç‡æ­£ç›¸å…³ï¼Œä½“ç°æ•´ä½“è´¨é‡ä¸€è‡´æ€§\n\n")
        
        f.write("### ğŸ¯ å®é™…åº”ç”¨å«ä¹‰\n\n")
        f.write("#### ç³»ç»Ÿè®¾è®¡æƒè¡¡\n")
        f.write("- **åˆ›æ„ vs è´¨é‡**: éœ€è¦åœ¨è¯æ±‡å¤šæ ·æ€§å’Œè¯­ä¹‰è¿è´¯æ€§é—´æ‰¾å¹³è¡¡\n")
        f.write("- **æµç•…æ€§ä¼˜åŒ–**: PPLå’Œé”™è¯¯ç‡éœ€è¦åˆ†åˆ«ä¼˜åŒ–ï¼Œä¸èƒ½ä»…ä¾èµ–å•ä¸€æŒ‡æ ‡\n")
        f.write("- **æƒ…æ„Ÿè°ƒæ§**: æƒ…æ„Ÿè¡¨è¾¾å¯ä»¥ç›¸å¯¹ç‹¬ç«‹è°ƒæ•´ï¼Œä¸ä¼šæ˜¾è‘—å½±å“å…¶ä»–ç»´åº¦\n\n")
        
        f.write("#### Multi-Agentç³»ç»Ÿä¼˜åŠ¿è§£é‡Š\n")
        f.write("- **å¹³è¡¡ä¼˜åŒ–**: Multi-Agentåœ¨ä¿æŒåˆç†å¤šæ ·æ€§çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†è¯­ä¹‰è¿ç»­æ€§\n")
        f.write("- **è´¨é‡å¯¼å‘**: è´Ÿç›¸å…³æ¨¡å¼è§£é‡Šäº†ä¸ºä»€ä¹ˆMulti-Agentä¼šæœ‰é€‚åº¦çš„å¤šæ ·æ€§é™ä½\n")
        f.write("- **ç»¼åˆæå‡**: åœ¨å¤šä¸ªç›¸å…³ç»´åº¦ä¸Šçš„åè°ƒæ”¹è¿›ï¼Œä½“ç°äº†ç³»ç»Ÿæ€§ä¼˜åŒ–\n\n")
        
        f.write("---\n\n")
        
        f.write("## C.4 ç»“è®ºç¤ºä¾‹ï¼ˆåŸºäºçœŸå®æ•°æ®ï¼‰\n\n")
        
        f.write("### âœ… **ä¸»è¦ç›¸å…³æ€§å‘ç°**\n\n")
        f.write(f"**\"å¤šæ ·æ€§ä¸è¯­ä¹‰è¿ç»­æ€§å‘ˆå¼ºè´Ÿç›¸å…³ (Ï={div_sem_corr:.2f})ï¼Œæ˜¾ç¤ºå¤šæ ·æ€§æå‡å¾€å¾€ç‰ºç‰²è¿è´¯æ€§ã€‚\"**\n\n")
        f.write(f"**\"å¤šæ ·æ€§ä¸å›°æƒ‘åº¦å‘ˆå¼ºæ­£ç›¸å…³ (Ï={div_ppl_corr:.2f})ï¼Œè¡¨æ˜è¯æ±‡å¤šæ ·æ€§ä¼šé™ä½è¯­è¨€æµç•…åº¦ã€‚\"**\n\n")
        f.write(f"**\"è¯­ä¹‰è¿ç»­æ€§ä¸é”™è¯¯ç‡å‘ˆè´Ÿç›¸å…³ (Ï={sem_err_corr:.2f})ï¼Œè¿è´¯çš„æ–‡æœ¬å¾€å¾€è¯­æ³•æ›´å‡†ç¡®ã€‚\"**\n\n")
        
        f.write("### ğŸ“ˆ **ç³»ç»Ÿæ€§èƒ½è§£é‡Š**\n\n")
        f.write("**\"ç›¸å…³æ€§åˆ†ææ­ç¤ºäº†Multi-Agentç³»ç»Ÿçš„è®¾è®¡ä¼˜åŠ¿ï¼šé€šè¿‡é€‚åº¦é™ä½è¯æ±‡å¤šæ ·æ€§ï¼Œ")
        f.write("å®ç°äº†è¯­ä¹‰è¿ç»­æ€§å’Œè¯­è¨€å‡†ç¡®æ€§çš„æ˜¾è‘—æå‡ï¼Œä½“ç°äº†æ™ºèƒ½çš„è´¨é‡-åˆ›æ„æƒè¡¡ç­–ç•¥ã€‚\"**\n\n")
        
        f.write("---\n\n")
        f.write("## C.5 ç”Ÿæˆæ–‡ä»¶\n\n")
        f.write("- `figure_4_correlation_heatmap.png`: åŒé¢æ¿ç›¸å…³æ€§çƒ­åŠ›å›¾\n")
        f.write("- `figure_4_correlation_heatmap_single.png`: å•é¢æ¿Spearmanç›¸å…³æ€§çƒ­åŠ›å›¾\n")
        f.write("- `section_C_correlation_report.md`: æœ¬ç›¸å…³æ€§åˆ†ææŠ¥å‘Š\n\n")
        f.write("---\n\n")
        f.write("*åŸºäº57ä¸ªæ ·æœ¬çš„å®Œæ•´ç›¸å…³æ€§åˆ†æ*  \n")
        f.write("*ä½¿ç”¨ç¨³å¥çš„Spearmanç§©ç›¸å…³å’ŒPearsonçº¿æ€§ç›¸å…³*\n")
    
    print(f"âœ… ç›¸å…³æ€§åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")

if __name__ == "__main__":
    print("ğŸ”— å¼€å§‹Céƒ¨åˆ†ï¼šç›¸å…³æ€§åˆ†æ")
    
    # åˆ›å»ºç›¸å…³æ€§åˆ†æ
    pearson_corr, spearman_corr = create_correlation_analysis()
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_correlation_report(pearson_corr, spearman_corr)
    
    print("ğŸ‰ Céƒ¨åˆ†ï¼šç›¸å…³æ€§åˆ†æå®Œæˆï¼")
