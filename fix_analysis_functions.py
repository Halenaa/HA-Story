#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®æ­£é—®å·åˆ†æå‡½æ•° - å¤„ç†æ·±åº¦è¯„ä»·vsæµ…åº¦è¯„ä»·çš„ä¸å¹³è¡¡é—®é¢˜
Fix Questionnaire Analysis Functions - Handle Deep vs Shallow Evaluation Imbalance

ä¸»è¦ä¿®æ­£ï¼š
1. Configçº§åˆ«åˆ†æ - åŒºåˆ†Group A-F(æ·±åº¦9æ¬¡) vs Group G(æµ…åº¦1æ¬¡)
2. Storyçº§åˆ«åˆ†æ - å¤„ç†3äººvs4äººè¯„ä»·çš„ä¸ç­‰æƒé‡
3. ç§å­ç¨³å®šæ€§åˆ†æ - è€ƒè™‘ç»„é—´å·®å¼‚
4. æ··åˆæ•ˆåº”æ¨¡å‹ - æ·»åŠ ç»„åˆ«æ•ˆåº”
"""

import pandas as pd
import numpy as np
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

def identify_group_membership(long_table_df):
    """
    æ ¹æ®æ¯ä¸ªraterè¯„ä»·çš„story patternè¯†åˆ«å…¶æ‰€å±ç»„åˆ«
    
    Returns:
        dict: {rater_id: {'group_type': 'deep'/'shallow', 'pattern': '...'}}
    """
    rater_groups = {}
    
    for rater_id in long_table_df['rater_id'].unique():
        rater_data = long_table_df[long_table_df['rater_id'] == rater_id]
        
        # è·å–è¯¥raterè¯„ä»·çš„ébaselineæ•…äº‹
        exp_stories = rater_data[rater_data['config'] != 'baseline']['story_id'].unique()
        exp_configs = rater_data[rater_data['config'] != 'baseline']['config'].unique()
        
        # åˆ¤æ–­è¯„ä»·æ¨¡å¼
        if len(exp_configs) == 1 and len(exp_stories) == 3:
            # å•ä¸€configçš„3ä¸ªseeds - æ·±åº¦è¯„ä»·ç»„ (Group A-F)
            rater_groups[rater_id] = {
                'group_type': 'deep',
                'pattern': f"single_config_{exp_configs[0]}",
                'n_configs': 1,
                'n_stories': 3
            }
        elif len(exp_configs) > 1:
            # å¤šä¸ªconfigsçš„å•ä¸€seeds - æµ…åº¦è¯„ä»·ç»„ (Group G)
            rater_groups[rater_id] = {
                'group_type': 'shallow', 
                'pattern': f"multi_config_{len(exp_configs)}",
                'n_configs': len(exp_configs),
                'n_stories': len(exp_stories)
            }
        else:
            # å…¶ä»–å¼‚å¸¸æƒ…å†µ
            rater_groups[rater_id] = {
                'group_type': 'unknown',
                'pattern': f"unknown_{len(exp_configs)}c_{len(exp_stories)}s",
                'n_configs': len(exp_configs),
                'n_stories': len(exp_stories)
            }
    
    return rater_groups

def create_corrected_config_aggregation(long_table_df):
    """
    ä¿®æ­£ç‰ˆConfigçº§åˆ«èšåˆ - è€ƒè™‘æ·±åº¦vsæµ…åº¦è¯„ä»·çš„è´¨é‡å·®å¼‚
    
    Args:
        long_table_df: é•¿æ ¼å¼æ•°æ®è¡¨
        
    Returns:
        pd.DataFrame: ä¿®æ­£åçš„configèšåˆæ•°æ®
    """
    # 1. è¯†åˆ«ç»„åˆ«
    rater_groups = identify_group_membership(long_table_df)
    
    # 2. ä¸ºæ•°æ®æ·»åŠ ç»„åˆ«æ ‡è¯†
    working_df = long_table_df.copy()
    working_df['group_type'] = working_df['rater_id'].map(
        lambda x: rater_groups.get(x, {}).get('group_type', 'unknown')
    )
    
    # 3. åˆ†å±‚èšåˆ
    results = []
    
    for config in working_df['config'].unique():
        if config == 'baseline':
            # Baselineä½¿ç”¨æ ‡å‡†èšåˆ
            config_data = working_df[working_df['config'] == config]
            for dimension in config_data['dimension'].unique():
                dim_data = config_data[config_data['dimension'] == dimension]
                
                results.append({
                    'config': config,
                    'structure': None,
                    'temperature': None,
                    'dimension': dimension,
                    'mean_score': dim_data['score'].mean(),
                    'corrected_mean': dim_data['score'].mean(),  # baselineæ— éœ€ä¿®æ­£
                    'std_score': dim_data['score'].std(),
                    'n_ratings': len(dim_data),
                    'n_deep_eval': len(dim_data),  # baselineå…¨ä¸ºæ·±åº¦è¯„ä»·
                    'n_shallow_eval': 0,
                    'eval_balance': 1.0,
                    'quality_score': 1.0  # baselineè´¨é‡åˆ†æ•°ä¸º1.0
                })
        else:
            # å®éªŒé…ç½®ä½¿ç”¨ä¿®æ­£èšåˆ
            config_data = working_df[working_df['config'] == config]
            
            for dimension in config_data['dimension'].unique():
                dim_data = config_data[config_data['dimension'] == dimension]
                
                # åˆ†ç¦»æ·±åº¦å’Œæµ…åº¦è¯„ä»·
                deep_data = dim_data[dim_data['group_type'] == 'deep']
                shallow_data = dim_data[dim_data['group_type'] == 'shallow']
                
                # è®¡ç®—ç»Ÿè®¡é‡
                n_deep = len(deep_data)
                n_shallow = len(shallow_data)
                total_n = n_deep + n_shallow
                
                if total_n == 0:
                    continue
                
                # è´¨é‡åŠ æƒèšåˆï¼ˆæ·±åº¦è¯„ä»·æƒé‡æ›´é«˜ï¼‰
                deep_weight = 0.8  # æ·±åº¦è¯„ä»·æƒé‡80%
                shallow_weight = 0.2  # æµ…åº¦è¯„ä»·æƒé‡20%
                
                # å½’ä¸€åŒ–æƒé‡
                actual_deep_prop = n_deep / total_n
                actual_shallow_prop = n_shallow / total_n
                
                if n_deep > 0 and n_shallow > 0:
                    # è´¨é‡åŠ æƒå‡å€¼
                    corrected_mean = (
                        deep_data['score'].mean() * deep_weight + 
                        shallow_data['score'].mean() * shallow_weight
                    )
                elif n_deep > 0:
                    corrected_mean = deep_data['score'].mean()
                else:
                    corrected_mean = shallow_data['score'].mean()
                
                # åŸå§‹ç­‰æƒé‡å‡å€¼
                raw_mean = dim_data['score'].mean()
                
                # æ•°æ®è´¨é‡åˆ†æ•°ï¼ˆæ·±åº¦è¯„ä»·æ¯”ä¾‹è¶Šé«˜è´¨é‡åˆ†æ•°è¶Šé«˜ï¼‰
                quality_score = actual_deep_prop * 0.9 + 0.1  # æœ€ä½0.1ï¼Œæœ€é«˜1.0
                
                results.append({
                    'config': config,
                    'structure': dim_data['structure'].iloc[0] if 'structure' in dim_data.columns else None,
                    'temperature': dim_data['temperature'].iloc[0] if 'temperature' in dim_data.columns else None,
                    'dimension': dimension,
                    'mean_score': raw_mean,  # åŸå§‹å‡å€¼
                    'corrected_mean': corrected_mean,  # è´¨é‡ä¿®æ­£å‡å€¼  
                    'std_score': dim_data['score'].std(),
                    'n_ratings': total_n,
                    'n_deep_eval': n_deep,
                    'n_shallow_eval': n_shallow,
                    'eval_balance': actual_deep_prop,
                    'quality_score': quality_score
                })
    
    return pd.DataFrame(results).round(3)

def create_corrected_story_aggregation(long_table_df):
    """
    ä¿®æ­£ç‰ˆStoryçº§åˆ«èšåˆ - å¤„ç†è¯„ä»·è€…æ•°é‡ä¸ç­‰çš„æƒé‡é—®é¢˜
    """
    rater_groups = identify_group_membership(long_table_df)
    working_df = long_table_df.copy()
    working_df['group_type'] = working_df['rater_id'].map(
        lambda x: rater_groups.get(x, {}).get('group_type', 'unknown')
    )
    
    results = []
    
    for story_id in working_df['story_id'].unique():
        story_data = working_df[working_df['story_id'] == story_id]
        
        for dimension in story_data['dimension'].unique():
            dim_data = story_data[story_data['dimension'] == dimension]
            
            # è®¡ç®—è¯„ä»·è€…æ„æˆ
            deep_raters = dim_data[dim_data['group_type'] == 'deep']['rater_id'].nunique()
            shallow_raters = dim_data[dim_data['group_type'] == 'shallow']['rater_id'].nunique()
            total_raters = dim_data['rater_id'].nunique()
            
            # æ ‡å‡†è¯¯ä¿®æ­£ï¼ˆè€ƒè™‘è¯„ä»·è€…æ•°é‡å·®å¼‚ï¼‰
            if total_raters > 1:
                # ä½¿ç”¨Besselä¿®æ­£
                corrected_std = dim_data['score'].std(ddof=1) * np.sqrt((total_raters - 1) / total_raters)
                std_error = corrected_std / np.sqrt(total_raters)
            else:
                corrected_std = 0
                std_error = np.inf
            
            results.append({
                'story_id': story_id,
                'config': dim_data['config'].iloc[0] if 'config' in dim_data.columns else None,
                'seed': dim_data['seed'].iloc[0] if 'seed' in dim_data.columns else None,
                'structure': dim_data['structure'].iloc[0] if 'structure' in dim_data.columns else None,
                'temperature': dim_data['temperature'].iloc[0] if 'temperature' in dim_data.columns else None,
                'dimension': dimension,
                'mean_score': dim_data['score'].mean(),
                'std_score': corrected_std,
                'std_error': std_error,
                'n_ratings': len(dim_data),
                'n_raters': total_raters,
                'n_deep_raters': deep_raters,
                'n_shallow_raters': shallow_raters,
                'rater_balance': deep_raters / total_raters if total_raters > 0 else 0,
                'reliability_weight': min(1.0, total_raters / 4.0)  # æƒé‡ï¼š4äººä¸ºæ»¡åˆ†
            })
    
    return pd.DataFrame(results).round(3)

def corrected_seed_stability_analysis(long_table_df, focus_dim='Overall Quality'):
    """
    ä¿®æ­£ç‰ˆç§å­ç¨³å®šæ€§åˆ†æ - è€ƒè™‘ç»„é—´æ•ˆåº”
    """
    from scipy.stats import levene, kruskal
    
    rater_groups = identify_group_membership(long_table_df)
    working_df = long_table_df.copy()
    working_df['group_type'] = working_df['rater_id'].map(
        lambda x: rater_groups.get(x, {}).get('group_type', 'unknown')
    )
    
    # ç­›é€‰ç›®æ ‡ç»´åº¦
    focus_data = working_df[
        (working_df['dimension'] == focus_dim) & 
        (working_df['config'] != 'baseline')
    ].copy()
    
    results = []
    
    for config in focus_data['config'].unique():
        config_data = focus_data[focus_data['config'] == config]
        
        # æŒ‰seedèšåˆï¼ˆè€ƒè™‘ç»„åˆ«æƒé‡ï¼‰
        seed_stats = []
        seed_groups = []  # ç”¨äºæ–¹å·®é½æ€§æ£€éªŒ
        
        for seed in config_data['seed'].unique():
            if pd.isna(seed):
                continue
                
            seed_data = config_data[config_data['seed'] == seed]
            
            # åˆ†ç»„ç»Ÿè®¡
            deep_scores = seed_data[seed_data['group_type'] == 'deep']['score']
            shallow_scores = seed_data[seed_data['group_type'] == 'shallow']['score']
            
            # è´¨é‡åŠ æƒå‡å€¼
            if len(deep_scores) > 0 and len(shallow_scores) > 0:
                weighted_mean = deep_scores.mean() * 0.8 + shallow_scores.mean() * 0.2
            elif len(deep_scores) > 0:
                weighted_mean = deep_scores.mean()
            elif len(shallow_scores) > 0:
                weighted_mean = shallow_scores.mean()
            else:
                continue
                
            seed_stats.append({
                'seed': seed,
                'weighted_mean': weighted_mean,
                'raw_mean': seed_data['score'].mean(),
                'n_deep': len(deep_scores),
                'n_shallow': len(shallow_scores),
                'n_total': len(seed_data)
            })
            
            # æ”¶é›†ç”¨äºæ–¹å·®æ£€éªŒçš„æ•°æ®
            seed_groups.append(seed_data['score'].values)
        
        if len(seed_stats) < 2:
            continue
            
        seed_df = pd.DataFrame(seed_stats)
        
        # ç§å­é—´ç¨³å®šæ€§ç»Ÿè®¡
        weighted_means = seed_df['weighted_mean'].values
        raw_means = seed_df['raw_mean'].values
        
        # å˜å¼‚ç³»æ•°
        cv_weighted = np.std(weighted_means, ddof=1) / np.mean(weighted_means) if np.mean(weighted_means) != 0 else np.nan
        cv_raw = np.std(raw_means, ddof=1) / np.mean(raw_means) if np.mean(raw_means) != 0 else np.nan
        
        # Leveneæ£€éªŒï¼ˆæ–¹å·®é½æ€§ï¼‰
        try:
            if len(seed_groups) >= 2 and all(len(g) > 1 for g in seed_groups):
                levene_stat, levene_p = levene(*seed_groups, center='median')
            else:
                levene_stat, levene_p = np.nan, np.nan
        except:
            levene_stat, levene_p = np.nan, np.nan
        
        # Kruskal-Wallisæ£€éªŒï¼ˆåˆ†å¸ƒå·®å¼‚ï¼‰
        try:
            if len(seed_groups) >= 2 and all(len(g) > 0 for g in seed_groups):
                kruskal_stat, kruskal_p = kruskal(*seed_groups)
            else:
                kruskal_stat, kruskal_p = np.nan, np.nan
        except:
            kruskal_stat, kruskal_p = np.nan, np.nan
        
        results.append({
            'config': config,
            'n_seeds': len(seed_stats),
            'mean_weighted': np.mean(weighted_means),
            'mean_raw': np.mean(raw_means),
            'std_weighted': np.std(weighted_means, ddof=1),
            'std_raw': np.std(raw_means, ddof=1),
            'cv_weighted': cv_weighted,
            'cv_raw': cv_raw,
            'levene_stat': levene_stat,
            'levene_p': levene_p,
            'kruskal_stat': kruskal_stat,
            'kruskal_p': kruskal_p,
            'stability_quality': 'High' if cv_weighted < 0.15 else 'Medium' if cv_weighted < 0.30 else 'Low'
        })
    
    return pd.DataFrame(results).round(4)

def corrected_bradley_terry_analysis(pairwise_df, story_agg_df):
    """
    ä¿®æ­£ç‰ˆBradley-Terryåˆ†æ - æ·»åŠ è¯„ä»·æ¬¡æ•°æƒé‡
    """
    # åˆå¹¶storyèšåˆä¿¡æ¯ï¼ˆåŒ…å«reliability_weightï¼‰
    enhanced_pairwise = pairwise_df.merge(
        story_agg_df[['story_id', 'reliability_weight']].drop_duplicates(),
        left_on='winner_story_id', right_on='story_id', how='left'
    ).rename(columns={'reliability_weight': 'winner_weight'})
    
    enhanced_pairwise = enhanced_pairwise.merge(
        story_agg_df[['story_id', 'reliability_weight']].drop_duplicates(), 
        left_on='loser_story_id', right_on='story_id', how='left'
    ).rename(columns={'reliability_weight': 'loser_weight'})
    
    # è®¡ç®—æ¯”è¾ƒæƒé‡ï¼ˆå–ä¸¤è€…å¹³å‡ï¼‰
    enhanced_pairwise['comparison_weight'] = (
        enhanced_pairwise['winner_weight'].fillna(1.0) + 
        enhanced_pairwise['loser_weight'].fillna(1.0)
    ) / 2
    
    # åŠ æƒBradley-Terryè¯„åˆ†
    story_scores = {}
    story_comparisons = {}
    
    for _, row in enhanced_pairwise.iterrows():
        winner = row['winner_story_id']
        loser = row['loser_story_id'] 
        weight = row['comparison_weight']
        
        if winner not in story_scores:
            story_scores[winner] = 0
            story_comparisons[winner] = {'wins': 0, 'losses': 0, 'total_weight': 0}
        if loser not in story_scores:
            story_scores[loser] = 0
            story_comparisons[loser] = {'wins': 0, 'losses': 0, 'total_weight': 0}
        
        # åŠ æƒå¾—åˆ†æ›´æ–°
        story_scores[winner] += weight
        story_scores[loser] -= weight * 0.5  # å¤±è´¥æƒ©ç½šæƒé‡å‡åŠ
        
        # ç»Ÿè®¡ä¿¡æ¯æ›´æ–°
        story_comparisons[winner]['wins'] += weight
        story_comparisons[winner]['total_weight'] += weight
        story_comparisons[loser]['losses'] += weight  
        story_comparisons[loser]['total_weight'] += weight
    
    # ç”Ÿæˆæ’åè¡¨
    results = []
    for story_id, score in story_scores.items():
        comp_info = story_comparisons[story_id]
        win_rate = comp_info['wins'] / comp_info['total_weight'] if comp_info['total_weight'] > 0 else 0
        
        results.append({
            'story_id': story_id,
            'bt_score': score,
            'weighted_wins': comp_info['wins'],
            'weighted_losses': comp_info['losses'],
            'total_weight': comp_info['total_weight'],
            'weighted_win_rate': win_rate,
            'confidence': min(1.0, comp_info['total_weight'] / 10.0)  # åŸºäºæƒé‡æ€»æ•°çš„ä¿¡å¿ƒåˆ†æ•°
        })
    
    result_df = pd.DataFrame(results).sort_values('bt_score', ascending=False).reset_index(drop=True)
    result_df['rank'] = range(1, len(result_df) + 1)
    
    return result_df

if __name__ == "__main__":
    print("ğŸ”§ é—®å·åˆ†æä¿®æ­£å‡½æ•°å·²åŠ è½½")
    print("ä¸»è¦ä¿®æ­£å†…å®¹ï¼š")
    print("1. âœ… Configçº§åˆ«åˆ†æ - åŒºåˆ†æ·±åº¦(9æ¬¡)vsæµ…åº¦(1æ¬¡)è¯„ä»·") 
    print("2. âœ… Storyçº§åˆ«åˆ†æ - å¤„ç†3äººvs4äººè¯„ä»·æƒé‡")
    print("3. âœ… ç§å­ç¨³å®šæ€§åˆ†æ - è€ƒè™‘ç»„é—´æ•ˆåº”") 
    print("4. âœ… Bradley-Terryåˆ†æ - æ·»åŠ è¯„ä»·æ¬¡æ•°æƒé‡")
    print()
    print("ä½¿ç”¨æ–¹æ³•ï¼š")
    print(">>> import fix_analysis_functions as fix")
    print(">>> corrected_config = fix.create_corrected_config_aggregation(long_table)")
    print(">>> corrected_story = fix.create_corrected_story_aggregation(long_table)")
