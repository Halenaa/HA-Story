#!/bin/bash

# GPUæœåŠ¡å™¨ç¯å¢ƒé…ç½®è„šæœ¬
# ç”¨äºé…ç½®æµç•…åº¦åˆ†ææ‰€éœ€çš„ç¯å¢ƒ

echo "ğŸš€ å¼€å§‹é…ç½®GPUæœåŠ¡å™¨ç¯å¢ƒ..."

# æ£€æŸ¥å½“å‰ç›®å½•
echo "ğŸ“ å½“å‰å·¥ä½œç›®å½•: $(pwd)"

# è¿›å…¥Storyé¡¹ç›®ç›®å½•
cd /root/Story || {
    echo "âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°Storyç›®å½•"
    exit 1
}

echo "ğŸ“‚ è¿›å…¥é¡¹ç›®ç›®å½•: $(pwd)"

# æ£€æŸ¥Pythonç‰ˆæœ¬
echo "ğŸ æ£€æŸ¥Pythonç‰ˆæœ¬..."
python3 --version
python3 -m pip --version

# æ£€æŸ¥GPUæ˜¯å¦å¯ç”¨
echo "ğŸ” æ£€æŸ¥GPUçŠ¶æ€..."
nvidia-smi

# æ£€æŸ¥PyTorchå’ŒGPUæ”¯æŒ
echo "ğŸ” æ£€æŸ¥PyTorch GPUæ”¯æŒ..."
python3 -c "
import torch
print(f'PyTorchç‰ˆæœ¬: {torch.__version__}')
print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'CUDAç‰ˆæœ¬: {torch.version.cuda}')
    print(f'GPUæ•°é‡: {torch.cuda.device_count()}')
    print(f'å½“å‰GPU: {torch.cuda.get_device_name(0)}')
else:
    print('âš ï¸  CUDAä¸å¯ç”¨ï¼Œéœ€è¦å®‰è£…PyTorch GPUç‰ˆæœ¬')
"

# å®‰è£…requirements.txtä¸­çš„ä¾èµ–
echo "ğŸ“¦ å®‰è£…Pythonä¾èµ–..."
if [ -f "requirements.txt" ]; then
    echo "æ‰¾åˆ°requirements.txtï¼Œå¼€å§‹å®‰è£…ä¾èµ–..."
    python3 -m pip install --upgrade pip
    python3 -m pip install -r requirements.txt
    echo "âœ… ä¾èµ–å®‰è£…å®Œæˆ"
else
    echo "âŒ æ‰¾ä¸åˆ°requirements.txtæ–‡ä»¶"
    exit 1
fi

# å¦‚æœPyTorchä¸æ”¯æŒCUDAï¼Œå®‰è£…GPUç‰ˆæœ¬
echo "ğŸ”§ æ£€æŸ¥å¹¶å®‰è£…PyTorch GPUç‰ˆæœ¬..."
python3 -c "
import torch
if not torch.cuda.is_available():
    print('éœ€è¦å®‰è£…PyTorch GPUç‰ˆæœ¬')
    import subprocess
    subprocess.run(['pip', 'install', 'torch', 'torchvision', 'torchaudio', '--index-url', 'https://download.pytorch.org/whl/cu118'])
else:
    print('PyTorch GPUæ”¯æŒå·²å°±ç»ª')
"

# éªŒè¯GPUç¯å¢ƒ
echo "âœ… æœ€ç»ˆéªŒè¯GPUç¯å¢ƒ..."
python3 -c "
import torch
print('=' * 50)
print('GPUç¯å¢ƒéªŒè¯ç»“æœ:')
print(f'PyTorchç‰ˆæœ¬: {torch.__version__}')
print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'CUDAç‰ˆæœ¬: {torch.version.cuda}')
    print(f'GPUæ•°é‡: {torch.cuda.device_count()}')
    for i in range(torch.cuda.device_count()):
        print(f'GPU {i}: {torch.cuda.get_device_name(i)}')
    print(f'å½“å‰è®¾å¤‡: {torch.cuda.current_device()}')
print('=' * 50)
"

# æ£€æŸ¥å…³é”®ä¾èµ–
echo "ğŸ” éªŒè¯å…³é”®ä¾èµ–åŒ…..."
python3 -c "
try:
    import transformers
    print(f'âœ… transformers: {transformers.__version__}')
except ImportError:
    print('âŒ transformers æœªå®‰è£…')

try:
    import language_tool_python
    print('âœ… language-tool-python: å·²å®‰è£…')
except ImportError:
    print('âŒ language-tool-python æœªå®‰è£…')

try:
    import pandas
    print(f'âœ… pandas: {pandas.__version__}')
except ImportError:
    print('âŒ pandas æœªå®‰è£…')

try:
    import numpy
    print(f'âœ… numpy: {numpy.__version__}')
except ImportError:
    print('âŒ numpy æœªå®‰è£…')
"

echo "ğŸ‰ GPUæœåŠ¡å™¨ç¯å¢ƒé…ç½®å®Œæˆï¼"
echo ""
echo "ğŸ“‹ æ¥ä¸‹æ¥å¯ä»¥æ‰§è¡Œçš„æ“ä½œï¼š"
echo "1. æµ‹è¯•å•æ–‡ä»¶æµç•…åº¦åˆ†æ: python3 test_fluency_single.py"
echo "2. è¿è¡Œæ‰¹é‡æµç•…åº¦åˆ†æ: python3 batch_analyze_fluency.py"
echo ""
echo "ğŸ’¡ å»ºè®®å…ˆè¿è¡Œæµ‹è¯•è„šæœ¬éªŒè¯ç¯å¢ƒæ˜¯å¦æ­£å¸¸å·¥ä½œ"
