#!/usr/bin/env python3
"""
æ­£ç¡®çš„æ–‡æ¡£çº§Self-BLEUè®¡ç®—
é€seedã€æ•´ç¯‡æ–‡æ¡£çº§çš„Self-BLEUï¼Œä½¿ç”¨sacrebleu/corpus_bleu
"""

import pandas as pd
import numpy as np
import os
import re
import json
from pathlib import Path
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')

try:
    import sacrebleu
    USE_SACREBLEU = True
    print("ä½¿ç”¨sacrebleuåº“è¿›è¡Œæ–‡æ¡£çº§BLEUè®¡ç®—")
except ImportError:
    USE_SACREBLEU = False
    print("sacrebleuæœªå®‰è£…ï¼Œä½¿ç”¨NLTK corpus_bleu")
    from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction

class DocumentLevelSelfBLEU:
    def __init__(self, data_dirs):
        self.data_dirs = data_dirs
        self.stories_data = {}
        self.tokenization = 'intl'  # sacrebleu tokenization
        self.use_sacrebleu = USE_SACREBLEU
        
    def load_story_text(self, story_dir):
        """ä»æ•…äº‹ç›®å½•åŠ è½½æ–‡æœ¬"""
        story_file = story_dir / 'enhanced_story_dialogue_updated.md'
        
        if not story_file.exists():
            alt_files = ['enhanced_story_updated.md', 'novel_story.md']
            for alt_file in alt_files:
                alt_path = story_dir / alt_file
                if alt_path.exists():
                    with open(alt_path, 'r', encoding='utf-8') as f:
                        return f.read()
        else:
            with open(story_file, 'r', encoding='utf-8') as f:
                return f.read()
        
        return ""
    
    def clean_text_for_bleu(self, text):
        """æ¸…ç†æ–‡æœ¬ç”¨äºBLEUè®¡ç®—"""
        # ç§»é™¤markdownæ ‡è®°
        text = re.sub(r'#.*?\n', ' ', text)
        text = re.sub(r'\*\*.*?\*\*', lambda m: m.group(0)[2:-2], text)  # ä¿æŒåŠ ç²—å†…å®¹
        text = re.sub(r'\*.*?\*', lambda m: m.group(0)[1:-1], text)      # ä¿æŒæ–œä½“å†…å®¹
        
        # è§„èŒƒåŒ–ç©ºç™½å­—ç¬¦
        text = re.sub(r'\s+', ' ', text)
        text = text.strip()
        
        return text
    
    def parse_config_name(self, dir_name):
        """ä»ç›®å½•åè§£æé…ç½®ä¿¡æ¯"""
        parts = dir_name.split('_')
        
        if 'sciencefictionrewrite' in dir_name:
            genre = 'sciencefiction'
            structure = parts[2] 
            temp_seed = parts[3:]
        elif 'horror-suspenserewrite' in dir_name:
            genre = 'horror'
            structure = parts[2]
            temp_seed = parts[3:]
        elif 'romanticrewrite' in dir_name:
            genre = 'romantic'
            structure = parts[2]
            temp_seed = parts[3:]
        else:
            return None
            
        # è§£ææ¸©åº¦å’Œç§å­
        temp_match = re.search(r'T(0\.[379])', ''.join(temp_seed))
        seed_match = re.search(r's([123])', ''.join(temp_seed))
        
        if temp_match and seed_match:
            temperature = temp_match.group(1)
            seed = seed_match.group(1)
            
            return {
                'genre': genre,
                'structure': structure, 
                'temperature': temperature,
                'seed': seed,
                'story_id': f"{genre}_{structure}_T{temperature}_s{seed}",
                'group_key': f"{genre}_{structure}_T{temperature}"
            }
        
        return None
    
    def collect_stories(self):
        """æ”¶é›†æ‰€æœ‰æ•…äº‹æ•°æ®"""
        print("æ”¶é›†æ•…äº‹æ–‡æœ¬æ•°æ®...")
        
        for data_dir in self.data_dirs:
            print(f"\nå¤„ç†ç›®å½•: {data_dir}")
            
            if not os.path.exists(data_dir):
                continue
                
            for story_dir_name in os.listdir(data_dir):
                story_dir_path = Path(data_dir) / story_dir_name
                
                if not story_dir_path.is_dir():
                    continue
                
                config = self.parse_config_name(story_dir_name)
                if not config:
                    continue
                
                story_text = self.load_story_text(story_dir_path)
                if not story_text:
                    continue
                
                cleaned_text = self.clean_text_for_bleu(story_text)
                
                self.stories_data[config['story_id']] = {
                    **config,
                    'raw_text': story_text,
                    'clean_text': cleaned_text,
                    'text_length': len(cleaned_text.split()),
                    'dir_name': story_dir_name
                }
                
                print(f"  âœ“ {config['story_id']}: {len(cleaned_text.split())} words")
        
        print(f"\næ€»å…±æ”¶é›† {len(self.stories_data)} ä¸ªæ•…äº‹")
    
    def calculate_document_self_bleu_sacrebleu(self, hypothesis, references):
        """ä½¿ç”¨sacrebleuè®¡ç®—æ–‡æ¡£çº§BLEU"""
        if not references:
            return 0.0
        
        try:
            bleu = sacrebleu.sentence_bleu(
                hypothesis, 
                references,
                tokenize=self.tokenization,
                smooth_method='exp',  # æŒ‡æ•°å¹³æ»‘
                smooth_value=0.01,
                use_effective_order=True
            )
            return bleu.score / 100.0  # sacrebleuè¿”å›ç™¾åˆ†åˆ¶ï¼Œè½¬æ¢ä¸ºå°æ•°
        except Exception as e:
            print(f"    sacrebleuè®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def calculate_document_self_bleu_nltk(self, hypothesis, references):
        """ä½¿ç”¨NLTKè®¡ç®—æ–‡æ¡£çº§BLEU"""
        if not references:
            return 0.0
        
        try:
            # åˆ†è¯
            hyp_tokens = hypothesis.lower().split()
            ref_tokens_list = [ref.lower().split() for ref in references]
            
            smoothing = SmoothingFunction().method1
            
            bleu = corpus_bleu(
                [ref_tokens_list],  # æ¯ä¸ªå€™é€‰å¯¹åº”çš„å‚è€ƒåˆ—è¡¨
                [hyp_tokens],       # å€™é€‰åˆ—è¡¨
                smoothing_function=smoothing,
                weights=(0.25, 0.25, 0.25, 0.25)
            )
            return bleu
        except Exception as e:
            print(f"    NLTK BLEUè®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def calculate_group_self_bleu(self, group_stories):
        """è®¡ç®—ç»„å†…æ¯ä¸ªæ•…äº‹çš„Self-BLEU"""
        if len(group_stories) < 2:
            return {}
        
        results = {}
        
        for i, (story_id, story_data) in enumerate(group_stories):
            hypothesis = story_data['clean_text']
            
            # è·å–å…¶ä»–æ•…äº‹ä½œä¸ºå‚è€ƒ
            references = []
            for j, (other_story_id, other_story_data) in enumerate(group_stories):
                if i != j:
                    references.append(other_story_data['clean_text'])
            
            # è®¡ç®—Self-BLEU
            if self.use_sacrebleu:
                self_bleu = self.calculate_document_self_bleu_sacrebleu(hypothesis, references)
            else:
                self_bleu = self.calculate_document_self_bleu_nltk(hypothesis, references)
            
            one_minus_self_bleu = 1.0 - self_bleu
            
            results[story_id] = {
                'self_bleu': self_bleu,
                'one_minus_self_bleu': one_minus_self_bleu,
                'hypothesis_length': len(hypothesis.split()),
                'reference_count': len(references),
                'reference_lengths': [len(ref.split()) for ref in references]
            }
            
            print(f"    {story_id}:")
            print(f"      self_bleu: {self_bleu:.6f}")
            print(f"      one_minus_self_bleu: {one_minus_self_bleu:.6f}")
            print(f"      text_length: {len(hypothesis.split())} words")
        
        return results
    
    def calculate_all_self_bleu(self):
        """è®¡ç®—æ‰€æœ‰ç»„çš„Self-BLEU"""
        print("\n" + "="*80)
        print("è®¡ç®—æ–‡æ¡£çº§Self-BLEU")
        print("="*80)
        
        # æŒ‰ç»„ç»„ç»‡æ•°æ®
        groups = defaultdict(list)
        for story_id, story_data in self.stories_data.items():
            groups[story_data['group_key']].append((story_id, story_data))
        
        all_results = {}
        
        for group_key, group_stories in groups.items():
            print(f"\nå¤„ç†ç»„: {group_key} ({len(group_stories)} stories)")
            
            if len(group_stories) != 3:
                print(f"  è­¦å‘Š: ç»„å†…æ•…äº‹æ•° = {len(group_stories)}, è·³è¿‡")
                continue
            
            group_results = self.calculate_group_self_bleu(group_stories)
            all_results.update(group_results)
            
            # ç»„çº§ç»Ÿè®¡
            if group_results:
                self_bleus = [r['self_bleu'] for r in group_results.values()]
                one_minus_bleus = [r['one_minus_self_bleu'] for r in group_results.values()]
                
                print(f"  ç»„çº§ç»Ÿè®¡:")
                print(f"    self_bleu: {np.mean(self_bleus):.6f} Â± {np.std(self_bleus):.6f}")
                print(f"    self_bleu CV: {np.std(self_bleus)/np.mean(self_bleus):.6f}")
                print(f"    one_minus_self_bleu: {np.mean(one_minus_bleus):.6f} Â± {np.std(one_minus_bleus):.6f}")
                print(f"    one_minus_self_bleu CV: {np.std(one_minus_bleus)/np.mean(one_minus_bleus):.6f}")
        
        return all_results
    
    def generate_corrected_dataset(self, self_bleu_results):
        """ç”Ÿæˆä¿®æ­£åçš„æ•°æ®é›†"""
        print("\n" + "="*80)
        print("ç”Ÿæˆä¿®æ­£åçš„æ•°æ®é›†")
        print("="*80)
        
        # è¯»å–åŸå§‹diversityæ•°æ®
        original_df = pd.read_csv('/Users/haha/Story/corrected_diversity_per_seed.csv')
        
        corrected_rows = []
        
        for _, row in original_df.iterrows():
            story_id = row['story_id']
            
            # è·å–ä¿®æ­£çš„Self-BLEUæ•°æ®
            if story_id in self_bleu_results:
                bleu_data = self_bleu_results[story_id]
                new_self_bleu = bleu_data['self_bleu']
                new_one_minus_self_bleu = bleu_data['one_minus_self_bleu']
            else:
                new_self_bleu = np.nan
                new_one_minus_self_bleu = np.nan
            
            corrected_row = {
                'story_id': story_id,
                'genre': row['genre'],
                'structure': row['structure'],
                'temperature': row['temperature'],
                'seed': row['seed'],
                'distinct_avg': row['distinct_avg'],
                'self_bleu_corrected': new_self_bleu,
                'one_minus_self_bleu_corrected': new_one_minus_self_bleu,
                'word_count': row['word_count'],
                'dir_name': row['dir_name']
            }
            
            corrected_rows.append(corrected_row)
        
        corrected_df = pd.DataFrame(corrected_rows)
        corrected_df = corrected_df.sort_values(['genre', 'structure', 'temperature', 'seed'])
        
        
    
    # 5. è®¡ç®—per-seed diversityåˆ†æ•° (é¿å…ç»„çº§æ³„æ¼)
    print("\nè®¡ç®—per-seed diversityåˆ†æ•° (é¿å…ç»„çº§æ³„æ¼)...")
    alpha = 0.6  # å›ºå®šalphaå€¼ï¼Œåç»­å¯å­¦ä¹ 
    
    # ç›´æ¥é€seedè®¡ç®—ï¼Œé¿å…ç»„çº§æ³„æ¼
    corrected_df['diversity_score_seed'] = (
        alpha * corrected_df['one_minus_self_bleu_corrected'] + 
        (1 - alpha) * corrected_df['distinct_avg']
    )
    
    # è®¾ç½®alphaç›¸å…³å­—æ®µ
    corrected_df['alpha_value'] = alpha
    corrected_df['alpha_genre'] = alpha
    
    print(f"   âœ… ä¸º {len(corrected_df)} ä¸ªæ•…äº‹è®¡ç®—äº†per-seed diversityåˆ†æ•°")
    
    # éªŒè¯æ— ç»„çº§æ³„æ¼
    leakage_check = corrected_df.groupby(['genre', 'structure', 'temperature']).agg({
        'diversity_score_seed': 'nunique',
        'distinct_avg': 'nunique'
    })
    
    diversity_fixed = (leakage_check['diversity_score_seed'] > 1).sum()
    total_groups = len(leakage_check)
    
    print(f"   âœ… éªŒè¯ç»“æœ: {diversity_fixed}/{total_groups} ç»„æœ‰çœŸå®å˜å¼‚æ€§")
    
    return corrected_df

def calculate_diversity_group_score(corrected_df):
        """é‡æ–°è®¡ç®—diversity_group_score"""
        print("\né‡æ–°è®¡ç®—diversity_group_score...")
        
        # æŒ‰ç»„è®¡ç®—alphaæƒé‡å’Œdiversity_score
        groups = corrected_df.groupby(['genre', 'structure', 'temperature'])
        
        for group_key, group_df in groups:
            genre, structure, temp = group_key
            print(f"\nç»„ {genre}_{structure}_T{temp}:")
            
            # è·å–ç»„å†…æ•°æ®
            distinct_avgs = group_df['distinct_avg'].values
            one_minus_bleus = group_df['one_minus_self_bleu_corrected'].values
            
            if len(distinct_avgs) == 3 and not np.any(pd.isna(one_minus_bleus)):
                # è®¡ç®—ç®€åŒ–çš„alpha (æš‚æ—¶ä½¿ç”¨0.6ä½œä¸ºé»˜è®¤å€¼)
                alpha = 0.6
                
                # è®¡ç®—ç»„å†…å¹³å‡å’Œdiversity_score
                avg_distinct = np.mean(distinct_avgs)
                avg_one_minus_bleu = np.mean(one_minus_bleus)
                
                diversity_group_score = alpha * avg_one_minus_bleu + (1 - alpha) * avg_distinct
                
                # ä¸ºç»„å†…æ‰€æœ‰æ•…äº‹è®¾ç½®ç›¸åŒçš„ç»„çº§åˆ†æ•°
                mask = ((corrected_df['genre'] == genre) & 
                       (corrected_df['structure'] == structure) & 
                       (corrected_df['temperature'] == temp))
                
                corrected_df.loc[mask, 'diversity_group_score'] = diversity_group_score
                corrected_df.loc[mask, 'alpha_value'] = alpha
                
                print(f"  distinct_avg: {avg_distinct:.6f}")
                print(f"  one_minus_self_bleu: {avg_one_minus_bleu:.6f}")
                print(f"  alpha: {alpha:.3f}")
                print(f"  diversity_group_score: {diversity_group_score:.6f}")
            else:
                print(f"  æ•°æ®ä¸å®Œæ•´ï¼Œè·³è¿‡diversity_group_scoreè®¡ç®—")
        
        
    
    # 5. è®¡ç®—per-seed diversityåˆ†æ•° (é¿å…ç»„çº§æ³„æ¼)
    print("\nè®¡ç®—per-seed diversityåˆ†æ•° (é¿å…ç»„çº§æ³„æ¼)...")
    alpha = 0.6  # å›ºå®šalphaå€¼ï¼Œåç»­å¯å­¦ä¹ 
    
    # ç›´æ¥é€seedè®¡ç®—ï¼Œé¿å…ç»„çº§æ³„æ¼
    corrected_df['diversity_score_seed'] = (
        alpha * corrected_df['one_minus_self_bleu_corrected'] + 
        (1 - alpha) * corrected_df['distinct_avg']
    )
    
    # è®¾ç½®alphaç›¸å…³å­—æ®µ
    corrected_df['alpha_value'] = alpha
    corrected_df['alpha_genre'] = alpha
    
    print(f"   âœ… ä¸º {len(corrected_df)} ä¸ªæ•…äº‹è®¡ç®—äº†per-seed diversityåˆ†æ•°")
    
    # éªŒè¯æ— ç»„çº§æ³„æ¼
    leakage_check = corrected_df.groupby(['genre', 'structure', 'temperature']).agg({
        'diversity_score_seed': 'nunique',
        'distinct_avg': 'nunique'
    })
    
    diversity_fixed = (leakage_check['diversity_score_seed'] > 1).sum()
    total_groups = len(leakage_check)
    
    print(f"   âœ… éªŒè¯ç»“æœ: {diversity_fixed}/{total_groups} ç»„æœ‰çœŸå®å˜å¼‚æ€§")
    
    return corrected_df
    
    def run_complete_correction(self):
        """è¿è¡Œå®Œæ•´çš„ä¿®æ­£æµç¨‹"""
        print("="*80)
        print("æ–‡æ¡£çº§Self-BLEUå®Œæ•´ä¿®æ­£æµç¨‹")
        print("="*80)
        
        # 1. æ”¶é›†æ•…äº‹æ•°æ®
        self.collect_stories()
        
        # 2. è®¡ç®—Self-BLEU
        self_bleu_results = self.calculate_all_self_bleu()
        
        # 3. ç”Ÿæˆä¿®æ­£æ•°æ®é›†
        corrected_df = self.generate_corrected_dataset(self_bleu_results)
        
        # 4. é‡æ–°è®¡ç®—diversity_group_score
        final_df = self.calculate_diversity_group_score(corrected_df)
        
        # 5. ä¿å­˜ç»“æœ
        output_file = '/Users/haha/Story/final_corrected_diversity_data.csv'
        final_df.to_csv(output_file, index=False, encoding='utf-8')
        
        # 6. è¾“å‡ºç»Ÿè®¡ç»“æœ
        print(f"\n" + "="*80)
        print("ä¿®æ­£å®Œæˆç»Ÿè®¡")
        print("="*80)
        
        print(f"âœ… ä¿®æ­£åæ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
        print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"   æ€»æ•…äº‹æ•°: {len(final_df)}")
        print(f"   æœ‰æ•ˆSelf-BLEUæ•°: {final_df['self_bleu_corrected'].notna().sum()}")
        print(f"   Self-BLEUèŒƒå›´: [{final_df['self_bleu_corrected'].min():.6f}, {final_df['self_bleu_corrected'].max():.6f}]")
        
        return final_df, self_bleu_results

def main():
    """ä¸»å‡½æ•°"""
    data_dirs = [
        '/Users/haha/Story/data/output/regression_test',
        '/Users/haha/Story/data/output/horror_test', 
        '/Users/haha/Story/data/output/romantic_test'
    ]
    
    calculator = DocumentLevelSelfBLEU(data_dirs)
    final_df, results = calculator.run_complete_correction()
    
    return final_df, results

if __name__ == "__main__":
    df, results = main()
