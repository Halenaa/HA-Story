{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad9da43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®è·¯å¾„\n",
    "sys.path.append('/Users/haha/Story')  # ä½ çš„é¡¹ç›®æ ¹ç›®å½•\n",
    "\n",
    "# å¯¼å…¥æ‰€æœ‰å¿…è¦æ¨¡å—\n",
    "from src.constant import output_dir\n",
    "from src.utils.utils import save_md, save_json, load_json, extract_plot_list\n",
    "from src.generation.outline_generator import generate_outline\n",
    "from src.generation.chapter_reorder import reorder_chapters\n",
    "from src.generation.generate_characters import generate_characters_v1\n",
    "from src.generation.expand_story import expand_story_v1\n",
    "from src.compile_story import compile_full_story_by_sentence, compile_full_story_by_chapter\n",
    "from src.enhance_story import enhance_story_with_transitions, polish_dialogues_in_story\n",
    "from src.generation.dialogue_inserter import analyze_dialogue_insertions, run_dialogue_insertion, analyze_dialogue_insertions_v2\n",
    "from src.utils.utils import extract_behavior_llm, convert_dialogue_dict_to_list\n",
    "from src.sync.plot_sync_manager import sync_plot_and_dialogue_from_behavior\n",
    "from src.sync.auto_propagate_plot_update import auto_propagate_plot_update\n",
    "from src.analysis.character_state_tracker import run_character_state_tracker\n",
    "from src.utils.logger import append_log, build_log_record, build_simple_log, init_log_path\n",
    "from src.version_namer import build_version_name \n",
    "\n",
    "print(\"âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ\")\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08a4b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# è¯»å–story.json\n",
    "version_folder = \"/Users/haha/Story/data/output/å°çº¢å¸½_ç§‘å¹»_linear_T0.7_s1\"  # æ›¿æ¢æˆä½ çš„è·¯å¾„\n",
    "story_path = f\"{version_folder}/story.json\"\n",
    "\n",
    "with open(story_path, 'r', encoding='utf-8') as f:\n",
    "    story_data = json.load(f)\n",
    "\n",
    "print(\"=== æ£€æŸ¥story.jsonä¸­çš„plotå†…å®¹ ===\")\n",
    "print(f\"æ€»ç« èŠ‚æ•°: {len(story_data)}\")\n",
    "\n",
    "# æ£€æŸ¥æ¯ä¸ªç« èŠ‚çš„plotæ˜¯å¦æœ‰è§’è‰²åé‡å¤\n",
    "for i, chapter in enumerate(story_data):\n",
    "    chapter_id = chapter.get(\"chapter_id\", f\"ç¬¬{i+1}ç« \")\n",
    "    plot = chapter.get(\"plot\", \"\")\n",
    "    \n",
    "    # æ£€æŸ¥è§’è‰²åé‡å¤\n",
    "    duplicates = re.findall(r'å°çº¢å¸½å°çº¢å¸½|æœºæ¢°ç‹¼æœºæ¢°ç‹¼|å¤–å©†å¤–å©†|å°è“å°è“', plot)\n",
    "    \n",
    "    if duplicates:\n",
    "        print(f\"\\nâŒ {chapter_id} å‘ç°é‡å¤:\")\n",
    "        print(f\"   é‡å¤å†…å®¹: {duplicates}\")\n",
    "        print(f\"   ç‰‡æ®µ: {plot[:200]}...\")\n",
    "    else:\n",
    "        print(f\"âœ… {chapter_id} æ— é‡å¤\")\n",
    "\n",
    "# æ˜¾ç¤ºç¬¬ä¸€ç« çš„å®Œæ•´plotä½œä¸ºç¤ºä¾‹\n",
    "print(f\"\\n=== ç¬¬ä¸€ç« å®Œæ•´plotç¤ºä¾‹ ===\")\n",
    "if story_data:\n",
    "    print(story_data[0].get(\"plot\", \"æ— plotå†…å®¹\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f891e09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥sentence_dialogues.json\n",
    "sentence_path = f\"{version_folder}/sentence_dialogues.json\"\n",
    "\n",
    "try:\n",
    "    with open(sentence_path, 'r', encoding='utf-8') as f:\n",
    "        sentence_data = json.load(f)\n",
    "    \n",
    "    print(\"=== æ£€æŸ¥sentence_dialogues.json ===\")\n",
    "    print(f\"æ€»å¥å­æ•°: {len(sentence_data)}\")\n",
    "    \n",
    "    # æ£€æŸ¥å‰5ä¸ªæœ‰å¯¹è¯çš„å¥å­\n",
    "    dialogue_count = 0\n",
    "    duplicate_count = 0\n",
    "    \n",
    "    for i, sentence in enumerate(sentence_data):\n",
    "        if sentence.get(\"dialogue\") and len(sentence[\"dialogue\"]) > 0:\n",
    "            dialogue_count += 1\n",
    "            \n",
    "            # æ£€æŸ¥è¿™ä¸ªå¥å­çš„å¯¹è¯æ˜¯å¦æœ‰è§’è‰²åé‡å¤\n",
    "            for dlg in sentence[\"dialogue\"]:\n",
    "                speaker = dlg.get(\"speaker\", \"\")\n",
    "                dialogue_text = dlg.get(\"dialogue\", \"\")\n",
    "                action = dlg.get(\"action\", \"\")\n",
    "                \n",
    "                # æ£€æŸ¥å„ä¸ªå­—æ®µæ˜¯å¦æœ‰é‡å¤\n",
    "                if re.search(r'å°çº¢å¸½å°çº¢å¸½|æœºæ¢°ç‹¼æœºæ¢°ç‹¼|å¤–å©†å¤–å©†|å°è“å°è“', speaker):\n",
    "                    print(f\"âŒ å¥å­{i} speakeræœ‰é‡å¤: {speaker}\")\n",
    "                    duplicate_count += 1\n",
    "                \n",
    "                if re.search(r'å°çº¢å¸½å°çº¢å¸½|æœºæ¢°ç‹¼æœºæ¢°ç‹¼|å¤–å©†å¤–å©†|å°è“å°è“', dialogue_text):\n",
    "                    print(f\"âŒ å¥å­{i} dialogueæœ‰é‡å¤: {dialogue_text}\")\n",
    "                    duplicate_count += 1\n",
    "                \n",
    "                if re.search(r'å°çº¢å¸½å°çº¢å¸½|æœºæ¢°ç‹¼æœºæ¢°ç‹¼|å¤–å©†å¤–å©†|å°è“å°è“', action):\n",
    "                    print(f\"âŒ å¥å­{i} actionæœ‰é‡å¤: {action}\")\n",
    "                    duplicate_count += 1\n",
    "                \n",
    "                # æ˜¾ç¤ºå‰3ä¸ªå¯¹è¯ç¤ºä¾‹\n",
    "                if dialogue_count <= 3:\n",
    "                    print(f\"\\nå¯¹è¯ç¤ºä¾‹{dialogue_count}:\")\n",
    "                    print(f\"  ç« èŠ‚: {sentence['chapter_id']}\")\n",
    "                    print(f\"  å¥å­: {sentence['sentence'][:50]}...\")\n",
    "                    print(f\"  speaker: {speaker}\")\n",
    "                    print(f\"  dialogue: {dialogue_text}\")\n",
    "                    print(f\"  action: {action}\")\n",
    "    \n",
    "    print(f\"\\nç»Ÿè®¡:\")\n",
    "    print(f\"  æœ‰å¯¹è¯çš„å¥å­: {dialogue_count}\")\n",
    "    print(f\"  å‘ç°é‡å¤çš„æ¬¡æ•°: {duplicate_count}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ sentence_dialogues.json æ–‡ä»¶ä¸å­˜åœ¨\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ è¯»å–å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cfc1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥novel_story.mdï¼Œçœ‹ç¼–è¯‘ç»“æœ\n",
    "novel_path = f\"{version_folder}/novel_story.md\"\n",
    "\n",
    "with open(novel_path, 'r', encoding='utf-8') as f:\n",
    "    novel_content = f.read()\n",
    "\n",
    "print(\"=== æ£€æŸ¥novel_story.mdä¸­çš„é‡å¤é—®é¢˜ ===\")\n",
    "\n",
    "# æŸ¥æ‰¾å¸¦actionçš„å¯¹è¯æ ¼å¼ï¼ˆåº”è¯¥æ˜¯: è§’è‰²actionï¼Œ\"å¯¹è¯\" â€”â€”è§’è‰²ï¼‰\n",
    "import re\n",
    "duplicates = re.findall(r'å°çº¢å¸½å°çº¢å¸½|æœºæ¢°ç‹¼æœºæ¢°ç‹¼|å¤–å©†å¤–å©†|å°è“å°è“', novel_content)\n",
    "\n",
    "print(f\"å‘ç°çš„é‡å¤: {len(duplicates)} ä¸ª\")\n",
    "if duplicates:\n",
    "    print(f\"é‡å¤ç±»å‹: {set(duplicates)}\")\n",
    "\n",
    "# æŸ¥æ‰¾å…·ä½“çš„é‡å¤è¡Œ\n",
    "lines = novel_content.split('\\n')\n",
    "duplicate_lines = []\n",
    "for i, line in enumerate(lines):\n",
    "    if re.search(r'å°çº¢å¸½å°çº¢å¸½|æœºæ¢°ç‹¼æœºæ¢°ç‹¼|å¤–å©†å¤–å©†|å°è“å°è“', line):\n",
    "        duplicate_lines.append((i+1, line.strip()))\n",
    "\n",
    "print(f\"\\né‡å¤å‡ºç°çš„è¡Œæ•°: {len(duplicate_lines)}\")\n",
    "for line_num, line in duplicate_lines[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª\n",
    "    print(f\"ç¬¬{line_num}è¡Œ: {line}\")\n",
    "\n",
    "# æŸ¥æ‰¾åŸå§‹actionæ‹¼æ¥çš„æ¨¡å¼\n",
    "action_pattern = r'([^ï¼Œ\\n]+å°çº¢å¸½[^ï¼Œ\\n]+)ï¼Œ\"([^\"]+)\" â€”â€”å°çº¢å¸½'\n",
    "action_matches = re.findall(action_pattern, novel_content)\n",
    "\n",
    "print(f\"\\nå‘ç°çš„actionæ‹¼æ¥æ¨¡å¼: {len(action_matches)} ä¸ª\")\n",
    "if action_matches:\n",
    "    print(\"ç¤ºä¾‹:\")\n",
    "    for i, (action_part, dialogue) in enumerate(action_matches[:3]):\n",
    "        print(f\"  {i+1}. {action_part}ï¼Œ\\\"{dialogue}\\\" â€”â€”å°çº¢å¸½\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ca0acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿®å¤compile_story.pyä¸­çš„format_dialogue_with_actionå‡½æ•°\n",
    "def fixed_format_dialogue_with_action(speaker, dialogue_text, action):\n",
    "    \"\"\"ä¿®å¤åçš„å¯¹è¯æ ¼å¼åŒ–å‡½æ•°\"\"\"\n",
    "    if not action or not action.strip():\n",
    "        # æ— åŠ¨ä½œæ—¶çš„æ ‡å‡†æ ¼å¼\n",
    "        return f'\"{dialogue_text.strip()}\" â€”â€”{speaker}\\n\\n'\n",
    "    \n",
    "    action_clean = action.strip()\n",
    "    \n",
    "    # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ£€æŸ¥actionæ˜¯å¦å·²ç»åŒ…å«è§’è‰²å\n",
    "    if action_clean.startswith(speaker):\n",
    "        # å¦‚æœåŒ…å«ï¼Œç›´æ¥ä½¿ç”¨actionï¼ˆä¸é‡å¤æ·»åŠ speakerï¼‰\n",
    "        formatted_action = action_clean\n",
    "    else:\n",
    "        # å¦åˆ™æ‰æ‹¼æ¥speaker\n",
    "        formatted_action = f'{speaker}{action_clean}'\n",
    "    \n",
    "    return f'{formatted_action}ï¼Œ\"{dialogue_text.strip()}\" â€”â€”{speaker}\\n\\n'\n",
    "\n",
    "# æµ‹è¯•ä¿®å¤æ•ˆæœ\n",
    "print(\"=== æµ‹è¯•ä¿®å¤æ•ˆæœ ===\")\n",
    "\n",
    "# æµ‹è¯•å‡ ä¸ªä¾‹å­\n",
    "test_cases = [\n",
    "    (\"å°çº¢å¸½\", \"æˆ‘å‡†å¤‡å¥½äº†\", \"å°çº¢å¸½å¯åŠ¨é£èˆ¹,è¾“å…¥ç›®æ ‡åæ ‡\"),  # actionåŒ…å«è§’è‰²å\n",
    "    (\"å°çº¢å¸½\", \"æ”¶åˆ°æŒ‡ä»¤\", \"ç‚¹å¤´ç¡®è®¤\"),  # actionä¸åŒ…å«è§’è‰²å\n",
    "    (\"æœºæ¢°ç‹¼\", \"äº¤å‡ºèŠ¯ç‰‡\", \"æœºæ¢°ç‹¼å†·ç¬‘ä¸€å£°,æ­¥æ­¥é€¼è¿‘\"),  # å¦ä¸€ä¸ªåŒ…å«è§’è‰²åçš„ä¾‹å­\n",
    "]\n",
    "\n",
    "for speaker, dialogue, action in test_cases:\n",
    "    result = fixed_format_dialogue_with_action(speaker, dialogue, action)\n",
    "    print(f\"åŸå§‹: speaker='{speaker}', action='{action}'\")\n",
    "    print(f\"ç»“æœ: {result.strip()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab75319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç›´æ¥åœ¨notebookä¸­å®šä¹‰ä¿®å¤åçš„ç¼–è¯‘å‡½æ•°\n",
    "def compile_full_story_by_sentence_FIXED(story_json, sentence_dialogues):\n",
    "    \"\"\"ä¿®å¤ç‰ˆæœ¬çš„å¥å­çº§ç¼–è¯‘å‡½æ•°\"\"\"\n",
    "    from src.utils.utils import split_plot_into_sentences\n",
    "    \n",
    "    def fixed_format_dialogue_with_action(speaker, dialogue_text, action):\n",
    "        \"\"\"ä¿®å¤åçš„å¯¹è¯æ ¼å¼åŒ–å‡½æ•°\"\"\"\n",
    "        if not action or not action.strip():\n",
    "            return f'\"{dialogue_text.strip()}\" â€”â€”{speaker}\\n\\n'\n",
    "        \n",
    "        action_clean = action.strip()\n",
    "        \n",
    "        # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ£€æŸ¥actionæ˜¯å¦å·²ç»åŒ…å«è§’è‰²å\n",
    "        if action_clean.startswith(speaker):\n",
    "            formatted_action = action_clean\n",
    "        else:\n",
    "            formatted_action = f'{speaker}{action_clean}'\n",
    "        \n",
    "        return f'{formatted_action}ï¼Œ\"{dialogue_text.strip()}\" â€”â€”{speaker}\\n\\n'\n",
    "    \n",
    "    # ç»„ç»‡å¥å­çº§å¯¹è¯æ•°æ®\n",
    "    dialogue_map = {}\n",
    "    for item in sentence_dialogues:\n",
    "        if item.get(\"need_to_action\") == 1 and item.get(\"dialogue\"):\n",
    "            chapter_id = item[\"chapter_id\"]\n",
    "            sentence_idx = item[\"sentence_index\"]\n",
    "            \n",
    "            if chapter_id not in dialogue_map:\n",
    "                dialogue_map[chapter_id] = {}\n",
    "            dialogue_map[chapter_id][sentence_idx] = item[\"dialogue\"]\n",
    "    \n",
    "    full_story = \"\"\n",
    "    \n",
    "    for chapter in story_json:\n",
    "        chapter_id = chapter.get(\"chapter_id\", f\"Unknown\")\n",
    "        title = chapter.get(\"title\", f\"Unknown\")\n",
    "        plot = chapter.get(\"plot\", \"\").strip()\n",
    "        \n",
    "        full_story += f\"# {chapter_id}ï¼š{title}\\n\\n\"\n",
    "        \n",
    "        # æŒ‰å¥å­åˆ†å‰²å¹¶æ’å…¥å¯¹è¯\n",
    "        sentences = split_plot_into_sentences(plot)\n",
    "        \n",
    "        for sent_idx, sentence in enumerate(sentences):\n",
    "            # æ·»åŠ å™è¿°å¥å­\n",
    "            full_story += sentence + \"\\n\\n\"\n",
    "            \n",
    "            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ’å…¥å¯¹è¯\n",
    "            if (chapter_id in dialogue_map and \n",
    "                sent_idx in dialogue_map[chapter_id]):\n",
    "                \n",
    "                dialogues = dialogue_map[chapter_id][sent_idx]\n",
    "                \n",
    "                if dialogues:\n",
    "                    for line in dialogues:\n",
    "                        if isinstance(line, dict):\n",
    "                            speaker = line.get(\"speaker\", \"\")\n",
    "                            dialogue_text = line.get(\"dialogue\", line.get(\"line\", \"\"))\n",
    "                            action = line.get(\"action\", \"\")\n",
    "                            \n",
    "                            if speaker and dialogue_text:\n",
    "                                # ğŸ”§ ä½¿ç”¨ä¿®å¤åçš„æ ¼å¼åŒ–å‡½æ•°\n",
    "                                formatted_line = fixed_format_dialogue_with_action(speaker, dialogue_text, action)\n",
    "                                full_story += formatted_line\n",
    "                        elif isinstance(line, str):\n",
    "                            full_story += line.strip() + \"\\n\\n\"\n",
    "        \n",
    "        full_story += \"-\" * 40 + \"\\n\\n\"\n",
    "    \n",
    "    return full_story\n",
    "\n",
    "# é‡æ–°ç¼–è¯‘å°è¯´\n",
    "print(\"ğŸ”§ ä½¿ç”¨ä¿®å¤åçš„ç¼–è¯‘å‡½æ•°é‡æ–°ç”Ÿæˆå°è¯´...\")\n",
    "\n",
    "# è¯»å–æ•°æ®\n",
    "with open(f\"{version_folder}/story.json\", 'r', encoding='utf-8') as f:\n",
    "    story_data = json.load(f)\n",
    "\n",
    "with open(f\"{version_folder}/sentence_dialogues.json\", 'r', encoding='utf-8') as f:\n",
    "    sentence_data = json.load(f)\n",
    "\n",
    "# ç¼–è¯‘ä¿®å¤ç‰ˆå°è¯´\n",
    "fixed_novel = compile_full_story_by_sentence_FIXED(story_data, sentence_data)\n",
    "\n",
    "# ä¿å­˜ä¿®å¤ç‰ˆ\n",
    "with open(f\"{version_folder}/novel_story_FIXED.md\", 'w', encoding='utf-8') as f:\n",
    "    f.write(fixed_novel)\n",
    "\n",
    "print(\"âœ… ä¿®å¤ç‰ˆå°è¯´å·²ç”Ÿæˆ: novel_story_FIXED.md\")\n",
    "\n",
    "# éªŒè¯ä¿®å¤æ•ˆæœ\n",
    "duplicates_fixed = re.findall(r'å°çº¢å¸½å°çº¢å¸½|æœºæ¢°ç‹¼æœºæ¢°ç‹¼|å¤–å©†å¤–å©†|å°è“å°è“', fixed_novel)\n",
    "print(f\"ä¿®å¤åå‘ç°çš„é‡å¤: {len(duplicates_fixed)} ä¸ª\")\n",
    "\n",
    "if len(duplicates_fixed) == 0:\n",
    "    print(\"ğŸ‰ è§’è‰²åé‡å¤é—®é¢˜å·²å®Œå…¨ä¿®å¤ï¼\")\n",
    "else:\n",
    "    print(f\"âš ï¸ ä»æœ‰ {len(duplicates_fixed)} ä¸ªé‡å¤ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•\")\n",
    "\n",
    "# é¢„è§ˆä¿®å¤æ•ˆæœ\n",
    "print(f\"\\nğŸ“– ä¿®å¤ç‰ˆé¢„è§ˆï¼ˆå‰800å­—ç¬¦ï¼‰:\")\n",
    "print(fixed_novel[:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc3cc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®Œå–„çš„ä¿®å¤å‡½æ•°ï¼ŒåŒæ—¶å¤„ç†è§’è‰²åé‡å¤å’Œæ ‡ç‚¹ç¬¦å·é—®é¢˜\n",
    "def compile_full_story_by_sentence_COMPLETE_FIX(story_json, sentence_dialogues):\n",
    "    \"\"\"å®Œæ•´ä¿®å¤ç‰ˆï¼šå¤„ç†è§’è‰²åé‡å¤ + æ ‡ç‚¹ç¬¦å·é—®é¢˜\"\"\"\n",
    "    from src.utils.utils import split_plot_into_sentences\n",
    "    import re\n",
    "    \n",
    "    def clean_punctuation(text):\n",
    "        \"\"\"æ¸…ç†æ ‡ç‚¹ç¬¦å·é—®é¢˜\"\"\"\n",
    "        if not text:\n",
    "            return text\n",
    "        \n",
    "        # ç»Ÿä¸€ä¸­è‹±æ–‡æ ‡ç‚¹ç¬¦å·\n",
    "        text = text.replace(',', 'ï¼Œ')  # ç»Ÿä¸€ç”¨ä¸­æ–‡é€—å·\n",
    "        text = text.replace('.', 'ã€‚')   # ç»Ÿä¸€ç”¨ä¸­æ–‡å¥å·\n",
    "        text = text.replace('!', 'ï¼')  # ç»Ÿä¸€ç”¨ä¸­æ–‡æ„Ÿå¹å·\n",
    "        text = text.replace('?', 'ï¼Ÿ')  # ç»Ÿä¸€ç”¨ä¸­æ–‡é—®å·\n",
    "        text = text.replace(';', 'ï¼›')  # ç»Ÿä¸€ç”¨ä¸­æ–‡åˆ†å·\n",
    "        \n",
    "        # ä¿®å¤æ ‡ç‚¹ç¬¦å·é”™è¯¯ç»„åˆ\n",
    "        text = re.sub(r'ã€‚ï¼Œ+', 'ï¼Œ', text)  # å¥å·+é€—å· -> é€—å·\n",
    "        text = re.sub(r'ï¼Œã€‚+', 'ã€‚', text)  # é€—å·+å¥å· -> å¥å·  \n",
    "        text = re.sub(r'ã€‚+ï¼Œ', 'ï¼Œ', text)  # å¥å·+é€—å· -> é€—å·\n",
    "        text = re.sub(r'ï¼Œ+ã€‚', 'ã€‚', text)  # é€—å·+å¥å· -> å¥å·\n",
    "        \n",
    "        # æ¸…ç†é‡å¤æ ‡ç‚¹\n",
    "        text = re.sub(r'ï¼Œ{2,}', 'ï¼Œ', text)  # å¤šä¸ªé€—å· -> å•ä¸ªé€—å·\n",
    "        text = re.sub(r'ã€‚{2,}', 'ã€‚', text)  # å¤šä¸ªå¥å· -> å•ä¸ªå¥å·\n",
    "        \n",
    "        # æ¸…ç†æ ‡ç‚¹å‰çš„ç©ºæ ¼\n",
    "        text = re.sub(r'\\s+([ï¼Œã€‚ï¼ï¼Ÿï¼›])', r'\\1', text)\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    def fixed_format_dialogue_with_action(speaker, dialogue_text, action):\n",
    "        \"\"\"ä¿®å¤åçš„å¯¹è¯æ ¼å¼åŒ–å‡½æ•°ï¼šå¤„ç†è§’è‰²åé‡å¤ + æ ‡ç‚¹é—®é¢˜\"\"\"\n",
    "        if not action or not action.strip():\n",
    "            return f'\"{dialogue_text.strip()}\" â€”â€”{speaker}\\n\\n'\n",
    "        \n",
    "        action_clean = action.strip()\n",
    "        \n",
    "        # ğŸ”§ ä¿®å¤1ï¼šæ£€æŸ¥actionæ˜¯å¦å·²ç»åŒ…å«è§’è‰²å\n",
    "        if action_clean.startswith(speaker):\n",
    "            formatted_action = action_clean\n",
    "        else:\n",
    "            formatted_action = f'{speaker}{action_clean}'\n",
    "        \n",
    "        # ğŸ”§ ä¿®å¤2ï¼šæ¸…ç†æ ‡ç‚¹ç¬¦å·\n",
    "        formatted_action = clean_punctuation(formatted_action)\n",
    "        dialogue_text = clean_punctuation(dialogue_text)\n",
    "        \n",
    "        # ğŸ”§ ä¿®å¤3ï¼šç¡®ä¿actionä»¥æ­£ç¡®æ ‡ç‚¹ç»“å°¾\n",
    "        if formatted_action and not formatted_action.endswith(('ï¼Œ', 'ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼›')):\n",
    "            # å¦‚æœactionæ²¡æœ‰ç»“å°¾æ ‡ç‚¹ï¼Œæ·»åŠ é€—å·\n",
    "            formatted_action += 'ï¼Œ'\n",
    "        elif formatted_action.endswith('ã€‚'):\n",
    "            # å¦‚æœä»¥å¥å·ç»“å°¾ï¼Œæ”¹ä¸ºé€—å·ï¼ˆå› ä¸ºåé¢è¿˜æœ‰å¯¹è¯ï¼‰\n",
    "            formatted_action = formatted_action[:-1] + 'ï¼Œ'\n",
    "        \n",
    "        return f'{formatted_action}\"{dialogue_text.strip()}\" â€”â€”{speaker}\\n\\n'\n",
    "    \n",
    "    # ç»„ç»‡å¥å­çº§å¯¹è¯æ•°æ®\n",
    "    dialogue_map = {}\n",
    "    for item in sentence_dialogues:\n",
    "        if item.get(\"need_to_action\") == 1 and item.get(\"dialogue\"):\n",
    "            chapter_id = item[\"chapter_id\"]\n",
    "            sentence_idx = item[\"sentence_index\"]\n",
    "            \n",
    "            if chapter_id not in dialogue_map:\n",
    "                dialogue_map[chapter_id] = {}\n",
    "            dialogue_map[chapter_id][sentence_idx] = item[\"dialogue\"]\n",
    "    \n",
    "    full_story = \"\"\n",
    "    \n",
    "    for chapter in story_json:\n",
    "        chapter_id = chapter.get(\"chapter_id\", f\"Unknown\")\n",
    "        title = chapter.get(\"title\", f\"Unknown\")\n",
    "        plot = chapter.get(\"plot\", \"\").strip()\n",
    "        \n",
    "        full_story += f\"# {chapter_id}ï¼š{title}\\n\\n\"\n",
    "        \n",
    "        # æŒ‰å¥å­åˆ†å‰²å¹¶æ’å…¥å¯¹è¯\n",
    "        sentences = split_plot_into_sentences(plot)\n",
    "        \n",
    "        for sent_idx, sentence in enumerate(sentences):\n",
    "            # ğŸ”§ æ¸…ç†å™è¿°å¥å­çš„æ ‡ç‚¹\n",
    "            clean_sentence = clean_punctuation(sentence)\n",
    "            full_story += clean_sentence + \"\\n\\n\"\n",
    "            \n",
    "            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ’å…¥å¯¹è¯\n",
    "            if (chapter_id in dialogue_map and \n",
    "                sent_idx in dialogue_map[chapter_id]):\n",
    "                \n",
    "                dialogues = dialogue_map[chapter_id][sent_idx]\n",
    "                \n",
    "                if dialogues:\n",
    "                    for line in dialogues:\n",
    "                        if isinstance(line, dict):\n",
    "                            speaker = line.get(\"speaker\", \"\")\n",
    "                            dialogue_text = line.get(\"dialogue\", line.get(\"line\", \"\"))\n",
    "                            action = line.get(\"action\", \"\")\n",
    "                            \n",
    "                            if speaker and dialogue_text:\n",
    "                                formatted_line = fixed_format_dialogue_with_action(speaker, dialogue_text, action)\n",
    "                                full_story += formatted_line\n",
    "                        elif isinstance(line, str):\n",
    "                            clean_line = clean_punctuation(line)\n",
    "                            full_story += clean_line + \"\\n\\n\"\n",
    "        \n",
    "        full_story += \"-\" * 40 + \"\\n\\n\"\n",
    "    \n",
    "    return full_story\n",
    "\n",
    "# æµ‹è¯•æ ‡ç‚¹ä¿®å¤æ•ˆæœ\n",
    "print(\"=== æµ‹è¯•æ ‡ç‚¹ä¿®å¤æ•ˆæœ ===\")\n",
    "\n",
    "# æµ‹è¯•æ ‡ç‚¹æ¸…ç†å‡½æ•°\n",
    "def clean_punctuation(text):\n",
    "    if not text:\n",
    "        return text\n",
    "    \n",
    "    text = text.replace(',', 'ï¼Œ').replace('.', 'ã€‚').replace('!', 'ï¼').replace('?', 'ï¼Ÿ').replace(';', 'ï¼›')\n",
    "    text = re.sub(r'ã€‚ï¼Œ+', 'ï¼Œ', text)\n",
    "    text = re.sub(r'ï¼Œã€‚+', 'ã€‚', text)\n",
    "    text = re.sub(r'ã€‚+ï¼Œ', 'ï¼Œ', text)\n",
    "    text = re.sub(r'ï¼Œ+ã€‚', 'ã€‚', text)\n",
    "    text = re.sub(r'ï¼Œ{2,}', 'ï¼Œ', text)\n",
    "    text = re.sub(r'ã€‚{2,}', 'ã€‚', text)\n",
    "    text = re.sub(r'\\s+([ï¼Œã€‚ï¼ï¼Ÿï¼›])', r'\\1', text)\n",
    "    return text.strip()\n",
    "\n",
    "test_punctuation = [\n",
    "    \"å°çº¢å¸½å¯åŠ¨é£èˆ¹,è¾“å…¥ç›®æ ‡åæ ‡,å¼€å§‹å‡ç©ºå‰å¾€åŒ»ç–—ä¸­å¿ƒ.ï¼Œ\",\n",
    "    \"æœºæ¢°ç‹¼å†·ç¬‘ä¸€å£°ï¼Œ.å‡†å¤‡æ”»å‡»\",\n",
    "    \"å¤–å©†è™šå¼±åœ°è¯´é“...ï¼Œï¼Œ\",\n",
    "]\n",
    "\n",
    "for test in test_punctuation:\n",
    "    fixed = clean_punctuation(test)\n",
    "    print(f\"åŸå§‹: {test}\")\n",
    "    print(f\"ä¿®å¤: {fixed}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a584d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨å®Œæ•´ä¿®å¤ç‰ˆé‡æ–°ç¼–è¯‘å°è¯´\n",
    "print(\"ğŸ”§ ä½¿ç”¨å®Œæ•´ä¿®å¤ç‰ˆï¼ˆè§’è‰²å+æ ‡ç‚¹ï¼‰é‡æ–°ç”Ÿæˆå°è¯´...\")\n",
    "\n",
    "# é‡æ–°ç¼–è¯‘\n",
    "complete_fixed_novel = compile_full_story_by_sentence_COMPLETE_FIX(story_data, sentence_data)\n",
    "\n",
    "# ä¿å­˜å®Œæ•´ä¿®å¤ç‰ˆ\n",
    "with open(f\"{version_folder}/novel_story_COMPLETE_FIXED.md\", 'w', encoding='utf-8') as f:\n",
    "    f.write(complete_fixed_novel)\n",
    "\n",
    "print(\"âœ… å®Œæ•´ä¿®å¤ç‰ˆå°è¯´å·²ç”Ÿæˆ: novel_story_COMPLETE_FIXED.md\")\n",
    "\n",
    "# éªŒè¯ä¿®å¤æ•ˆæœ\n",
    "print(\"\\n=== ä¿®å¤æ•ˆæœéªŒè¯ ===\")\n",
    "\n",
    "# 1. æ£€æŸ¥è§’è‰²åé‡å¤\n",
    "duplicates_fixed = re.findall(r'å°çº¢å¸½å°çº¢å¸½|æœºæ¢°ç‹¼æœºæ¢°ç‹¼|å¤–å©†å¤–å©†|å°è“å°è“', complete_fixed_novel)\n",
    "print(f\"è§’è‰²åé‡å¤: {len(duplicates_fixed)} ä¸ª\")\n",
    "\n",
    "# 2. æ£€æŸ¥æ ‡ç‚¹ç¬¦å·é—®é¢˜\n",
    "punct_issues = []\n",
    "if re.search(r'[,ï¼Œ][.ã€‚]', complete_fixed_novel):\n",
    "    punct_issues.append(\"é€—å·+å¥å·\")\n",
    "if re.search(r'[.ã€‚][,ï¼Œ]', complete_fixed_novel):\n",
    "    punct_issues.append(\"å¥å·+é€—å·\")\n",
    "if re.search(r'[,ï¼Œ]{2,}', complete_fixed_novel):\n",
    "    punct_issues.append(\"é‡å¤é€—å·\")\n",
    "if re.search(r'[.ã€‚]{2,}', complete_fixed_novel):\n",
    "    punct_issues.append(\"é‡å¤å¥å·\")\n",
    "\n",
    "print(f\"æ ‡ç‚¹ç¬¦å·é—®é¢˜: {len(punct_issues)} ç§\")\n",
    "if punct_issues:\n",
    "    print(f\"  é—®é¢˜ç±»å‹: {punct_issues}\")\n",
    "\n",
    "# 3. ç»Ÿè®¡å¯¹è¯æ•°é‡\n",
    "dialogue_count = complete_fixed_novel.count('\" â€”â€”')\n",
    "print(f\"å¯¹è¯æ•°é‡: {dialogue_count} æ¡\")\n",
    "\n",
    "if len(duplicates_fixed) == 0 and len(punct_issues) == 0:\n",
    "    print(\"\\nğŸ‰ æ‰€æœ‰é—®é¢˜å·²å®Œå…¨ä¿®å¤ï¼\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ ä»æœ‰é—®é¢˜éœ€è¦å¤„ç†\")\n",
    "\n",
    "# 4. å¯¹æ¯”ä¿®å¤å‰å\n",
    "print(f\"\\nğŸ“Š ä¿®å¤å‰åå¯¹æ¯”:\")\n",
    "with open(f\"{version_folder}/novel_story.md\", 'r', encoding='utf-8') as f:\n",
    "    original_novel = f.read()\n",
    "\n",
    "original_duplicates = len(re.findall(r'å°çº¢å¸½å°çº¢å¸½|æœºæ¢°ç‹¼æœºæ¢°ç‹¼|å¤–å©†å¤–å©†|å°è“å°è“', original_novel))\n",
    "print(f\"  è§’è‰²åé‡å¤: {original_duplicates} -> {len(duplicates_fixed)}\")\n",
    "\n",
    "# 5. é¢„è§ˆä¿®å¤æ•ˆæœï¼ˆå‰1000å­—ç¬¦ï¼‰\n",
    "print(f\"\\nğŸ“– å®Œæ•´ä¿®å¤ç‰ˆé¢„è§ˆ:\")\n",
    "print(complete_fixed_novel[:1000])\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccf89da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœ¨ä½ çš„ipynbä¸­å¿«é€Ÿæµ‹è¯•\n",
    "import sys\n",
    "sys.path.append('/Users/haha/Story')\n",
    "\n",
    "# é‡æ–°ç¼–è¯‘æµ‹è¯•\n",
    "from src.compile_story import compile_full_story_by_sentence\n",
    "from src.utils.utils import load_json\n",
    "\n",
    "version_folder = \"/Users/haha/Story/data/output/å°çº¢å¸½_ç§‘å¹»_linear_T0.7_s1\"\n",
    "\n",
    "story_data = load_json(f\"{version_folder}/story.json\")\n",
    "sentence_data = load_json(f\"{version_folder}/sentence_dialogues.json\")\n",
    "\n",
    "# ç”¨ä¿®å¤åçš„å‡½æ•°ç¼–è¯‘\n",
    "test_novel = compile_full_story_by_sentence(story_data, sentence_data)\n",
    "\n",
    "# æ£€æŸ¥æ˜¯å¦è¿˜æœ‰é—®é¢˜\n",
    "import re\n",
    "duplicates = re.findall(r'å°çº¢å¸½å°çº¢å¸½|æœºæ¢°ç‹¼æœºæ¢°ç‹¼|å¤–å©†å¤–å©†|å°è“å°è“', test_novel)\n",
    "print(f\"è§’è‰²åé‡å¤: {len(duplicates)} ä¸ª\")\n",
    "\n",
    "# æ£€æŸ¥å¯¹è¯æ•°é‡\n",
    "dialogue_count = test_novel.count('\" â€”â€”')\n",
    "print(f\"å¯¹è¯æ•°é‡: {dialogue_count} æ¡\")\n",
    "\n",
    "if len(duplicates) == 0:\n",
    "    print(\"ğŸ‰ ä¿®å¤æˆåŠŸï¼\")\n",
    "    # ä¿å­˜æµ‹è¯•ç»“æœ\n",
    "    with open(f\"{version_folder}/novel_story_FINAL_TEST.md\", 'w', encoding='utf-8') as f:\n",
    "        f.write(test_novel)\n",
    "else:\n",
    "    print(\"âš ï¸ è¿˜æœ‰é—®é¢˜éœ€è¦æ£€æŸ¥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c4c8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691411d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b4d566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca40210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a28b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç½®å‚æ•°\n",
    "topic = \"å°çº¢å¸½\"\n",
    "style = \"ç§‘å¹»æ”¹å†™\"\n",
    "reorder_mode = \"linear\"\n",
    "use_cache = False\n",
    "behavior_model = \"gpt-4.1\"\n",
    "temperature = 0.7\n",
    "seed = 1\n",
    "\n",
    "print(f\"ğŸ“‹ æµ‹è¯•å‚æ•°:\")\n",
    "print(f\"   Topic: {topic}\")\n",
    "print(f\"   Style: {style}\")\n",
    "print(f\"   Reorder mode: {reorder_mode}\")\n",
    "print(f\"   Temperature: {temperature}\")\n",
    "print(f\"   Seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accc7273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è‡ªåŠ¨æ„å»ºç‰ˆæœ¬åç§°\n",
    "version = build_version_name(\n",
    "    topic=topic,\n",
    "    style=style,\n",
    "    temperature=temperature,\n",
    "    seed=seed,\n",
    "    order_mode=reorder_mode\n",
    ")\n",
    "\n",
    "print(f\"ğŸ·ï¸ ç”Ÿæˆç‰ˆæœ¬å: {version}\")\n",
    "\n",
    "# åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹\n",
    "def ensure_output_dir(version):\n",
    "    folder = os.path.join(output_dir, version)\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    return folder\n",
    "\n",
    "def step_file(version, filename):\n",
    "    return os.path.join(output_dir, version, filename)\n",
    "\n",
    "folder = ensure_output_dir(version)\n",
    "role_state = {}\n",
    "\n",
    "plot_log_path = init_log_path(folder, \"plot\")\n",
    "dialogue_log_path = init_log_path(folder, \"dialogue\")\n",
    "\n",
    "print(f\"ğŸ“ è¾“å‡ºæ–‡ä»¶å¤¹: {folder}\")\n",
    "print(f\"ğŸ“ æ—¥å¿—è·¯å¾„: plot={plot_log_path}, dialogue={dialogue_log_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eeb6e2",
   "metadata": {},
   "source": [
    "# Step 1 - Outline Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917afb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Step 1: Outline Generation ===\")\n",
    "\n",
    "# å¤åˆ¶main_pipeline.pyçš„outlineç”Ÿæˆé€»è¾‘\n",
    "outline_base_path = os.path.join(output_dir, \"reference_outline\", f\"{topic}_{style}_T{temperature}_s{seed}outline.json\")\n",
    "os.makedirs(os.path.dirname(outline_base_path), exist_ok=True)\n",
    "\n",
    "if os.path.exists(outline_base_path) and use_cache:\n",
    "    outline = load_json(outline_base_path)\n",
    "    print(f\"ğŸ“– å·²åŠ è½½å…±äº« outlineï¼š{outline_base_path}\")\n",
    "else:\n",
    "    print(f\"ğŸ”„ ç”Ÿæˆæ–°çš„outline...\")\n",
    "    outline = generate_outline(topic=topic, style=style, custom_instruction=\"\")\n",
    "    save_json(outline, \"reference_outline\", f\"{topic}_{style}_T{temperature}_s{seed}_outline.json\")\n",
    "    print(f\"ğŸ’¾ ç”Ÿæˆå¹¶ä¿å­˜å…±äº« outlineï¼š{outline_base_path}\")\n",
    "\n",
    "print(f\"âœ… Outlineç”Ÿæˆå®Œæˆ\")\n",
    "print(f\"   ç« èŠ‚æ•°: {len(outline)}\")\n",
    "for i, ch in enumerate(outline):\n",
    "    print(f\"   {i+1}. {ch.get('chapter_id', 'Unknown')}: {ch.get('title', 'Unknown')}\")\n",
    "    print(f\"      Summary: {ch.get('summary', '')[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6102b5",
   "metadata": {},
   "source": [
    "# Step 2 - Chapter Reordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d4769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Step 2: Chapter Reordering ===\")\n",
    "\n",
    "# å¤åˆ¶main_pipeline.pyçš„ç« èŠ‚é‡æ’é€»è¾‘\n",
    "if reorder_mode == \"linear\":\n",
    "    reorder_outline_raw = outline\n",
    "    save_json(outline, version, \"test_outline.json\")\n",
    "    print(\"âœ… ä½¿ç”¨ linear é¡ºåºï¼ˆç›´æ¥æ¥è‡ª outlineï¼‰\")\n",
    "\n",
    "elif reorder_mode == \"nonlinear\":\n",
    "    save_json(outline, version, \"test_outline_linear.json\")\n",
    "    reorder_path = os.path.join(output_dir, \"reference_reorder\", f\"{topic}_{style}_T{temperature}_s{seed}_nonlinear.json\")\n",
    "    os.makedirs(os.path.dirname(reorder_path), exist_ok=True)\n",
    "\n",
    "    if os.path.exists(reorder_path) and use_cache:\n",
    "        reorder_outline_raw = load_json(reorder_path)\n",
    "        print(f\"ğŸ“– å·²åŠ è½½ cached nonlinear é¡ºåºï¼š{reorder_path}\")\n",
    "    else:\n",
    "        print(f\"ğŸ”„ ç”Ÿæˆnonlinearé¡ºåº...\")\n",
    "        reorder_outline_raw = reorder_chapters(outline, mode=\"nonlinear\")\n",
    "\n",
    "        # æ·»åŠ æ—¥å¿—è®°å½•\n",
    "        reorder_log_path = init_log_path(folder, \"reorder\")\n",
    "        reorder_log = build_simple_log(\n",
    "            module=\"chapter_reorder\",\n",
    "            task_name=version,\n",
    "            input_data={\"outline\": outline},\n",
    "            output_data={\"reorder_result\": reorder_outline_raw}\n",
    "        )\n",
    "        append_log(reorder_log_path, reorder_log)\n",
    "\n",
    "        # æ£€æŸ¥æ˜¯å¦çœŸçš„ç”Ÿæˆäº† new_order å­—æ®µ\n",
    "        if not any(\"new_order\" in ch for ch in reorder_outline_raw):\n",
    "            print(\"âš ï¸ LLM é‡æ’å¤±è´¥ï¼šæœªæ£€æµ‹åˆ°ä»»ä½• new_order å­—æ®µï¼Œå›é€€ä¸ºåŸå§‹é¡ºåº\")\n",
    "        else:\n",
    "            print(\"âœ… reorder_chapters æˆåŠŸç”Ÿæˆéçº¿æ€§é¡ºåº\")\n",
    "\n",
    "        save_json(reorder_outline_raw, \"reference_reorder\", f\"{topic}_{style}_T{temperature}_s{seed}_nonlinear.json\")\n",
    "        print(f\"ğŸ’¾ ç”Ÿæˆ nonlinear é¡ºåºå¹¶ç¼“å­˜ï¼š{reorder_path}\")\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"order_mode å¿…é¡»ä¸º 'linear' æˆ– 'nonlinear'\")\n",
    "\n",
    "# ç»Ÿä¸€ç»“æ„ï¼šè¡¥å…¨ summary å­—æ®µ\n",
    "reorder_outline = []\n",
    "for reordered_ch in reorder_outline_raw:\n",
    "    match = next((x for x in outline if x[\"chapter_id\"] == reordered_ch[\"chapter_id\"]), None)\n",
    "    if match:\n",
    "        merged = {\n",
    "            \"chapter_id\": reordered_ch[\"chapter_id\"],\n",
    "            \"title\": reordered_ch[\"title\"],\n",
    "            \"summary\": match.get(\"summary\", \"\")\n",
    "        }\n",
    "        if \"new_order\" in reordered_ch:\n",
    "            merged[\"new_order\"] = reordered_ch[\"new_order\"]\n",
    "        reorder_outline.append(merged)\n",
    "\n",
    "save_json(reorder_outline, version, \"test_reorder_outline.json\")\n",
    "print(\"âœ… ç« èŠ‚é¡ºåºå¤„ç†å®Œæˆï¼ˆå·²ä¿ç•™ summaryï¼‰\")\n",
    "\n",
    "# æ˜¾ç¤ºæœ€ç»ˆé¡ºåº\n",
    "print(f\"ğŸ“‹ æœ€ç»ˆç« èŠ‚é¡ºåº:\")\n",
    "for i, ch in enumerate(reorder_outline):\n",
    "    order_info = f\" (åŸé¡ºåº: {ch.get('new_order', i+1)})\" if 'new_order' in ch else \"\"\n",
    "    print(f\"   {i+1}. {ch['chapter_id']}: {ch['title']}{order_info}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeef6b79",
   "metadata": {},
   "source": [
    "# Step 3 - Character Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837dbb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Step 3: Character Generation ===\")\n",
    "\n",
    "character_path = step_file(version, \"characters.json\")\n",
    "if use_cache and os.path.exists(character_path):\n",
    "    characters = load_json(character_path)\n",
    "    print(\"ğŸ“– å·²åŠ è½½è§’è‰²è®¾å®š\")\n",
    "else:\n",
    "    print(f\"ğŸ”„ ç”Ÿæˆè§’è‰²è®¾å®š...\")\n",
    "    characters = generate_characters_v1(reorder_outline)\n",
    "    save_json(characters, version, \"characters.json\")\n",
    "    print(\"ğŸ’¾ ç”Ÿæˆè§’è‰²è®¾å®šå®Œæˆ\")\n",
    "\n",
    "print(f\"âœ… è§’è‰²ç”Ÿæˆå®Œæˆ\")\n",
    "print(f\"   è§’è‰²æ•°: {len(characters)}\")\n",
    "for i, char in enumerate(characters):\n",
    "    print(f\"   {i+1}. {char.get('name', 'Unknown')}\")\n",
    "    print(f\"      ç‰¹å¾: {char.get('traits', 'Unknown')[:50]}...\")\n",
    "    print(f\"      èƒŒæ™¯: {char.get('background', 'Unknown')[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e56ee6c",
   "metadata": {},
   "source": [
    "# Step 4 - Story Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc27600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Step 4: Story Expansion ===\")\n",
    "\n",
    "plot_path = step_file(version, \"story.json\")\n",
    "if use_cache and os.path.exists(plot_path):\n",
    "    story = load_json(plot_path)\n",
    "    print(\"ğŸ“– å·²åŠ è½½æ•…äº‹å†…å®¹\")\n",
    "else:\n",
    "    print(f\"ğŸ”„ ç”Ÿæˆæ•…äº‹å†…å®¹...\")\n",
    "    story = expand_story_v1(reorder_outline, characters, custom_instruction=\"\")\n",
    "    \n",
    "    # ç¡®ä¿æ¯ç« éƒ½æœ‰æ­£ç¡®çš„IDå’Œæ ‡é¢˜\n",
    "    for idx, ch in enumerate(story):\n",
    "        ch.setdefault(\"chapter_id\", reorder_outline[idx][\"chapter_id\"])\n",
    "        ch.setdefault(\"title\", reorder_outline[idx][\"title\"])\n",
    "\n",
    "        # è®°å½•æ—¥å¿—\n",
    "        log = build_log_record(\n",
    "            module=\"expand_story\", step=\"plot\",\n",
    "            task_name=version, chapter_id=ch[\"chapter_id\"],\n",
    "            model=behavior_model, \n",
    "            input_data={\"outline\": reorder_outline[idx]},\n",
    "            output_data={\"plot\": ch[\"plot\"]},\n",
    "            temperature=temperature, \n",
    "            seed=seed\n",
    "        )\n",
    "        append_log(plot_log_path, log)\n",
    "\n",
    "    save_json(story, version, \"story.json\")\n",
    "    print(\"ğŸ’¾ æ•…äº‹å†…å®¹ç”Ÿæˆå®Œæˆ\")\n",
    "\n",
    "print(f\"âœ… æ•…äº‹ç”Ÿæˆå®Œæˆ\")\n",
    "print(f\"   ç« èŠ‚æ•°: {len(story)}\")\n",
    "for i, ch in enumerate(story):\n",
    "    print(f\"   {i+1}. {ch.get('chapter_id', 'Unknown')}: {ch.get('title', 'Unknown')}\")\n",
    "    print(f\"      Ploté•¿åº¦: {len(ch.get('plot', ''))} å­—ç¬¦\")\n",
    "    print(f\"      Sceneé•¿åº¦: {len(ch.get('scene', ''))} å­—ç¬¦\")\n",
    "    print(f\"      Ploté¢„è§ˆ: {ch.get('plot', '')[:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c787a0",
   "metadata": {},
   "source": [
    "# Step 5&6 - æ–°ç‰ˆå¯¹è¯ç”Ÿæˆï¼ˆå…³é”®æµ‹è¯•ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716b0217",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Step 5&6: æ–°ç‰ˆå¯¹è¯ç”Ÿæˆï¼ˆå¥å­çº§åˆ†æ + ç« èŠ‚çº§å…¼å®¹ï¼‰ ===\")\n",
    "\n",
    "print(f\"ğŸ”„ å¼€å§‹åˆ†æ {len(story)} ä¸ªç« èŠ‚...\")\n",
    "\n",
    "try:\n",
    "    # è°ƒç”¨æ–°çš„v2å‡½æ•°\n",
    "    chapter_results, sentence_results, behavior_timeline = analyze_dialogue_insertions_v2(story, characters)\n",
    "    \n",
    "    print(f\"âœ… å¯¹è¯åˆ†æå®Œæˆï¼\")\n",
    "    print(f\"   Chapter results: {len(chapter_results)} ä¸ªç« èŠ‚\")\n",
    "    print(f\"   Sentence results: {len(sentence_results)} ä¸ªå¥å­\") \n",
    "    print(f\"   Behavior timeline: {len(behavior_timeline)} æ¡è®°å½•\")\n",
    "    \n",
    "    # ä¿å­˜ä¸‰ç§æ ¼å¼çš„æ•°æ®\n",
    "    save_json(chapter_results, version, \"dialogue_marks.json\")        # å…¼å®¹æ ¼å¼\n",
    "    save_json(sentence_results, version, \"sentence_dialogues.json\")    # å¥å­çº§è¯¦ç»†åˆ†æ\n",
    "    save_json(behavior_timeline, version, \"behavior_timeline_raw.json\")  # åŸå§‹behavioræ•°æ®\n",
    "    \n",
    "    # è®¾ç½®dialogue_resultä»¥ä¿æŒåç»­æµç¨‹å…¼å®¹\n",
    "    dialogue_result = chapter_results\n",
    "    print(\"ğŸ’¾ ä¸‰ç§æ ¼å¼æ•°æ®å·²ä¿å­˜\")\n",
    "    \n",
    "    # å¿«é€Ÿç»Ÿè®¡\n",
    "    print(f\"\\nğŸ“Š å¥å­åˆ†æç»Ÿè®¡:\")\n",
    "    chapter_stats = {}\n",
    "    dialogue_count = 0\n",
    "    \n",
    "    for sentence in sentence_results:\n",
    "        chapter_id = sentence['chapter_id']\n",
    "        if chapter_id not in chapter_stats:\n",
    "            chapter_stats[chapter_id] = {'total': 0, 'dialogue': 0}\n",
    "        chapter_stats[chapter_id]['total'] += 1\n",
    "        if sentence['need_to_action'] == 1:\n",
    "            chapter_stats[chapter_id]['dialogue'] += 1\n",
    "            dialogue_count += 1\n",
    "    \n",
    "    print(f\"   æ€»å¥å­æ•°: {len(sentence_results)}\")\n",
    "    print(f\"   éœ€è¦å¯¹è¯çš„å¥å­: {dialogue_count}\")\n",
    "    \n",
    "    for chapter_id, stats in chapter_stats.items():\n",
    "        print(f\"   {chapter_id}: {stats['total']} å¥ï¼Œ{stats['dialogue']} å¥éœ€å¯¹è¯\")\n",
    "    \n",
    "    # Behaviorç»Ÿè®¡\n",
    "    if behavior_timeline:\n",
    "        behavior_chars = {}\n",
    "        for behavior in behavior_timeline:\n",
    "            char = behavior['character']\n",
    "            if char not in behavior_chars:\n",
    "                behavior_chars[char] = 0\n",
    "            behavior_chars[char] += 1\n",
    "        \n",
    "        print(f\"\\nğŸ‘¥ Behaviorç»Ÿè®¡:\")\n",
    "        for char, count in behavior_chars.items():\n",
    "            print(f\"   {char}: {count} ä¸ªè¡Œä¸º\")\n",
    "    \n",
    "    print(f\"âœ… æ–°ç‰ˆå¯¹è¯ç”Ÿæˆå®Œæˆ\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ å¯¹è¯ç”Ÿæˆå¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    # å¦‚æœå¤±è´¥ï¼Œå¯ä»¥åœ¨è¿™é‡Œåœæ­¢æˆ–ä½¿ç”¨æ—§æ–¹æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfacbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœ¨ Step 5&6 ä¹‹åæ·»åŠ \n",
    "print(\"\\n=== éªŒè¯å¥å­çº§å¯¹è¯æ•°æ® ===\")\n",
    "\n",
    "# æ£€æŸ¥ä¿å­˜çš„æ–‡ä»¶\n",
    "sentence_dialogues_path = os.path.join(folder, \"sentence_dialogues.json\")\n",
    "if os.path.exists(sentence_dialogues_path):\n",
    "    saved_sentence_data = load_json(sentence_dialogues_path)\n",
    "    print(f\"âœ… sentence_dialogues.json å­˜åœ¨ï¼ŒåŒ…å« {len(saved_sentence_data)} ä¸ªå¥å­\")\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦æœ‰dialogueå’Œaction\n",
    "    dialogues_with_action = 0\n",
    "    for sentence in saved_sentence_data:\n",
    "        if sentence.get(\"dialogue\"):\n",
    "            for d in sentence[\"dialogue\"]:\n",
    "                if d.get(\"action\"):\n",
    "                    dialogues_with_action += 1\n",
    "                    print(f\"   æ‰¾åˆ°action: {d['speaker']}: {d['action']}\")\n",
    "                    break  # åªæ‰“å°ç¬¬ä¸€ä¸ªä½œä¸ºç¤ºä¾‹\n",
    "    \n",
    "    print(f\"ğŸ“Š æœ‰ {dialogues_with_action} ä¸ªå¥å­åŒ…å«å¸¦actionçš„å¯¹è¯\")\n",
    "else:\n",
    "    print(\"âŒ sentence_dialogues.json ä¸å­˜åœ¨ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcbae82",
   "metadata": {},
   "source": [
    "# Step 8 - æ£€æŸ¥é•¿åº¦åŒ¹é…å’Œè®°å½•æ—¥å¿—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162685b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å’Œæ—¥å¿—è®°å½• ===\")\n",
    "\n",
    "# æ£€æŸ¥é•¿åº¦æ˜¯å¦åŒ¹é…\n",
    "if len(story) != len(dialogue_result):\n",
    "    print(f\"âš ï¸ è­¦å‘Šï¼šstory æœ‰ {len(story)} ç« ï¼Œä½† dialogue_result åªæœ‰ {len(dialogue_result)} æ¡å¯¹ç™½\")\n",
    "else:\n",
    "    print(f\"âœ… æ•°æ®é•¿åº¦åŒ¹é…ï¼š{len(story)} ç« èŠ‚\")\n",
    "\n",
    "# è®°å½•å¯¹è¯ç”Ÿæˆæ—¥å¿—\n",
    "print(f\"ğŸ“ è®°å½•å¯¹è¯ç”Ÿæˆæ—¥å¿—...\")\n",
    "for ch, dlg in zip(story, dialogue_result):\n",
    "    log = build_log_record(\n",
    "        module=\"dialogue_inserter\", step=\"dialogue\",\n",
    "        task_name=version, chapter_id=ch[\"chapter_id\"],\n",
    "        model=behavior_model,\n",
    "        input_data={\"plot\": ch[\"plot\"]},\n",
    "        output_data={\"dialogue\": dlg[\"dialogue\"]},\n",
    "        temperature=temperature, seed=seed\n",
    "    )\n",
    "    append_log(dialogue_log_path, log)\n",
    "\n",
    "print(f\"âœ… æ—¥å¿—è®°å½•å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6eac7f",
   "metadata": {},
   "source": [
    "# Step 6.5 - æ–°ç‰ˆBehaviorå¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162bfe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Step 6.5: æ–°ç‰ˆBehaviorå¤„ç† ===\")\n",
    "\n",
    "# ç»„ç»‡è§’è‰²å¼§çº¿\n",
    "character_arcs = {}\n",
    "for item in behavior_timeline:\n",
    "    char = item[\"character\"]\n",
    "    if char not in character_arcs:\n",
    "        character_arcs[char] = []\n",
    "    character_arcs[char].append({\n",
    "        \"chapter\": item[\"chapter_id\"],\n",
    "        \"sentence\": item[\"sentence_index\"],\n",
    "        \"behavior\": item[\"behavior\"],\n",
    "        \"scene\": item[\"scene_context\"][:30] + \"...\" if len(item[\"scene_context\"]) > 30 else item[\"scene_context\"]\n",
    "    })\n",
    "\n",
    "# ç”Ÿæˆå®Œæ•´çš„behavior_trace\n",
    "behavior_trace = {\n",
    "    \"timeline\": behavior_timeline,\n",
    "    \"character_arcs\": character_arcs,\n",
    "    \"statistics\": {\n",
    "        \"total_dialogue_moments\": len(behavior_timeline),\n",
    "        \"characters_behavior_count\": {char: len(arcs) for char, arcs in character_arcs.items()}\n",
    "    },\n",
    "    \"legacy_behaviors\": [f\"{item['character']}ï¼š{item['behavior']}\" for item in behavior_timeline]\n",
    "}\n",
    "\n",
    "save_json(behavior_trace, version, \"behavior_trace.json\")\n",
    "\n",
    "# å…¼å®¹role_state\n",
    "role_state = {}\n",
    "for item in behavior_timeline:\n",
    "    role = item[\"character\"]\n",
    "    behavior_item = item[\"behavior\"]\n",
    "    role_state.setdefault(role, [])\n",
    "    if behavior_item not in role_state[role]:\n",
    "        role_state[role].append(behavior_item)\n",
    "\n",
    "print(f\"âœ… æ–°ç‰ˆbehavior traceç”Ÿæˆå®Œæˆ\")\n",
    "print(f\"ğŸ“Š è§’è‰²å¼§çº¿ç»Ÿè®¡:\")\n",
    "for char, arcs in character_arcs.items():\n",
    "    print(f\"   {char}: {len(arcs)} ä¸ªè¡Œä¸ºèŠ‚ç‚¹\")\n",
    "\n",
    "# æ˜¾ç¤ºè§’è‰²å¼§çº¿ç¤ºä¾‹\n",
    "print(f\"\\nğŸ‘¤ è§’è‰²å¼§çº¿ç¤ºä¾‹ï¼ˆæ¯ä¸ªè§’è‰²å‰3ä¸ªè¡Œä¸ºï¼‰:\")\n",
    "for char, arcs in character_arcs.items():\n",
    "    print(f\"   {char}:\")\n",
    "    for i, arc in enumerate(arcs[:3]):\n",
    "        print(f\"      {i+1}. {arc['chapter']}ç¬¬{arc['sentence']+1}å¥: {arc['behavior']}\")\n",
    "    if len(arcs) > 3:\n",
    "        print(f\"      ... è¿˜æœ‰ {len(arcs)-3} ä¸ªè¡Œä¸º\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba6fd6e",
   "metadata": {},
   "source": [
    "# Step 6.7 - è”åŠ¨æœºåˆ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf75758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6.7 - è”åŠ¨æœºåˆ¶\n",
    "print(\"=== Step 6.7: è”åŠ¨æœºåˆ¶ ===\")\n",
    "\n",
    "print(f\"ğŸ”„ è¿è¡Œplotå’Œdialogueè”åŠ¨æœºåˆ¶...\")\n",
    "try:\n",
    "    # ä½¿ç”¨ç« èŠ‚çº§æ•°æ®è¿›è¡Œsync\n",
    "    story, chapter_results_updated, revision_log = sync_plot_and_dialogue_from_behavior(\n",
    "        story, chapter_results, characters, model=behavior_model)\n",
    "    \n",
    "    print(f\"âœ… è”åŠ¨æœºåˆ¶å®Œæˆ\")\n",
    "    print(f\"   ä¿®è®¢è®°å½•æ•°: {len(revision_log) if revision_log else 0}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ è”åŠ¨æœºåˆ¶å‡ºé”™: {e}\")\n",
    "    chapter_results_updated = chapter_results  # æ·»åŠ è¿™è¡Œ\n",
    "    revision_log = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34311294",
   "metadata": {},
   "source": [
    "# Step 7 - ä¿å­˜æ‰€æœ‰è¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f1c7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7 - ä¿å­˜æ‰€æœ‰è¾“å‡º\n",
    "print(\"=== Step 7: ä¿å­˜æ‰€æœ‰è¾“å‡º ===\")\n",
    "\n",
    "# ä¿å­˜æ ¸å¿ƒæ•°æ®\n",
    "save_json(role_state, version, \"role_state.json\")\n",
    "save_json(story, version, \"story_updated.json\")\n",
    "save_json(sentence_results, version, \"dialogue_updated.json\")  # æ”¹ä¸ºä¿å­˜å¥å­çº§ï¼\n",
    "save_json(revision_log, version, \"revision_log.json\")\n",
    "\n",
    "print(f\"ğŸ’¾ æ ¸å¿ƒæ•°æ®å·²ä¿å­˜\")\n",
    "\n",
    "# ç”Ÿæˆå°è¯´æ–‡ä»¶\n",
    "print(f\"ğŸ“š ç”Ÿæˆå°è¯´æ–‡ä»¶...\")\n",
    "\n",
    "# ä½¿ç”¨ç« èŠ‚çº§ç¼–è¯‘ï¼ˆä½œä¸ºå¯¹æ¯”ï¼‰\n",
    "compiled_story = compile_full_story_by_chapter(story, chapter_results_updated)\n",
    "save_md(compiled_story, os.path.join(folder, \"novel_story_chapter.md\"))\n",
    "print(f\"   âœ… novel_story_chapter.md å·²ç”Ÿæˆï¼ˆç« èŠ‚çº§ï¼‰\")\n",
    "\n",
    "# ä½¿ç”¨å¥å­çº§ç²¾ç¡®ç¼–è¯‘ï¼ˆä¸»è¦è¾“å‡ºï¼‰\n",
    "compiled_updated = compile_full_story_by_sentence(story, sentence_results)\n",
    "save_md(compiled_updated, os.path.join(folder, \"novel_story.md\"))  # ä¹Ÿä¿å­˜ä¸ºä¸»æ–‡ä»¶\n",
    "print(f\"   âœ… novel_story.md å·²ç”Ÿæˆï¼ˆå¥å­çº§ç²¾ç¡®ï¼‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a715d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœ¨ Step 7 ç¼–è¯‘å°è¯´åæ·»åŠ \n",
    "print(\"\\n=== éªŒè¯ç¼–è¯‘ç»“æœ ===\")\n",
    "\n",
    "# è¯»å–å¹¶æ£€æŸ¥novel_story.md\n",
    "novel_path = os.path.join(folder, \"novel_story.md\")\n",
    "if os.path.exists(novel_path):\n",
    "    with open(novel_path, 'r', encoding='utf-8') as f:\n",
    "        novel_content = f.read()\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦æœ‰å¸¦actionçš„å¯¹è¯æ ¼å¼\n",
    "    import re\n",
    "    # åŒ¹é… \"è§’è‰²xxxï¼Œ\"å¯¹è¯\" â€”â€”è§’è‰²\" çš„æ ¼å¼\n",
    "    action_pattern = r'(\\w+)([^ï¼Œ]+)ï¼Œ\"([^\"]+)\" â€”â€”\\1'\n",
    "    action_matches = re.findall(action_pattern, novel_content)\n",
    "    \n",
    "    print(f\"âœ… æ‰¾åˆ° {len(action_matches)} ä¸ªå¸¦actionçš„å¯¹è¯\")\n",
    "    if action_matches:\n",
    "        print(\"ç¤ºä¾‹ï¼š\")\n",
    "        for i, (speaker, action, dialogue) in enumerate(action_matches[:3]):\n",
    "            print(f\"   {i+1}. {speaker}{action}ï¼Œ\\\"{dialogue}\\\" â€”â€”{speaker}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ca2de7",
   "metadata": {},
   "source": [
    "# Step 8 - å¢å¼ºå¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b673e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Step 8: å¢å¼ºå¤„ç† ===\")\n",
    "\n",
    "print(f\"ğŸ”„ è¿è¡Œæ•…äº‹å¢å¼º...\")\n",
    "try:\n",
    "    enhance_story_with_transitions(task_name=version, input_story_file=\"story_updated.json\")\n",
    "    print(f\"   âœ… æ•…äº‹è¿‡æ¸¡å¢å¼ºå®Œæˆ\")\n",
    "except Exception as e:\n",
    "    print(f\"   âš ï¸ æ•…äº‹å¢å¼ºå¤±è´¥: {e}\")\n",
    "\n",
    "print(f\"ğŸ”„ è¿è¡Œå¯¹è¯æ¶¦è‰²...\")\n",
    "try:\n",
    "    polish_dialogues_in_story(task_name=version, input_dialogue_file=\"dialogue_updated.json\")\n",
    "    print(f\"   âœ… å¯¹è¯æ¶¦è‰²å®Œæˆ\")\n",
    "except Exception as e:\n",
    "    print(f\"   âš ï¸ å¯¹è¯æ¶¦è‰²å¤±è´¥: {e}\")\n",
    "\n",
    "print(f\"ğŸ”„ è¿è¡Œè§’è‰²çŠ¶æ€è¿½è¸ª...\")\n",
    "try:\n",
    "    run_character_state_tracker(version=version, dialogue_file=\"dialogue_updated.json\", model=behavior_model)\n",
    "    print(f\"   âœ… è§’è‰²çŠ¶æ€è¿½è¸ªå®Œæˆ\")\n",
    "except Exception as e:\n",
    "    print(f\"   âš ï¸ è§’è‰²çŠ¶æ€è¿½è¸ªå¤±è´¥: {e}\")\n",
    "\n",
    "print(f\"âœ… å¢å¼ºå¤„ç†å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7020d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœ¨ Step 8 ä¹‹åæ·»åŠ \n",
    "print(\"\\n=== éªŒè¯å¢å¼ºç‰ˆæœ¬ ===\")\n",
    "\n",
    "enhanced_path = os.path.join(folder, \"enhanced_story_dialogue_updated.md\")\n",
    "if os.path.exists(enhanced_path):\n",
    "    with open(enhanced_path, 'r', encoding='utf-8') as f:\n",
    "        enhanced_content = f.read()\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰åŸå§‹æ ¼å¼çš„å¯¹è¯\n",
    "    original_format_count = enhanced_content.count('\" â€”â€”')\n",
    "    print(f\"ğŸ“Š å¢å¼ºç‰ˆæœ¬ä¸­åŸå§‹æ ¼å¼å¯¹è¯æ•°: {original_format_count}\")\n",
    "    \n",
    "    if original_format_count == 0:\n",
    "        print(\"âœ… æ‰€æœ‰å¯¹è¯éƒ½å·²è‡ªç„¶åŒ–ï¼\")\n",
    "    else:\n",
    "        print(\"âš ï¸ è¿˜æœ‰éƒ¨åˆ†å¯¹è¯æœªè¢«æ¶¦è‰²\")\n",
    "    \n",
    "    # é¢„è§ˆå¢å¼ºæ•ˆæœ\n",
    "    print(\"\\nğŸ“– å¢å¼ºç‰ˆæœ¬é¢„è§ˆï¼ˆå‰800å­—ç¬¦ï¼‰ï¼š\")\n",
    "    print(enhanced_content[:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a7e06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_action_flow(version):\n",
    "    \"\"\"è°ƒè¯•actionä¿¡æ¯çš„å®Œæ•´æµç¨‹\"\"\"\n",
    "    print(\"ğŸ” è°ƒè¯•ACTIONä¿¡æ¯æµç¨‹\")\n",
    "    \n",
    "    folder = os.path.join(output_dir, version)\n",
    "    \n",
    "    # 1. æ£€æŸ¥dialogue_updated.json\n",
    "    dialogue_path = os.path.join(folder, \"dialogue_updated.json\")\n",
    "    if os.path.exists(dialogue_path):\n",
    "        dialogue_data = load_json(dialogue_path)\n",
    "        \n",
    "        action_count = 0\n",
    "        action_examples = []\n",
    "        \n",
    "        for sentence in dialogue_data:\n",
    "            if sentence.get(\"dialogue\"):\n",
    "                for d in sentence[\"dialogue\"]:\n",
    "                    if d.get(\"action\"):\n",
    "                        action_count += 1\n",
    "                        if len(action_examples) < 3:\n",
    "                            action_examples.append({\n",
    "                                \"chapter\": sentence[\"chapter_id\"],\n",
    "                                \"sentence\": sentence[\"sentence_index\"],\n",
    "                                \"speaker\": d[\"speaker\"],\n",
    "                                \"action\": d[\"action\"],\n",
    "                                \"dialogue\": d[\"dialogue\"]\n",
    "                            })\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Actionç»Ÿè®¡ï¼š\")\n",
    "        print(f\"   æ€»actionæ•°: {action_count}\")\n",
    "        print(f\"\\nğŸ¯ Actionç¤ºä¾‹ï¼š\")\n",
    "        for ex in action_examples:\n",
    "            print(f\"   {ex['chapter']} å¥{ex['sentence']+1}:\")\n",
    "            print(f\"   {ex['speaker']}: {ex['action']}\")\n",
    "            print(f'   å¯¹è¯: \"{ex[\"dialogue\"]}\"')  # ä¿®å¤ï¼šä½¿ç”¨å•å¼•å·åŒ…è£¹ï¼Œå†…éƒ¨ç”¨åŒå¼•å·\n",
    "            print()\n",
    "    \n",
    "    # 2. æ£€æŸ¥novel_story.mdä¸­çš„action\n",
    "    novel_path = os.path.join(folder, \"novel_story.md\")\n",
    "    if os.path.exists(novel_path):\n",
    "        with open(novel_path, 'r', encoding='utf-8') as f:\n",
    "            novel = f.read()\n",
    "        \n",
    "        # æŸ¥æ‰¾å¸¦é€—å·çš„æ ¼å¼\n",
    "        import re\n",
    "        pattern = r'([^ï¼Œ\\n]+)ï¼Œ\"([^\"]+)\" â€”â€”(\\w+)'\n",
    "        matches = re.findall(pattern, novel)\n",
    "        \n",
    "        print(f\"\\nğŸ“– å°è¯´ä¸­çš„Actionæ ¼å¼ï¼š\")\n",
    "        print(f\"   æ‰¾åˆ° {len(matches)} ä¸ªå¯èƒ½çš„actionæ ¼å¼\")\n",
    "        if matches:\n",
    "            print(f\"\\nç¤ºä¾‹ï¼š\")\n",
    "            for i, (action_part, dialogue, speaker) in enumerate(matches[:3]):\n",
    "                if speaker in action_part:\n",
    "                    print(f'   {i+1}. {action_part}ï¼Œ\"{dialogue}\" â€”â€”{speaker}')  # ä¿®å¤\n",
    "    \n",
    "    # 3. æ£€æŸ¥enhancedç‰ˆæœ¬\n",
    "    enhanced_path = os.path.join(folder, \"enhanced_story_dialogue_updated.md\")\n",
    "    if os.path.exists(enhanced_path):\n",
    "        print(f\"\\nğŸ“š å¢å¼ºç‰ˆæœ¬å­˜åœ¨ï¼š{enhanced_path}\")\n",
    "        print(f\"   å¯ä»¥æ£€æŸ¥æ¶¦è‰²æ•ˆæœ\")\n",
    "    \n",
    "    return action_count > 0\n",
    "\n",
    "# è¿è¡Œè°ƒè¯•\n",
    "if debug_action_flow(version):\n",
    "    print(\"\\nâœ… Actionä¿¡æ¯æµç¨‹æ­£å¸¸ï¼\")\n",
    "else:\n",
    "    print(\"\\nâŒ æœªæ£€æµ‹åˆ°Actionä¿¡æ¯\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871a7d14",
   "metadata": {},
   "source": [
    "# æœ€ç»ˆç»“æœæ£€æŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a87e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== æœ€ç»ˆç»“æœæ£€æŸ¥ ===\")\n",
    "\n",
    "# æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶\n",
    "output_files = [\n",
    "    \"story.json\", \"characters.json\", \"dialogue_marks.json\",\n",
    "    \"sentence_analysis.json\", \"behavior_timeline_raw.json\", \"behavior_trace.json\",\n",
    "    \"story_updated.json\", \"dialogue_updated.json\", \"role_state.json\",\n",
    "    \"novel_story.md\", \"novel_story_updated.md\"\n",
    "]\n",
    "\n",
    "print(f\"ğŸ“ æ£€æŸ¥è¾“å‡ºæ–‡ä»¶:\")\n",
    "for filename in output_files:\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        size = os.path.getsize(filepath)\n",
    "        print(f\"   âœ… {filename}: {size} bytes\")\n",
    "    else:\n",
    "        print(f\"   âŒ {filename}: ç¼ºå¤±\")\n",
    "\n",
    "# æ˜¾ç¤ºå…³é”®ç»Ÿè®¡\n",
    "print(f\"\\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:\")\n",
    "print(f\"   ç‰ˆæœ¬åç§°: {version}\")\n",
    "print(f\"   è¾“å‡ºç›®å½•: {folder}\")\n",
    "print(f\"   æ•…äº‹ç« èŠ‚æ•°: {len(story)}\")\n",
    "print(f\"   è§’è‰²æ•°é‡: {len(characters)}\")\n",
    "print(f\"   å¥å­åˆ†ææ•°é‡: {len(sentence_results)}\")\n",
    "print(f\"   è¡Œä¸ºè®°å½•æ•°é‡: {len(behavior_timeline)}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ å®Œæ•´æµç¨‹æ‰§è¡Œå®Œæ¯•ï¼\")\n",
    "print(f\"ğŸ“‚ æ‰€æœ‰æ–‡ä»¶ä¿å­˜åœ¨: {folder}\")\n",
    "\n",
    "# æ˜¾ç¤ºç”Ÿæˆçš„å°è¯´é¢„è§ˆ\n",
    "try:\n",
    "    with open(os.path.join(folder, \"novel_story.md\"), 'r', encoding='utf-8') as f:\n",
    "        novel_content = f.read()\n",
    "    print(f\"\\nğŸ“– ç”Ÿæˆå°è¯´é¢„è§ˆï¼ˆå‰500å­—ç¬¦ï¼‰:\")\n",
    "    print(f\"{novel_content[:500]}...\")\n",
    "except:\n",
    "    print(f\"âŒ æ— æ³•è¯»å–ç”Ÿæˆçš„å°è¯´æ–‡ä»¶\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a3d2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœ¨ä½ çš„notebookä¸­è¿è¡Œè¿™ä¸ªè°ƒè¯•ä»£ç \n",
    "\n",
    "print(\"ğŸ” è°ƒè¯•sentence_resultsæ•°æ®...\")\n",
    "\n",
    "# 1. æ£€æŸ¥sentence_resultsçš„ç»“æ„\n",
    "if 'sentence_results' in locals() and sentence_results:\n",
    "    print(f\"âœ… sentence_resultså­˜åœ¨ï¼Œæ•°é‡: {len(sentence_results)}\")\n",
    "    \n",
    "    # æ£€æŸ¥å‰å‡ ä¸ªå¥å­çš„ç»“æ„\n",
    "    print(f\"\\nğŸ“Š å‰3ä¸ªå¥å­çš„ç»“æ„:\")\n",
    "    for i, sentence in enumerate(sentence_results[:3]):\n",
    "        print(f\"å¥å­{i+1}:\")\n",
    "        print(f\"  ç« èŠ‚: {sentence.get('chapter_id', 'Unknown')}\")\n",
    "        print(f\"  å¥å­ç´¢å¼•: {sentence.get('sentence_index', 'Unknown')}\")\n",
    "        print(f\"  éœ€è¦å¯¹è¯: {sentence.get('need_to_action', 0)}\")\n",
    "        print(f\"  æ¼”å‘˜: {sentence.get('actor_list', [])}\")\n",
    "        print(f\"  æœ‰dialogueå­—æ®µ: {'dialogue' in sentence}\")\n",
    "        \n",
    "        if sentence.get('dialogue'):\n",
    "            print(f\"  å¯¹è¯æ•°é‡: {len(sentence['dialogue'])}\")\n",
    "            if sentence['dialogue']:\n",
    "                print(f\"  ç¬¬ä¸€ä¸ªå¯¹è¯: {sentence['dialogue'][0]}\")\n",
    "        else:\n",
    "            print(f\"  å¯¹è¯: ç©º\")\n",
    "        print()\n",
    "    \n",
    "    # ç»Ÿè®¡æœ‰å¯¹è¯çš„å¥å­\n",
    "    dialogue_sentences = [s for s in sentence_results if s.get('need_to_action') == 1 and s.get('dialogue')]\n",
    "    print(f\"ğŸ“ˆ ç»Ÿè®¡:\")\n",
    "    print(f\"  æ€»å¥å­æ•°: {len(sentence_results)}\")\n",
    "    print(f\"  éœ€è¦å¯¹è¯çš„å¥å­: {len([s for s in sentence_results if s.get('need_to_action') == 1])}\")\n",
    "    print(f\"  å®é™…æœ‰å¯¹è¯æ•°æ®çš„å¥å­: {len(dialogue_sentences)}\")\n",
    "    \n",
    "    if dialogue_sentences:\n",
    "        print(f\"\\nâœ… æœ‰å¯¹è¯çš„å¥å­ç¤ºä¾‹:\")\n",
    "        sample = dialogue_sentences[0]\n",
    "        print(f\"  ç« èŠ‚: {sample['chapter_id']}\")\n",
    "        print(f\"  å¥å­ç´¢å¼•: {sample['sentence_index']}\")\n",
    "        print(f\"  å¥å­å†…å®¹: {sample['sentence'][:50]}...\")\n",
    "        print(f\"  å¯¹è¯æ•°é‡: {len(sample['dialogue'])}\")\n",
    "        print(f\"  å¯¹è¯ç¤ºä¾‹: {sample['dialogue'][0] if sample['dialogue'] else 'None'}\")\n",
    "    else:\n",
    "        print(f\"âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰å¯¹è¯æ•°æ®çš„å¥å­ï¼\")\n",
    "        \n",
    "else:\n",
    "    print(f\"âŒ sentence_resultsä¸å­˜åœ¨æˆ–ä¸ºç©º\")\n",
    "\n",
    "# 2. æ£€æŸ¥compile_full_story_by_sentenceçš„æ˜ å°„é€»è¾‘\n",
    "print(f\"\\nğŸ” æµ‹è¯•å¯¹è¯æ˜ å°„é€»è¾‘...\")\n",
    "\n",
    "if 'sentence_results' in locals() and sentence_results:\n",
    "    # æ¨¡æ‹Ÿcompile_full_story_by_sentenceçš„æ˜ å°„é€»è¾‘\n",
    "    dialogue_map = {}\n",
    "    for item in sentence_results:\n",
    "        if item.get(\"need_to_action\") == 1 and item.get(\"dialogue\"):\n",
    "            chapter_id = item[\"chapter_id\"]\n",
    "            sentence_idx = item[\"sentence_index\"]\n",
    "            \n",
    "            if chapter_id not in dialogue_map:\n",
    "                dialogue_map[chapter_id] = {}\n",
    "            dialogue_map[chapter_id][sentence_idx] = item[\"dialogue\"]\n",
    "    \n",
    "    print(f\"ğŸ“‹ å¯¹è¯æ˜ å°„ç»“æœ:\")\n",
    "    for chapter_id, chapter_dialogues in dialogue_map.items():\n",
    "        print(f\"  {chapter_id}: {len(chapter_dialogues)} ä¸ªå¥å­æœ‰å¯¹è¯\")\n",
    "        for sent_idx, dialogues in list(chapter_dialogues.items())[:2]:  # åªæ˜¾ç¤ºå‰2ä¸ª\n",
    "            print(f\"    å¥å­{sent_idx}: {len(dialogues)} æ¡å¯¹è¯\")\n",
    "    \n",
    "    if not dialogue_map:\n",
    "        print(f\"âŒ å¯¹è¯æ˜ å°„ä¸ºç©ºï¼è¿™å°±æ˜¯é—®é¢˜æ‰€åœ¨\")\n",
    "    else:\n",
    "        print(f\"âœ… å¯¹è¯æ˜ å°„æ­£å¸¸\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd476231",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===============================================\n",
    "# æ–¹æ¡ˆ1: é‡æ–°åˆ†é…å¯¹è¯åˆ°å¥å­çº§ï¼ˆåœ¨notebookä¸­è¿è¡Œï¼‰\n",
    "# ===============================================\n",
    "\n",
    "def redistribute_dialogues_to_sentences(story, chapter_results, sentence_results):\n",
    "    \"\"\"\n",
    "    å°†ç« èŠ‚çº§å¯¹è¯é‡æ–°åˆ†é…åˆ°å¥å­çº§\n",
    "    \"\"\"\n",
    "    print(\"ğŸ”„ é‡æ–°åˆ†é…å¯¹è¯åˆ°å¥å­çº§...\")\n",
    "    \n",
    "    # æŒ‰ç« èŠ‚åˆ†ç»„\n",
    "    chapters_sentences = {}\n",
    "    for sentence in sentence_results:\n",
    "        chapter_id = sentence['chapter_id']\n",
    "        if chapter_id not in chapters_sentences:\n",
    "            chapters_sentences[chapter_id] = []\n",
    "        chapters_sentences[chapter_id].append(sentence)\n",
    "    \n",
    "    # é‡æ–°åˆ†é…å¯¹è¯\n",
    "    fixed_sentence_results = []\n",
    "    \n",
    "    for chapter_idx, chapter_result in enumerate(chapter_results):\n",
    "        chapter_id = story[chapter_idx].get('chapter_id', f'Chapter {chapter_idx+1}')\n",
    "        chapter_dialogues = chapter_result.get('dialogue', [])\n",
    "        \n",
    "        # è·å–è¿™ä¸ªç« èŠ‚çš„å¥å­\n",
    "        chapter_sentences = chapters_sentences.get(chapter_id, [])\n",
    "        need_dialogue_sentences = [s for s in chapter_sentences if s.get('need_to_action') == 1]\n",
    "        \n",
    "        print(f\"  {chapter_id}: {len(chapter_dialogues)} æ¡å¯¹è¯ï¼Œ{len(need_dialogue_sentences)} ä¸ªå¥å­éœ€è¦å¯¹è¯\")\n",
    "        \n",
    "        # åˆ†é…å¯¹è¯åˆ°å¥å­\n",
    "        if chapter_dialogues and need_dialogue_sentences:\n",
    "            dialogues_per_sentence = len(chapter_dialogues) // len(need_dialogue_sentences)\n",
    "            remaining_dialogues = len(chapter_dialogues) % len(need_dialogue_sentences)\n",
    "            \n",
    "            dialogue_idx = 0\n",
    "            for sentence in chapter_sentences:\n",
    "                if sentence.get('need_to_action') == 1 and dialogue_idx < len(chapter_dialogues):\n",
    "                    # åˆ†é…å¯¹è¯\n",
    "                    num_dialogues = dialogues_per_sentence\n",
    "                    if remaining_dialogues > 0:\n",
    "                        num_dialogues += 1\n",
    "                        remaining_dialogues -= 1\n",
    "                    \n",
    "                    sentence_dialogues = chapter_dialogues[dialogue_idx:dialogue_idx + num_dialogues]\n",
    "                    sentence['dialogue'] = sentence_dialogues\n",
    "                    dialogue_idx += num_dialogues\n",
    "                    \n",
    "                    print(f\"    å¥å­{sentence['sentence_index']}: åˆ†é…äº† {len(sentence_dialogues)} æ¡å¯¹è¯\")\n",
    "                else:\n",
    "                    sentence['dialogue'] = []\n",
    "                \n",
    "                fixed_sentence_results.append(sentence)\n",
    "        else:\n",
    "            # æ²¡æœ‰å¯¹è¯çš„ç« èŠ‚\n",
    "            for sentence in chapter_sentences:\n",
    "                sentence['dialogue'] = []\n",
    "                fixed_sentence_results.append(sentence)\n",
    "    \n",
    "    return fixed_sentence_results\n",
    "\n",
    "# è¿è¡Œé‡æ–°åˆ†é…\n",
    "if 'sentence_results' in locals() and 'chapter_results' in locals():\n",
    "    print(\"ğŸ”§ å¼€å§‹é‡æ–°åˆ†é…å¯¹è¯...\")\n",
    "    fixed_sentence_results = redistribute_dialogues_to_sentences(story, chapter_results, sentence_results)\n",
    "    \n",
    "    # éªŒè¯ç»“æœ\n",
    "    dialogue_count = len([s for s in fixed_sentence_results if s.get('dialogue')])\n",
    "    print(f\"âœ… é‡æ–°åˆ†é…å®Œæˆï¼Œ{dialogue_count} ä¸ªå¥å­æœ‰å¯¹è¯æ•°æ®\")\n",
    "    \n",
    "    # ä¿å­˜ä¿®æ­£åçš„æ•°æ®\n",
    "    save_json(fixed_sentence_results, version, \"sentence_dialogues_fixed.json\")\n",
    "    \n",
    "    # é‡æ–°ç¼–è¯‘å°è¯´\n",
    "    print(\"ğŸ“– ä½¿ç”¨ä¿®æ­£åçš„æ•°æ®é‡æ–°ç¼–è¯‘å°è¯´...\")\n",
    "    compiled_fixed = compile_full_story_by_sentence(story, fixed_sentence_results)\n",
    "    save_md(compiled_fixed, os.path.join(folder, \"novel_story_SENTENCE_FIXED.md\"))\n",
    "    \n",
    "    # æ£€æŸ¥ç»“æœ\n",
    "    dialogue_in_novel = compiled_fixed.count('\" â€”â€”')\n",
    "    print(f\"âœ… ä¿®æ­£ç‰ˆå°è¯´ç”Ÿæˆå®Œæˆï¼Œæ£€æµ‹åˆ° {dialogue_in_novel} æ¡å¯¹è¯\")\n",
    "    \n",
    "    if dialogue_in_novel > 0:\n",
    "        print(\"ğŸ‰ æˆåŠŸï¼å¯¹è¯å·²æŒ‰å¥å­ç²¾ç¡®æ’å…¥\")\n",
    "        # é¢„è§ˆ\n",
    "        print(f\"\\nğŸ“– é¢„è§ˆï¼ˆå‰800å­—ç¬¦ï¼‰:\")\n",
    "        print(compiled_fixed[:800])\n",
    "    else:\n",
    "        print(\"âŒ ä»ç„¶æ²¡æœ‰å¯¹è¯ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c0a317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# è¯»å– story.json æ–‡ä»¶\n",
    "with open(\"/Users/haha/Story/data/output/å°çº¢å¸½_ç§‘å¹»_linear_T0.7_s1/story.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# æå–æ‰€æœ‰ plot\n",
    "plots = [item[\"plot\"] for item in data if \"plot\" in item]\n",
    "\n",
    "# è¾“å‡ºåˆ°å±å¹•\n",
    "for i, plot in enumerate(plots, 1):\n",
    "    print(f\"Chapter {i}:\\n{plot}\\n{'-'*50}\\n\")\n",
    "\n",
    "# ä¹Ÿå¯ä»¥ä¿å­˜åˆ°ä¸€ä¸ª txt æ–‡ä»¶\n",
    "with open(\"plots.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, plot in enumerate(plots, 1):\n",
    "        f.write(f\"Chapter {i}:\\n{plot}\\n{'-'*50}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cca735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bc47f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb1d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cfdd8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafbd855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e96833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94086a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== behavior_trace.json åˆ†æ ===\n",
      "timeline è®°å½•æ•°: 311\n",
      "0: Chapter 1, å°çº¢å¸½: è°¨æ…\n",
      "1: Chapter 1, å°çº¢å¸½: æœä»\n",
      "2: Chapter 1, å°çº¢å¸½: ç§¯æå‡†å¤‡\n",
      "3: Chapter 1, æ®–æ°‘æ˜Ÿçƒç®¡ç†å‘˜ï¼ˆæ—åšå£«ï¼‰: å†·é™\n",
      "4: Chapter 1, æ®–æ°‘æ˜Ÿçƒç®¡ç†å‘˜ï¼ˆæ—åšå£«ï¼‰: æŒ‡å¯¼\n",
      "\n",
      "=== role_state.json åˆ†æ ===\n",
      "ç« èŠ‚æ•°: 31\n",
      "ç« èŠ‚åˆ—è¡¨: ['Chapter 3', 'Chapter 5', 'Chapter 10', 'Chapter 14', 'Chapter 15', 'Chapter 20', 'Chapter 21', 'Chapter 22', 'Chapter 23', 'Chapter 24'] ...\n"
     ]
    }
   ],
   "source": [
    "# ========== Cell 1: åŠ è½½æ•°æ®å¹¶åˆ†æç°çŠ¶ ==========\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "version_folder = \"/Users/haha/Story/data/output/å°çº¢å¸½_ç§‘å¹»_linear_T0.7_s1\"\n",
    "\n",
    "# åŠ è½½ç°æœ‰æ–‡ä»¶\n",
    "with open(f\"{version_folder}/behavior_trace.json\", 'r', encoding='utf-8') as f:\n",
    "    behavior_data = json.load(f)\n",
    "\n",
    "with open(f\"{version_folder}/role_state.json\", 'r', encoding='utf-8') as f:\n",
    "    current_role_state = json.load(f)\n",
    "\n",
    "print(\"=== behavior_trace.json åˆ†æ ===\")\n",
    "timeline = behavior_data.get(\"timeline\", [])\n",
    "print(f\"timeline è®°å½•æ•°: {len(timeline)}\")\n",
    "\n",
    "# æŸ¥çœ‹å‰å‡ æ¡\n",
    "for i, item in enumerate(timeline[:5]):\n",
    "    print(f\"{i}: {item['chapter_id']}, {item['character']}: {item['behavior']}\")\n",
    "\n",
    "print(f\"\\n=== role_state.json åˆ†æ ===\")\n",
    "print(f\"ç« èŠ‚æ•°: {len(current_role_state)}\")\n",
    "print(\"ç« èŠ‚åˆ—è¡¨:\", list(current_role_state.keys())[:10], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57291d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "behavior_trace ä¸­çš„ç« èŠ‚ID:\n",
      "  Chapter 1\n",
      "  Chapter 2\n",
      "  Chapter 3\n",
      "  Chapter 4\n",
      "  Chapter 5\n",
      "  Chapter 6\n",
      "  Chapter 7\n",
      "\n",
      "role_state ä¸­çš„ç« èŠ‚ID:\n",
      "  Chapter 10\n",
      "  Chapter 14\n",
      "  Chapter 15\n",
      "  Chapter 20\n",
      "  Chapter 21\n",
      "  Chapter 22\n",
      "  Chapter 23\n",
      "  Chapter 24\n",
      "  Chapter 25\n",
      "  Chapter 26\n",
      "  Chapter 27\n",
      "  Chapter 28\n",
      "  Chapter 29\n",
      "  Chapter 3\n",
      "  Chapter 30\n",
      "  Chapter 31\n",
      "  Chapter 32\n",
      "  Chapter 34\n",
      "  Chapter 35\n",
      "  Chapter 36\n",
      "  Chapter 37\n",
      "  Chapter 38\n",
      "  Chapter 39\n",
      "  Chapter 41\n",
      "  Chapter 42\n",
      "  Chapter 43\n",
      "  Chapter 44\n",
      "  Chapter 45\n",
      "  Chapter 46\n",
      "  Chapter 47\n",
      "  Chapter 5\n",
      "\n",
      "ç« èŠ‚IDæ˜¯å¦åŒ¹é…: False\n",
      "ç¼ºå¤±: {'Chapter 7', 'Chapter 6', 'Chapter 4', 'Chapter 1', 'Chapter 2'}\n",
      "å¤šä½™: {'Chapter 29', 'Chapter 21', 'Chapter 41', 'Chapter 42', 'Chapter 24', 'Chapter 47', 'Chapter 39', 'Chapter 15', 'Chapter 37', 'Chapter 36', 'Chapter 43', 'Chapter 10', 'Chapter 35', 'Chapter 44', 'Chapter 26', 'Chapter 32', 'Chapter 31', 'Chapter 20', 'Chapter 14', 'Chapter 38', 'Chapter 27', 'Chapter 30', 'Chapter 34', 'Chapter 25', 'Chapter 23', 'Chapter 22', 'Chapter 28', 'Chapter 46', 'Chapter 45'}\n"
     ]
    }
   ],
   "source": [
    "# ========== Cell 2: éªŒè¯ç« èŠ‚IDæ˜¯å¦æ­£ç¡® ==========\n",
    "# ä»behavior_traceä¸­ç»Ÿè®¡çœŸå®çš„ç« èŠ‚ID\n",
    "chapters_in_behavior = set(item['chapter_id'] for item in timeline)\n",
    "chapters_in_role_state = set(current_role_state.keys())\n",
    "\n",
    "print(\"behavior_trace ä¸­çš„ç« èŠ‚ID:\")\n",
    "for ch in sorted(chapters_in_behavior):\n",
    "    print(f\"  {ch}\")\n",
    "\n",
    "print(f\"\\nrole_state ä¸­çš„ç« èŠ‚ID:\")\n",
    "for ch in sorted(chapters_in_role_state):\n",
    "    print(f\"  {ch}\")\n",
    "\n",
    "print(f\"\\nç« èŠ‚IDæ˜¯å¦åŒ¹é…: {chapters_in_behavior == chapters_in_role_state}\")\n",
    "\n",
    "if chapters_in_behavior != chapters_in_role_state:\n",
    "    print(f\"ç¼ºå¤±: {chapters_in_behavior - chapters_in_role_state}\")\n",
    "    print(f\"å¤šä½™: {chapters_in_role_state - chapters_in_behavior}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a01c56a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== dialogue_updated.json è¯¦ç»†åˆ†æ ===\n",
      "é¡¶å±‚æ•°æ®ç±»å‹: <class 'list'>\n",
      "é¡¶å±‚æ•°æ®é•¿åº¦: 48\n",
      "\n",
      "å‰3ä¸ªå…ƒç´ çš„ç±»å‹å’Œç»“æ„:\n",
      "  [0] ç±»å‹: <class 'dict'>\n",
      "      é”®: ['chapter_id', 'sentence_index', 'sentence', 'need_to_action', 'actor_list', 'dialogue', 'scene_context']\n",
      "      chapter_id: Chapter 1\n",
      "  [1] ç±»å‹: <class 'dict'>\n",
      "      é”®: ['chapter_id', 'sentence_index', 'sentence', 'need_to_action', 'actor_list', 'dialogue', 'scene_context']\n",
      "      chapter_id: Chapter 1\n",
      "  [2] ç±»å‹: <class 'dict'>\n",
      "      é”®: ['chapter_id', 'sentence_index', 'sentence', 'need_to_action', 'actor_list', 'dialogue', 'scene_context']\n",
      "      chapter_id: Chapter 1\n"
     ]
    }
   ],
   "source": [
    "# ========== Cell 10: æ£€æŸ¥ dialogue_updated.json çš„å…·ä½“æ ¼å¼ ==========\n",
    "with open(f\"{version_folder}/dialogue_updated.json\", 'r', encoding='utf-8') as f:\n",
    "    dialogue_data = json.load(f)\n",
    "\n",
    "print(\"=== dialogue_updated.json è¯¦ç»†åˆ†æ ===\")\n",
    "print(f\"é¡¶å±‚æ•°æ®ç±»å‹: {type(dialogue_data)}\")\n",
    "print(f\"é¡¶å±‚æ•°æ®é•¿åº¦: {len(dialogue_data)}\")\n",
    "\n",
    "print(f\"\\nå‰3ä¸ªå…ƒç´ çš„ç±»å‹å’Œç»“æ„:\")\n",
    "for i in range(min(3, len(dialogue_data))):\n",
    "    item = dialogue_data[i]\n",
    "    print(f\"  [{i}] ç±»å‹: {type(item)}\")\n",
    "    if isinstance(item, dict):\n",
    "        print(f\"      é”®: {list(item.keys())}\")\n",
    "        print(f\"      chapter_id: {item.get('chapter_id', 'æ— ')}\")\n",
    "    elif isinstance(item, list):\n",
    "        print(f\"      åˆ—è¡¨é•¿åº¦: {len(item)}\")\n",
    "        if len(item) > 0:\n",
    "            print(f\"      ç¬¬ä¸€ä¸ªå…ƒç´ ç±»å‹: {type(item[0])}\")\n",
    "            if isinstance(item[0], dict):\n",
    "                print(f\"      ç¬¬ä¸€ä¸ªå…ƒç´ çš„chapter_id: {item[0].get('chapter_id', 'æ— ')}\")\n",
    "\n",
    "# è¿™å°±æ˜¯é—®é¢˜ï¼å¦‚æœdialogue_updated.jsonæ˜¯sentence_resultsæ ¼å¼\n",
    "# é‚£å®ƒåŒ…å«çš„æ˜¯æ¯ä¸ªå¥å­çš„æ•°æ®ï¼Œä¸æ˜¯7ä¸ªç« èŠ‚ï¼Œè€Œæ˜¯å‡ åä¸ªå¥å­ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "966dfc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== æ¨¡æ‹Ÿ run_character_state_tracker çš„é”™è¯¯è¡Œä¸º ===\n",
      "é”™è¯¯æ˜ å°„ä¼šç”Ÿæˆ 48 ä¸ªç« èŠ‚:\n",
      "å‰10ä¸ª: ['Chapter 1', 'Chapter 2', 'Chapter 3', 'Chapter 4', 'Chapter 5', 'Chapter 6', 'Chapter 7', 'Chapter 8', 'Chapter 9', 'Chapter 10']\n",
      "å5ä¸ª: ['Chapter 44', 'Chapter 45', 'Chapter 46', 'Chapter 47', 'Chapter 48']\n",
      "\n",
      "è¿™å°±è§£é‡Šäº†ä¸ºä»€ä¹ˆ role_state.json æœ‰ 31 ä¸ªç« èŠ‚\n",
      "å®ƒæŠŠæ¯ä¸ªå¥å­éƒ½å½“æˆäº†ä¸€ä¸ªç« èŠ‚ï¼\n"
     ]
    }
   ],
   "source": [
    "# ========== Cell 11: ç¡®è®¤ run_character_state_tracker çš„é”™è¯¯ ==========\n",
    "print(\"=== æ¨¡æ‹Ÿ run_character_state_tracker çš„é”™è¯¯è¡Œä¸º ===\")\n",
    "\n",
    "# æ¨¡æ‹Ÿé”™è¯¯çš„ç« èŠ‚æ˜ å°„\n",
    "simulated_chapters = []\n",
    "for idx, item in enumerate(dialogue_data):\n",
    "    wrong_chapter_key = f\"Chapter {idx + 1}\"\n",
    "    simulated_chapters.append(wrong_chapter_key)\n",
    "\n",
    "print(f\"é”™è¯¯æ˜ å°„ä¼šç”Ÿæˆ {len(simulated_chapters)} ä¸ªç« èŠ‚:\")\n",
    "print(f\"å‰10ä¸ª: {simulated_chapters[:10]}\")\n",
    "print(f\"å5ä¸ª: {simulated_chapters[-5:]}\")\n",
    "\n",
    "# è¿™è§£é‡Šäº†ä¸ºä»€ä¹ˆrole_state.jsonæœ‰31ä¸ªå¥‡æ€ªçš„ç« èŠ‚ï¼\n",
    "print(f\"\\nè¿™å°±è§£é‡Šäº†ä¸ºä»€ä¹ˆ role_state.json æœ‰ {len(current_role_state)} ä¸ªç« èŠ‚\")\n",
    "print(\"å®ƒæŠŠæ¯ä¸ªå¥å­éƒ½å½“æˆäº†ä¸€ä¸ªç« èŠ‚ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83ceadd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== æ­£ç¡®çš„ role_state ===\n",
      "ç« èŠ‚æ•°: 7 (åº”è¯¥æ˜¯7ä¸ª)\n",
      "ç« èŠ‚ID: ['Chapter 1', 'Chapter 2', 'Chapter 3', 'Chapter 4', 'Chapter 5', 'Chapter 6', 'Chapter 7']\n",
      "\n",
      "Chapter 1 (3 ä¸ªè§’è‰²):\n",
      "  å°çº¢å¸½: 3 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  æ®–æ°‘æ˜Ÿçƒç®¡ç†å‘˜ï¼ˆæ—åšå£«ï¼‰: 3 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  é£èˆ¹äººå·¥æ™ºèƒ½ï¼ˆå°æ™ºï¼‰: 3 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "\n",
      "Chapter 2 (4 ä¸ªè§’è‰²):\n",
      "  å°çº¢å¸½: 3 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  é£èˆ¹äººå·¥æ™ºèƒ½ï¼ˆå°æ™ºï¼‰: 3 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  ç¥–æ¯: 3 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  åŒ»ç–—æœºå™¨äººï¼ˆå°ç™½ï¼‰: 3 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "\n",
      "Chapter 3 (3 ä¸ªè§’è‰²):\n",
      "  æœºæ¢°ç‹¼: 6 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  å°çº¢å¸½: 9 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  é£èˆ¹äººå·¥æ™ºèƒ½ï¼ˆå°æ™ºï¼‰: 4 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "\n",
      "Chapter 4 (5 ä¸ªè§’è‰²):\n",
      "  æœºæ¢°ç‹¼: 12 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  ç¥–æ¯: 13 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  åŒ»ç–—æœºå™¨äººï¼ˆå°ç™½ï¼‰: 9 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  å°çº¢å¸½: 18 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  é£èˆ¹äººå·¥æ™ºèƒ½ï¼ˆå°æ™ºï¼‰: 3 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "\n",
      "Chapter 5 (7 ä¸ªè§’è‰²):\n",
      "  ç¥–æ¯: 11 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  å°ç™½: 7 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  æœºæ¢°ç‹¼: 9 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  å°çº¢å¸½: 7 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  é£èˆ¹äººå·¥æ™ºèƒ½ï¼ˆå°æ™ºï¼‰: 10 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  é»‘å®¢ä¸»è„‘: 4 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  æ®–æ°‘æ˜Ÿçƒç®¡ç†å‘˜ï¼ˆæ—åšå£«ï¼‰: 5 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "\n",
      "Chapter 6 (5 ä¸ªè§’è‰²):\n",
      "  å°çº¢å¸½: 17 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  ç¥–æ¯: 10 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  åŒ»ç–—æœºå™¨äººï¼ˆå°ç™½ï¼‰: 15 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  æœºæ¢°ç‹¼: 13 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  é£èˆ¹äººå·¥æ™ºèƒ½ï¼ˆå°æ™ºï¼‰: 11 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "\n",
      "Chapter 7 (7 ä¸ªè§’è‰²):\n",
      "  å°çº¢å¸½: 13 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  å°ç™½: 9 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  ç¥–æ¯: 13 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  æ—åšå£«: 6 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  æœºæ¢°ç‹¼: 8 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  é»‘å®¢ä¸»è„‘: 5 ä¸ªè¡Œä¸ºçŠ¶æ€\n",
      "  å°æ™º: 9 ä¸ªè¡Œä¸ºçŠ¶æ€\n"
     ]
    }
   ],
   "source": [
    "# ========== Cell 12: ç”Ÿæˆæ­£ç¡®çš„ role_state.json ==========\n",
    "def generate_correct_role_state_from_behavior_trace():\n",
    "    \"\"\"ä»behavior_traceç›´æ¥ç”Ÿæˆæ­£ç¡®çš„role_state\"\"\"\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    # æŒ‰ç« èŠ‚å’Œè§’è‰²åˆ†ç»„\n",
    "    role_state_by_chapter = defaultdict(lambda: defaultdict(set))\n",
    "    \n",
    "    for item in timeline:\n",
    "        chapter_id = item[\"chapter_id\"]\n",
    "        character = item[\"character\"]\n",
    "        behavior = item[\"behavior\"]\n",
    "        \n",
    "        role_state_by_chapter[chapter_id][character].add(behavior)\n",
    "    \n",
    "    # è½¬æ¢ä¸ºæœ€ç»ˆæ ¼å¼\n",
    "    result = {}\n",
    "    for chapter_id in sorted(role_state_by_chapter.keys()):  # æŒ‰ç« èŠ‚IDæ’åº\n",
    "        result[chapter_id] = {}\n",
    "        for character, behaviors in role_state_by_chapter[chapter_id].items():\n",
    "            result[chapter_id][character] = sorted(list(behaviors))\n",
    "    \n",
    "    return result\n",
    "\n",
    "# ç”Ÿæˆæ­£ç¡®ç‰ˆæœ¬\n",
    "correct_role_state = generate_correct_role_state_from_behavior_trace()\n",
    "\n",
    "print(\"=== æ­£ç¡®çš„ role_state ===\")\n",
    "print(f\"ç« èŠ‚æ•°: {len(correct_role_state)} (åº”è¯¥æ˜¯7ä¸ª)\")\n",
    "print(\"ç« èŠ‚ID:\", sorted(correct_role_state.keys()))\n",
    "\n",
    "# æ˜¾ç¤ºæ¯ä¸ªç« èŠ‚çš„è§’è‰²æ•°æ®\n",
    "for chapter_id in sorted(correct_role_state.keys()):\n",
    "    characters = correct_role_state[chapter_id]\n",
    "    print(f\"\\n{chapter_id} ({len(characters)} ä¸ªè§’è‰²):\")\n",
    "    for character, behaviors in characters.items():\n",
    "        print(f\"  {character}: {len(behaviors)} ä¸ªè¡Œä¸ºçŠ¶æ€\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c647c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ç”Ÿæˆäº†æ­£ç¡®çš„ role_state\n",
      "ç« èŠ‚æ•°: 7\n",
      "ç« èŠ‚ID: ['Chapter 1', 'Chapter 2', 'Chapter 3', 'Chapter 4', 'Chapter 5', 'Chapter 6', 'Chapter 7']\n",
      "âœ… å·²ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶: /Users/haha/Story/data/output/å°çº¢å¸½_ç§‘å¹»_linear_T0.7_s1/role_state_fixed_temp.json\n"
     ]
    }
   ],
   "source": [
    "# ========== Cell 1: ç”Ÿæˆæ­£ç¡®çš„ role_state.json æ–‡ä»¶ ==========\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "version_folder = \"/Users/haha/Story/data/output/å°çº¢å¸½_ç§‘å¹»_linear_T0.7_s1\"\n",
    "\n",
    "# åŠ è½½ behavior_trace.json\n",
    "with open(f\"{version_folder}/behavior_trace.json\", 'r', encoding='utf-8') as f:\n",
    "    behavior_data = json.load(f)\n",
    "\n",
    "def generate_role_state_from_behavior_trace(behavior_trace_data):\n",
    "    \"\"\"ä»behavior_traceç›´æ¥ç”Ÿæˆrole_stateï¼Œé¿å…é‡å¤LLMè°ƒç”¨å’Œé”™è¯¯æ˜ å°„\"\"\"\n",
    "    timeline = behavior_trace_data.get(\"timeline\", [])\n",
    "    role_state_by_chapter = defaultdict(lambda: defaultdict(set))\n",
    "    \n",
    "    for item in timeline:\n",
    "        chapter_id = item[\"chapter_id\"]\n",
    "        character = item[\"character\"]\n",
    "        behavior = item[\"behavior\"]\n",
    "        role_state_by_chapter[chapter_id][character].add(behavior)\n",
    "    \n",
    "    # è½¬æ¢ä¸ºæœ€ç»ˆæ ¼å¼\n",
    "    result = {}\n",
    "    for chapter_id in sorted(role_state_by_chapter.keys()):\n",
    "        result[chapter_id] = {}\n",
    "        for character, behaviors in role_state_by_chapter[chapter_id].items():\n",
    "            result[chapter_id][character] = sorted(list(behaviors))\n",
    "    \n",
    "    return result\n",
    "\n",
    "# ç”Ÿæˆæ­£ç¡®çš„ role_state\n",
    "correct_role_state = generate_role_state_from_behavior_trace(behavior_data)\n",
    "\n",
    "print(f\"âœ… ç”Ÿæˆäº†æ­£ç¡®çš„ role_state\")\n",
    "print(f\"ç« èŠ‚æ•°: {len(correct_role_state)}\")\n",
    "print(f\"ç« èŠ‚ID: {sorted(correct_role_state.keys())}\")\n",
    "\n",
    "# ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶\n",
    "temp_file = f\"{version_folder}/role_state_fixed_temp.json\"\n",
    "with open(temp_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(correct_role_state, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"âœ… å·²ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶: {temp_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d8ce7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²å¤‡ä»½åŸæ–‡ä»¶åˆ°: /Users/haha/Story/data/output/å°çº¢å¸½_ç§‘å¹»_linear_T0.7_s1/role_state_backup_20250812_182435.json\n",
      "âœ… å·²æ›¿æ¢ role_state.json\n",
      "âœ… éªŒè¯æˆåŠŸï¼æ–°çš„ role_state.json:\n",
      "   ç« èŠ‚æ•°: 7\n",
      "   ç« èŠ‚ID: ['Chapter 1', 'Chapter 2', 'Chapter 3', 'Chapter 4', 'Chapter 5', 'Chapter 6', 'Chapter 7']\n",
      "âœ… å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶\n"
     ]
    }
   ],
   "source": [
    "# ========== Cell 2: å¤‡ä»½åŸæ–‡ä»¶å¹¶æ›¿æ¢ ==========\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# å¤‡ä»½åŸæ–‡ä»¶\n",
    "original_file = f\"{version_folder}/role_state.json\"\n",
    "backup_file = f\"{version_folder}/role_state_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "\n",
    "# åˆ›å»ºå¤‡ä»½\n",
    "shutil.copy(original_file, backup_file)\n",
    "print(f\"âœ… å·²å¤‡ä»½åŸæ–‡ä»¶åˆ°: {backup_file}\")\n",
    "\n",
    "# æ›¿æ¢ä¸ºæ­£ç¡®ç‰ˆæœ¬\n",
    "shutil.copy(temp_file, original_file)\n",
    "print(f\"âœ… å·²æ›¿æ¢ role_state.json\")\n",
    "\n",
    "# éªŒè¯æ›¿æ¢ç»“æœ\n",
    "with open(original_file, 'r', encoding='utf-8') as f:\n",
    "    new_data = json.load(f)\n",
    "\n",
    "print(f\"âœ… éªŒè¯æˆåŠŸï¼æ–°çš„ role_state.json:\")\n",
    "print(f\"   ç« èŠ‚æ•°: {len(new_data)}\")\n",
    "print(f\"   ç« èŠ‚ID: {sorted(new_data.keys())}\")\n",
    "\n",
    "# åˆ é™¤ä¸´æ—¶æ–‡ä»¶\n",
    "import os\n",
    "os.remove(temp_file)\n",
    "print(\"âœ… å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03d3bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6fec0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2600f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from src.utils.utils import generate_response, save_json, load_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d75c30c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ å¼€å§‹åŠ è½½story.json...\n",
      "==================================================\n",
      "ğŸ” æ­£åœ¨æŸ¥æ‰¾æ–‡ä»¶: story.json\n",
      "âŒ æ–‡ä»¶ä¸å­˜åœ¨: story.json\n",
      "ğŸ“ å½“å‰å·¥ä½œç›®å½•: /Users/haha/Story\n",
      "ğŸ“ å½“å‰ç›®å½•ä¸‹çš„æ–‡ä»¶:\n",
      "  - run_loop_status.json\n",
      "\n",
      "ğŸ’¡ å¸¸è§è§£å†³æ–¹æ¡ˆ:\n",
      "1. æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®\n",
      "2. æ£€æŸ¥JSONæ ¼å¼æ˜¯å¦æœ‰æ•ˆ\n",
      "3. æ£€æŸ¥æ–‡ä»¶ç¼–ç æ˜¯å¦ä¸ºUTF-8\n",
      "\n",
      "ğŸ“‹ æ”¯æŒçš„JSONæ ¼å¼ç¤ºä¾‹:\n",
      "\n",
      "{\n",
      "  \"story\": [\n",
      "    {\"chapter_id\": \"ç¬¬ä¸€ç« \", \"plot\": \"æ•…äº‹å†…å®¹...\"},\n",
      "    {\"chapter_id\": \"ç¬¬äºŒç« \", \"plot\": \"æ•…äº‹å†…å®¹...\"}\n",
      "  ]\n",
      "}\n",
      "\n",
      "æˆ–è€…:\n",
      "\n",
      "[\n",
      "  {\"chapter_id\": \"ç¬¬ä¸€ç« \", \"plot\": \"æ•…äº‹å†…å®¹...\"},\n",
      "  {\"chapter_id\": \"ç¬¬äºŒç« \", \"plot\": \"æ•…äº‹å†…å®¹...\"}\n",
      "]\n",
      "\n",
      "ğŸš€ å¼€å§‹åŠ è½½story.json...\n",
      "==================================================\n",
      "ğŸ” æ­£åœ¨æŸ¥æ‰¾æ–‡ä»¶: /Users/haha/Story/data/output/å°çº¢å¸½_ç§‘å¹»_linear_T0.7_s1/story.json\n",
      "âœ… æˆåŠŸåŠ è½½æ–‡ä»¶: /Users/haha/Story/data/output/å°çº¢å¸½_ç§‘å¹»_linear_T0.7_s1/story.json\n",
      "ğŸ”„ æ­£åœ¨è§£ææ•°æ®æ ¼å¼...\n",
      "âœ… æ£€æµ‹åˆ°æ ¼å¼: ç›´æ¥ç« èŠ‚åˆ—è¡¨\n",
      "ğŸ“Š æ‰¾åˆ° 7 ä¸ªç« èŠ‚\n",
      "ğŸ” ç¬¬ä¸€ç« ç»“æ„:\n",
      "  - scene: str\n",
      "  - characters: list\n",
      "  - plot: str\n",
      "  - chapter_id: str\n",
      "  - title: str\n",
      "âœ… æ‰¾åˆ°å†…å®¹å­—æ®µ: plot\n",
      "âœ… æ‰¾åˆ°IDå­—æ®µ: chapter_id\n",
      "ğŸ”„ æ ‡å‡†åŒ–æ ¼å¼: chapter_id -> chapter_id, plot -> plot\n",
      "âœ… æ ‡å‡†åŒ–å®Œæˆ: 7 ä¸ªç« èŠ‚\n",
      "\n",
      "ğŸ“– æ•°æ®é¢„è§ˆ:\n",
      "==================================================\n",
      "\n",
      "ç« èŠ‚ 1:\n",
      "  ID: Chapter 1\n",
      "  å†…å®¹é•¿åº¦: 206 å­—ç¬¦\n",
      "  å†…å®¹é¢„è§ˆ: æ¸…æ™¨,å°çº¢å¸½èº«ç©¿çº¢è‰²æ™ºèƒ½åˆ¶æœ,èƒŒç€å¯†å°åŒ»ç–—èˆ±,ç¥æƒ…åšå®šåœ°èµ°å…¥å¤ªç©ºæ¸¯ä¸»æ§å¤§å….æ—åšå£«å·²ç­‰å€™åœ¨æœåŠ¡å°æ—,ä»–ç›®å…‰å…³åˆ‡,é€’ä¸Šæœ€åçš„è®¸å¯æ–‡ä»¶.ä¸¤äººä½å£°äº¤è°ˆ,æ—åšå£«å®å˜±å°çº¢å¸½æ³¨æ„é€”ä¸­å®‰å…¨,å°¤å…¶è¦å°å¿ƒè¿‘æœŸé¢‘å‘çš„é»‘å®¢...\n",
      "\n",
      "ç« èŠ‚ 2:\n",
      "  ID: Chapter 2\n",
      "  å†…å®¹é•¿åº¦: 184 å­—ç¬¦\n",
      "  å†…å®¹é¢„è§ˆ: å°çº¢å¸½é©¾é©¶ç€çº¢æ˜Ÿå·é£èˆ¹,è½½ç€ç—…é‡çš„ç¥–æ¯å’ŒåŒ»ç–—æœºå™¨äººå°ç™½,ç©¿è¡Œåœ¨å¹½è“çš„å¤ªç©ºè·ƒè¿é€šé“.é£èˆ¹å†…éƒ¨ä¸€ç‰‡æœ‰åº,ç¥–æ¯é¢è‰²è™šå¼±å´æ¸©æŸ”åœ°å¾®ç¬‘,å°ç™½åœ¨æ—è°ƒè¯•åŒ»ç–—è®¾å¤‡.å°çº¢å¸½ä¸é£èˆ¹AIå°æ™ºåä½œ,æ—¶åˆ»å…³æ³¨å¯¼èˆªä¸é£èˆ¹é˜²å¾¡ç³»ç»Ÿ...\n",
      "\n",
      "ç« èŠ‚ 3:\n",
      "  ID: Chapter 3\n",
      "  å†…å®¹é•¿åº¦: 246 å­—ç¬¦\n",
      "  å†…å®¹é¢„è§ˆ: å°çº¢å¸½é©¾é©¶æ‚¬æµ®æ»‘æ¿,è°¨æ…åœ°ç©¿æ¢­åœ¨æš®è‰²æ£®æ—é—´.å¥¹æ­£å‡†å¤‡åŠ é€Ÿèµ¶å¾€ç¥–æ¯çš„å±…æ‰€,å´çªç„¶è¢«ä¸€é“é“¶è‰²æ®‹å½±æ‹¦ä½å»è·¯.æœºæ¢°ç‹¼æ½œä¼åœ¨æ ‘æ ¹é˜´å½±ä¸‹,åŒçœ¼æ³›èµ·è“è‰²å†·å…‰,èº«èº¯é‡‘å±éƒ¨ä»¶åœ¨å¤œè‰²ä¸­åå°„ç€å†°å†·å…‰èŠ’.å®ƒä»¥ä½æ²‰çš„æœºæ¢°å£°è°ƒå‘...\n",
      "\n",
      "... è¿˜æœ‰ 4 ä¸ªç« èŠ‚\n",
      "==================================================\n",
      "âœ… story.jsonåŠ è½½å®Œæˆ!\n"
     ]
    }
   ],
   "source": [
    "# ç®€åŒ–ç‰ˆï¼šç›´æ¥åŠ è½½story.jsonå¹¶æµ‹è¯•äº‹ä»¶æå–\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "## 1. æ£€æŸ¥å’ŒåŠ è½½story.jsonæ–‡ä»¶\n",
    "def load_story_json(file_path=\"story.json\"):\n",
    "    \"\"\"åŠ è½½story.jsonæ–‡ä»¶\"\"\"\n",
    "    print(f\"ğŸ” æ­£åœ¨æŸ¥æ‰¾æ–‡ä»¶: {file_path}\")\n",
    "    \n",
    "    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}\")\n",
    "        print(f\"ğŸ“ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}\")\n",
    "        print(\"ğŸ“ å½“å‰ç›®å½•ä¸‹çš„æ–‡ä»¶:\")\n",
    "        for f in os.listdir('.'):\n",
    "            if f.endswith('.json'):\n",
    "                print(f\"  - {f}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"âœ… æˆåŠŸåŠ è½½æ–‡ä»¶: {file_path}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ åŠ è½½å¤±è´¥: {e}\")\n",
    "        return None\n",
    "\n",
    "## 2. è§£æstoryæ•°æ®æ ¼å¼\n",
    "def parse_story_data(data):\n",
    "    \"\"\"è§£æä¸åŒæ ¼å¼çš„storyæ•°æ®\"\"\"\n",
    "    if data is None:\n",
    "        return []\n",
    "    \n",
    "    print(\"ğŸ”„ æ­£åœ¨è§£ææ•°æ®æ ¼å¼...\")\n",
    "    \n",
    "    # æƒ…å†µ1: ç›´æ¥æ˜¯ç« èŠ‚åˆ—è¡¨\n",
    "    if isinstance(data, list):\n",
    "        print(\"âœ… æ£€æµ‹åˆ°æ ¼å¼: ç›´æ¥ç« èŠ‚åˆ—è¡¨\")\n",
    "        return data\n",
    "    \n",
    "    # æƒ…å†µ2: å­—å…¸æ ¼å¼ï¼ŒæŸ¥æ‰¾å¯èƒ½çš„ç« èŠ‚æ•°æ®\n",
    "    if isinstance(data, dict):\n",
    "        # å¸¸è§çš„å­—æ®µå\n",
    "        possible_keys = ['story', 'chapters', 'data', 'content', 'episodes']\n",
    "        \n",
    "        for key in possible_keys:\n",
    "            if key in data and isinstance(data[key], list):\n",
    "                print(f\"âœ… æ£€æµ‹åˆ°æ ¼å¼: ä»'{key}'å­—æ®µæå–ç« èŠ‚\")\n",
    "                return data[key]\n",
    "        \n",
    "        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œæ˜¾ç¤ºæ‰€æœ‰å­—æ®µ\n",
    "        print(\"ğŸ” å¯ç”¨å­—æ®µ:\")\n",
    "        for key, value in data.items():\n",
    "            print(f\"  - {key}: {type(value)}\")\n",
    "            if isinstance(value, list) and len(value) > 0:\n",
    "                print(f\"    (åˆ—è¡¨é•¿åº¦: {len(value)})\")\n",
    "    \n",
    "    print(\"âš ï¸ æ— æ³•è‡ªåŠ¨è¯†åˆ«æ ¼å¼ï¼Œè¯·æ£€æŸ¥æ•°æ®ç»“æ„\")\n",
    "    return []\n",
    "\n",
    "## 3. éªŒè¯ç« èŠ‚æ•°æ®\n",
    "def validate_chapters(chapters):\n",
    "    \"\"\"éªŒè¯ç« èŠ‚æ•°æ®æ˜¯å¦ç¬¦åˆè¦æ±‚\"\"\"\n",
    "    if not chapters:\n",
    "        print(\"âŒ æ²¡æœ‰æ‰¾åˆ°ç« èŠ‚æ•°æ®\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"ğŸ“Š æ‰¾åˆ° {len(chapters)} ä¸ªç« èŠ‚\")\n",
    "    \n",
    "    # æ£€æŸ¥ç¬¬ä¸€ä¸ªç« èŠ‚çš„ç»“æ„\n",
    "    first_chapter = chapters[0]\n",
    "    print(\"ğŸ” ç¬¬ä¸€ç« ç»“æ„:\")\n",
    "    for key, value in first_chapter.items():\n",
    "        print(f\"  - {key}: {type(value).__name__}\")\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦å­—æ®µ\n",
    "    content_fields = ['plot', 'content', 'text', 'story']\n",
    "    id_fields = ['chapter_id', 'id', 'title', 'name']\n",
    "    \n",
    "    content_field = None\n",
    "    id_field = None\n",
    "    \n",
    "    for field in content_fields:\n",
    "        if field in first_chapter:\n",
    "            content_field = field\n",
    "            break\n",
    "    \n",
    "    for field in id_fields:\n",
    "        if field in first_chapter:\n",
    "            id_field = field\n",
    "            break\n",
    "    \n",
    "    if content_field:\n",
    "        print(f\"âœ… æ‰¾åˆ°å†…å®¹å­—æ®µ: {content_field}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ æœªæ‰¾åˆ°å†…å®¹å­—æ®µï¼Œæ”¯æŒçš„å­—æ®µå: plot, content, text, story\")\n",
    "    \n",
    "    if id_field:\n",
    "        print(f\"âœ… æ‰¾åˆ°IDå­—æ®µ: {id_field}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ æœªæ‰¾åˆ°IDå­—æ®µï¼Œæ”¯æŒçš„å­—æ®µå: chapter_id, id, title, name\")\n",
    "    \n",
    "    return content_field is not None\n",
    "\n",
    "## 4. æ ‡å‡†åŒ–ç« èŠ‚æ ¼å¼\n",
    "def standardize_chapters(chapters):\n",
    "    \"\"\"å°†ç« èŠ‚æ•°æ®æ ‡å‡†åŒ–ä¸ºç»Ÿä¸€æ ¼å¼\"\"\"\n",
    "    standardized = []\n",
    "    \n",
    "    # æ£€æµ‹å­—æ®µæ˜ å°„\n",
    "    if not chapters:\n",
    "        return []\n",
    "    \n",
    "    sample = chapters[0]\n",
    "    \n",
    "    # æ‰¾åˆ°å†…å®¹å­—æ®µ\n",
    "    content_field = None\n",
    "    for field in ['plot', 'content', 'text', 'story']:\n",
    "        if field in sample:\n",
    "            content_field = field\n",
    "            break\n",
    "    \n",
    "    # æ‰¾åˆ°IDå­—æ®µ\n",
    "    id_field = None\n",
    "    for field in ['chapter_id', 'id', 'title', 'name']:\n",
    "        if field in sample:\n",
    "            id_field = field\n",
    "            break\n",
    "    \n",
    "    print(f\"ğŸ”„ æ ‡å‡†åŒ–æ ¼å¼: {id_field} -> chapter_id, {content_field} -> plot\")\n",
    "    \n",
    "    for i, chapter in enumerate(chapters):\n",
    "        std_chapter = {}\n",
    "        \n",
    "        # è®¾ç½®chapter_id\n",
    "        if id_field and id_field in chapter:\n",
    "            std_chapter['chapter_id'] = str(chapter[id_field])\n",
    "        else:\n",
    "            std_chapter['chapter_id'] = f\"ç¬¬{i+1}ç« \"\n",
    "        \n",
    "        # è®¾ç½®plot\n",
    "        if content_field and content_field in chapter:\n",
    "            std_chapter['plot'] = str(chapter[content_field])\n",
    "        else:\n",
    "            std_chapter['plot'] = \"\"\n",
    "        \n",
    "        # ä¿ç•™å…¶ä»–å­—æ®µ\n",
    "        for key, value in chapter.items():\n",
    "            if key not in [id_field, content_field]:\n",
    "                std_chapter[key] = value\n",
    "        \n",
    "        standardized.append(std_chapter)\n",
    "    \n",
    "    print(f\"âœ… æ ‡å‡†åŒ–å®Œæˆ: {len(standardized)} ä¸ªç« èŠ‚\")\n",
    "    return standardized\n",
    "\n",
    "## 5. é¢„è§ˆæ•°æ®\n",
    "def preview_data(chapters, max_show=3):\n",
    "    \"\"\"é¢„è§ˆç« èŠ‚æ•°æ®\"\"\"\n",
    "    print(\"\\nğŸ“– æ•°æ®é¢„è§ˆ:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for i, chapter in enumerate(chapters[:max_show]):\n",
    "        print(f\"\\nç« èŠ‚ {i+1}:\")\n",
    "        print(f\"  ID: {chapter.get('chapter_id', 'N/A')}\")\n",
    "        \n",
    "        plot = chapter.get('plot', '')\n",
    "        print(f\"  å†…å®¹é•¿åº¦: {len(plot)} å­—ç¬¦\")\n",
    "        \n",
    "        if len(plot) > 100:\n",
    "            print(f\"  å†…å®¹é¢„è§ˆ: {plot[:100]}...\")\n",
    "        else:\n",
    "            print(f\"  å†…å®¹: {plot}\")\n",
    "    \n",
    "    if len(chapters) > max_show:\n",
    "        print(f\"\\n... è¿˜æœ‰ {len(chapters) - max_show} ä¸ªç« èŠ‚\")\n",
    "\n",
    "## 6. ä¸»è¦åŠ è½½æµç¨‹\n",
    "def load_and_prepare_story(file_path=\"story.json\"):\n",
    "    \"\"\"å®Œæ•´çš„story.jsonåŠ è½½å’Œå‡†å¤‡æµç¨‹\"\"\"\n",
    "    print(\"ğŸš€ å¼€å§‹åŠ è½½story.json...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. åŠ è½½æ–‡ä»¶\n",
    "    raw_data = load_story_json(file_path)\n",
    "    if raw_data is None:\n",
    "        return None\n",
    "    \n",
    "    # 2. è§£ææ ¼å¼\n",
    "    chapters = parse_story_data(raw_data)\n",
    "    if not chapters:\n",
    "        return None\n",
    "    \n",
    "    # 3. éªŒè¯æ•°æ®\n",
    "    if not validate_chapters(chapters):\n",
    "        return None\n",
    "    \n",
    "    # 4. æ ‡å‡†åŒ–æ ¼å¼\n",
    "    standardized_chapters = standardize_chapters(chapters)\n",
    "    \n",
    "    # 5. é¢„è§ˆæ•°æ®\n",
    "    preview_data(standardized_chapters)\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"âœ… story.jsonåŠ è½½å®Œæˆ!\")\n",
    "    return standardized_chapters\n",
    "\n",
    "## 7. ä½¿ç”¨ç¤ºä¾‹\n",
    "# åŠ è½½ä½ çš„story.jsonæ–‡ä»¶\n",
    "story_data = load_and_prepare_story(\"story.json\")\n",
    "\n",
    "# å¦‚æœæ–‡ä»¶åœ¨å…¶ä»–ä½ç½®ï¼Œä¿®æ”¹è·¯å¾„ï¼š\n",
    "# story_data = load_and_prepare_story(\"/path/to/your/story.json\")\n",
    "# story_data = load_and_prepare_story(\"data/story.json\")\n",
    "\n",
    "## 8. å¦‚æœåŠ è½½æˆåŠŸï¼Œå¯ä»¥ç»§ç»­æµ‹è¯•äº‹ä»¶æå–\n",
    "if story_data:\n",
    "    print(f\"\\nğŸ¯ å‡†å¤‡æµ‹è¯•äº‹ä»¶æå– ({len(story_data)} ä¸ªç« èŠ‚)\")\n",
    "    print(\"å¦‚æœè¦ç»§ç»­æµ‹è¯•äº‹ä»¶æå–ï¼Œè¿è¡Œ:\")\n",
    "    print(\"result = extract_events_no_hallucination(story_data)\")\n",
    "else:\n",
    "    print(\"\\nğŸ’¡ å¸¸è§è§£å†³æ–¹æ¡ˆ:\")\n",
    "    print(\"1. æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®\")\n",
    "    print(\"2. æ£€æŸ¥JSONæ ¼å¼æ˜¯å¦æœ‰æ•ˆ\")\n",
    "    print(\"3. æ£€æŸ¥æ–‡ä»¶ç¼–ç æ˜¯å¦ä¸ºUTF-8\")\n",
    "    print(\"\\nğŸ“‹ æ”¯æŒçš„JSONæ ¼å¼ç¤ºä¾‹:\")\n",
    "    print(\"\"\"\n",
    "{\n",
    "  \"story\": [\n",
    "    {\"chapter_id\": \"ç¬¬ä¸€ç« \", \"plot\": \"æ•…äº‹å†…å®¹...\"},\n",
    "    {\"chapter_id\": \"ç¬¬äºŒç« \", \"plot\": \"æ•…äº‹å†…å®¹...\"}\n",
    "  ]\n",
    "}\n",
    "\n",
    "æˆ–è€…:\n",
    "\n",
    "[\n",
    "  {\"chapter_id\": \"ç¬¬ä¸€ç« \", \"plot\": \"æ•…äº‹å†…å®¹...\"},\n",
    "  {\"chapter_id\": \"ç¬¬äºŒç« \", \"plot\": \"æ•…äº‹å†…å®¹...\"}\n",
    "]\n",
    "\"\"\")\n",
    "story_data = load_and_prepare_story(\"/Users/haha/Story/data/output/å°çº¢å¸½_ç§‘å¹»_linear_T0.7_s1/story.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de6892f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_story_plot = \"\"\n",
    "for i in story_data :\n",
    "    concat_story_plot += i['chapter_id'] + \"\\n\" + i['plot'] + \"\\n\\n\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8867ca58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 1\\næ¸…æ™¨,å°çº¢å¸½èº«ç©¿çº¢è‰²æ™ºèƒ½åˆ¶æœ,èƒŒç€å¯†å°åŒ»ç–—èˆ±,ç¥æƒ…åšå®šåœ°èµ°å…¥å¤ªç©ºæ¸¯ä¸»æ§å¤§å….æ—åšå£«å·²ç­‰å€™åœ¨æœåŠ¡å°æ—,ä»–ç›®å…‰å…³åˆ‡,é€’ä¸Šæœ€åçš„è®¸å¯æ–‡ä»¶.ä¸¤äººä½å£°äº¤è°ˆ,æ—åšå£«å®å˜±å°çº¢å¸½æ³¨æ„é€”ä¸­å®‰å…¨,å°¤å…¶è¦å°å¿ƒè¿‘æœŸé¢‘å‘çš„é»‘å®¢è¢­å‡».å°çº¢å¸½ç‚¹å¤´,çœ¼ä¸­é—ªçƒç€åšå®šä¸ç„¦è™‘,ä¸ºæ•‘ç¥–æ¯è€Œè¸ä¸Šçš„æ˜Ÿé™…ä»»åŠ¡å³å°†å¯ç¨‹.å¤§å…çª—å¤–,ä¸“å±é£èˆ¹çš„é“¶è‰²èº«å½±é™é™åœæ³Š,é£èˆ¹äººå·¥æ™ºèƒ½å°æ™ºå·²å¯åŠ¨æ¬¢è¿ç¨‹åº,è“è‰²å…‰èŠ’åœ¨èˆ±é—¨è¾¹æµè½¬.æ°”æ°›ä¸­å¼¥æ¼«ç€æœŸå¾…ä¸ä¸€ä¸ç´§å¼ ,æ–°çš„å†’é™©å³å°†å¼€å§‹.\\n\\nChapter 2\\nå°çº¢å¸½é©¾é©¶ç€çº¢æ˜Ÿå·é£èˆ¹,è½½ç€ç—…é‡çš„ç¥–æ¯å’ŒåŒ»ç–—æœºå™¨äººå°ç™½,ç©¿è¡Œåœ¨å¹½è“çš„å¤ªç©ºè·ƒè¿é€šé“.é£èˆ¹å†…éƒ¨ä¸€ç‰‡æœ‰åº,ç¥–æ¯é¢è‰²è™šå¼±å´æ¸©æŸ”åœ°å¾®ç¬‘,å°ç™½åœ¨æ—è°ƒè¯•åŒ»ç–—è®¾å¤‡.å°çº¢å¸½ä¸é£èˆ¹AIå°æ™ºåä½œ,æ—¶åˆ»å…³æ³¨å¯¼èˆªä¸é£èˆ¹é˜²å¾¡ç³»ç»Ÿ,å´æœªå¯Ÿè§‰æœºæ¢°ç‹¼å·²æ½œä¼åœ¨å¤–éƒ¨,é€šè¿‡é»‘å®¢æ‰‹æ®µè¯•å›¾çªç ´é£èˆ¹å±éšœ.å°æ™ºå‘å‡ºè­¦æŠ¥,èˆ±å†…æ°”æ°›éª¤ç„¶ç´§å¼ ,å°çº¢å¸½å½“æœºç«‹æ–­,å¯åŠ¨é˜²å¾¡åè®®å¹¶ä¸ç¥–æ¯å’Œå°ç™½è¿…é€Ÿæ²Ÿé€š,å‡†å¤‡åº”å¯¹å³å°†åˆ°æ¥çš„å±æœº.\\n\\nChapter 3\\nå°çº¢å¸½é©¾é©¶æ‚¬æµ®æ»‘æ¿,è°¨æ…åœ°ç©¿æ¢­åœ¨æš®è‰²æ£®æ—é—´.å¥¹æ­£å‡†å¤‡åŠ é€Ÿèµ¶å¾€ç¥–æ¯çš„å±…æ‰€,å´çªç„¶è¢«ä¸€é“é“¶è‰²æ®‹å½±æ‹¦ä½å»è·¯.æœºæ¢°ç‹¼æ½œä¼åœ¨æ ‘æ ¹é˜´å½±ä¸‹,åŒçœ¼æ³›èµ·è“è‰²å†·å…‰,èº«èº¯é‡‘å±éƒ¨ä»¶åœ¨å¤œè‰²ä¸­åå°„ç€å†°å†·å…‰èŠ’.å®ƒä»¥ä½æ²‰çš„æœºæ¢°å£°è°ƒå‘å‡ºå¨èƒ,è¦æ±‚å°çº¢å¸½äº¤å‡ºåŒ»ç–—èŠ¯ç‰‡.å°çº¢å¸½è­¦è§‰åœ°æŒ‰ä¸‹é€šè®¯è€³æœº,å‘¼å«é£èˆ¹AIå°æ™ºæ”¯æ´,åŒæ—¶åˆ©ç”¨æ ‘æœ¨å’Œæ»‘æ¿çµæ´»å‘¨æ—‹,è¯•å›¾æ‘†è„±æœºæ¢°ç‹¼çš„è¿½å‡».æ£®æ—æ·±å¤„ä¸æ–­ä¼ æ¥æœºæ¢°ç‹¼çš„è„šæ­¥å£°å’Œç”µå­å¹²æ‰°ä¿¡å·,å°çº¢å¸½è¿ç”¨è‡ªå·±çš„é»‘å®¢æŠ€èƒ½,è¯•å›¾ç ´è§£æœºæ¢°ç‹¼çš„æ§åˆ¶ä¿¡å·,ä¸ºè‡ªå·±äº‰å–é€ƒè„±æ—¶é—´.ç©ºæ°”ä¸­å¼¥æ¼«ç€ç´§å¼ ä¸å¯¹å³™çš„æ°”æ¯,å±æœºä¸€è§¦å³å‘.\\n\\nChapter 4\\nå¤œå¹•é™ä¸´,ç¥–æ¯ä¾é ç€åŒ»ç–—åºŠé™é™ä¼‘æ¯,åŒ»ç–—æœºå™¨äººå°ç™½åœ¨æ—ç»†å¿ƒæ£€æŸ¥ç”Ÿå‘½ä½“å¾.çªç„¶,æ™ºèƒ½å±…ä½ç³»ç»Ÿå‘å‡ºè­¦æŠ¥,ç¯å…‰é—ªçƒ,é—¨é”è‡ªåŠ¨è§£é™¤.æœºæ¢°ç‹¼ä»¥ç»´ä¿®å‘˜ä¼ªè£…é—¯å…¥èˆ±å†…,è¯•å›¾é»‘å…¥ç¥–æ¯çš„åŒ»ç–—èŠ¯ç‰‡.å°çº¢å¸½æ¥åˆ°é£èˆ¹äººå·¥æ™ºèƒ½å°æ™ºçš„ç´§æ€¥é€šçŸ¥,ç«é€Ÿèµ¶å›å±…ä½èˆ±.å¥¹ç†Ÿç»ƒåœ°æ“ä½œèˆ±å†…ç»ˆç«¯,ä¸æœºæ¢°ç‹¼å±•å¼€æ¿€çƒˆçš„æ•°æ®å¯¹æŠ—.ç¥–æ¯æƒŠé†’å,åšå¼ºåœ°æŒ‡å¯¼å°çº¢å¸½å¹¶ååŠ©å°ç™½é‡‡å–é˜²å¾¡æªæ–½.æœºæ¢°ç‹¼æ­¥æ­¥ç´§é€¼,è¯•å›¾çªƒå–åŒ»ç–—æ•°æ®,ä½†åœ¨å°çº¢å¸½çš„æœºæ™ºå’Œå›¢é˜Ÿåä½œä¸‹,æœ€ç»ˆè¢«è¿«æ’¤é€€.å±æœºæš‚æ—¶è§£é™¤,ç¥–æ¯å®‰æ…°ç€å°çº¢å¸½,å±‹å†…æ¢å¤å¹³é™,æ˜Ÿç©ºä¸‹çš„æ™ºèƒ½èˆ±å†æ¬¡å®ˆæŠ¤ç€å¥¹ä»¬çš„å®‰å…¨.\\n\\nChapter 5\\nå¤œè‰²ä¸‹,ç¥–æ¯çš„æ™ºèƒ½åŒ»ç–—èˆ±è¢«æœªçŸ¥é»‘å®¢åŠ¿åŠ›å…¥ä¾µ,è­¦æŠ¥ç¯é—ªçƒ.æœºæ¢°ç‹¼åˆ©ç”¨é«˜çº§é»‘å®¢ç¨‹åºè¯•å›¾åŠ«æŒåŒ»ç–—ç³»ç»Ÿ,å¤ºå–ç¥–æ¯ä½“å†…çš„åŒ»ç–—èŠ¯ç‰‡.å°çº¢å¸½å‡­å€ŸåŸºç¡€é»‘å®¢è®­ç»ƒå’Œå°æ™ºçš„ååŠ©,è¿…é€Ÿååˆ¶,è°ƒåŠ¨èˆ±å†…å®‰ä¿ç³»ç»Ÿä¸è™šæ‹Ÿç©ºé—´ä½œæˆ˜å·¥å…·.å°ç™½åˆ™å®ˆåœ¨ç¥–æ¯èº«ä¾§,éšæ—¶å‡†å¤‡åº”æ€¥æŠ¤ç†.æœºæ¢°ç‹¼ä¸å°æ™ºåœ¨è™šæ‹Ÿç©ºé—´æ¿€çƒˆå¯¹æŠ—,é»‘å®¢ä¸»è„‘å±…ä¸­æŒ‡æŒ¥,å±€åŠ¿ä¸€åº¦å±æ€¥.èˆ±å¤–,æ—åšå£«æ­£å¸¦é¢†å®‰ä¿å°é˜Ÿèµ¶æ¥å¢æ´.å°çº¢å¸½å†·é™åˆ†æ,å·§å¦™åˆ©ç”¨åŒ»ç–—èˆ±çš„æ™ºèƒ½é˜²å¾¡ä¸AIååŒåå‡»,é€æ­¥å¤ºå›æ§åˆ¶æƒ,æœºæ¢°ç‹¼è¢«è¿«æ’¤é€€,ç¥–æ¯å®‰ç„¶æ— æ™.\\n\\nChapter 6\\nå¤œå¹•é™ä¸´,æ˜Ÿé™…å¿«é€’å‘˜å°çº¢å¸½é©¾é©¶ç€æ­è½½äººå·¥æ™ºèƒ½â€œå°æ™ºâ€çš„é£èˆ¹,æ‚„ç„¶é™è½åœ¨ç¥–æ¯çš„æ™ºèƒ½å±…æ‰€å¤–.å¥¹æ€€æ£ç€ç¨€æœ‰çš„åŒ»ç–—èŠ¯ç‰‡,æ­¥å…¥èˆ±é—¨,è¿æ¥å¥¹çš„æ˜¯ç¥–æ¯æ¸©æŸ”çš„ç›®å…‰å’ŒåŒ»ç–—æœºå™¨äººâ€œå°ç™½â€å¿™ç¢Œçš„èº«å½±.å°±åœ¨è¿™æ—¶,æœºæ¢°ç‹¼ä»¥ç»´ä¿®å·¥çš„èº«ä»½ä¼ªè£…é—¯å…¥,è¯•å›¾è¶æœºçªƒå–èŠ¯ç‰‡.å°çº¢å¸½å‡­å€Ÿæ•é”çš„ç›´è§‰å’Œå°æ™ºçš„å®‰ä¿ç³»ç»Ÿ,åŠæ—¶è¯†ç ´äº†æœºæ¢°ç‹¼çš„ä¼ªè£….åœ¨ä¸€åœºç´§å¼ çš„è™šæ‹Ÿç©ºé—´ä¸ç°å®äº¤é”™çš„æ–—æ™ºæ–—å‹‡ä¸­,å°çº¢å¸½å’Œå°æ™ºååŒä½œæˆ˜,å°ç™½åˆ™å®ˆæŠ¤åœ¨ç¥–æ¯èº«è¾¹,éšæ—¶å‡†å¤‡åº”æ€¥åŒ»ç–—å¤„ç†.æœ€ç»ˆ,å°çº¢å¸½æˆåŠŸå°†èŠ¯ç‰‡å®‰å…¨æ¤å…¥ç¥–æ¯ä½“å†…,æœºæ¢°ç‹¼è¢«å‡»é€€.å±…æ‰€å†…æ¢å¤å¹³é™,ç¥–æ¯éœ²å‡ºå®‰å¿ƒçš„å¾®ç¬‘,çª—å¤–çš„æ˜Ÿæ²³æ˜ ç…§ç€ä¸‰ä»£äººç±»ä¸äººå·¥æ™ºèƒ½å¹¶è‚©ä½œæˆ˜åçš„æ¸©é¦¨ä¸å¸Œæœ›.\\n\\nChapter 7\\nå°çº¢å¸½è¸å…¥åŒ»ç–—ç«™,æ™¨å…‰æ˜ ç…§ç€å¥¹åšå®šçš„ç¥æƒ….å¥¹ä¸ç¥–æ¯çŸ­æš‚æ¸©æƒ…ç›¸æ‹¥,å°†åŒ»ç–—èŠ¯ç‰‡é€’äº¤ç»™å°ç™½å‡†å¤‡æ¤å…¥.æ—åšå£«è°¨æ…åœ°æ£€æŸ¥ç«™å†…å®‰å…¨,å´å¯Ÿè§‰ä¸€ä¸å¼‚å¸¸.å°±åœ¨å°ç™½å‡†å¤‡æ‰‹æœ¯æ—¶,æœºæ¢°ç‹¼åœ¨é»‘å®¢ä¸»è„‘çš„è¿œç¨‹æŒ‡æŒ¥ä¸‹çªç„¶æš´éœ²èº«ä»½,ä¼å›¾å¤ºå–åŒ»ç–—èŠ¯ç‰‡.å°æ™ºç´§æ€¥å¯åŠ¨å®‰ä¿ç¨‹åº,è™šæ‹Ÿç©ºé—´ä¸­ä¸æœºæ¢°ç‹¼å±•å¼€å¯¹æŠ—.æ—åšå£«è”åˆå°çº¢å¸½ä¸´æœºåº”å˜,å°é”åŒ»ç–—ç«™å‡ºå£.ç¥–æ¯åœ¨å±æ€¥å…³å¤´æ¿€åŠ±å°çº¢å¸½åˆ©ç”¨è‡ªå·±çš„é»‘å®¢æŠ€èƒ½é€†è½¬å±€åŠ¿.ç»è¿‡ä¸€åœºæ™ºæ…§ä¸å‹‡æ°”çš„è¾ƒé‡,å°çº¢å¸½ä¸å°æ™ºåˆåŠ›å‡»é€€æœºæ¢°ç‹¼,åŒ»ç–—èŠ¯ç‰‡æˆåŠŸæ¤å…¥ç¥–æ¯ä½“å†….éšç€æ™¨æ›¦å½»åº•ç…§äº®åŒ»ç–—ç«™,æ–°å¸Œæœ›çš„é»æ˜ç»ˆäºé™ä¸´,ä¼—äººé‡è·å®‰å…¨ä¸å¸Œæœ›.\\n\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_story_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7039b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt = \"\"\"\n",
    "è¯·ä»ä»¥ä¸‹æ•…äº‹ä¸­æå–æ‰€æœ‰å…³é”®äº‹ä»¶ã€‚\n",
    "\n",
    "è¦æ±‚ï¼š\n",
    "1. æ¯ä¸ªäº‹ä»¶ç”¨10-20å­—ç®€æ´æè¿°\n",
    "2. æŒ‰æ—¶é—´é¡ºåºæ’åˆ—\n",
    "\n",
    "é‡è¦é™åˆ¶ï¼š\n",
    "1. åªæå–æ¯ä¸ªç« èŠ‚å†…æ˜ç¡®æè¿°å‘ç”Ÿçš„äº‹ä»¶, ä¸è¦æ·»åŠ ä»»ä½•å‡è®¾æˆ–æœªæ˜ç¡®æè¿°çš„äº‹ä»¶, ä¸è¦æ¨æ–­ç« èŠ‚ä¹‹é—´å‘ç”Ÿäº†ä»€ä¹ˆ\n",
    "2. å‡†ç¡®æè¿°åŠ¨ä½œçš„æ€§è´¨, ä¿æŒåŠ¨ä½œæè¿°çš„å‡†ç¡®æ€§ï¼Œä¸è¦å¤¸å¤§æˆ–æ”¹å˜å…¶æ€§è´¨,æ¯”å¦‚ä¸è¦æŠŠ\"å‡†å¤‡åšX\"ç†è§£ä¸º\"å·²ç»å®ŒæˆX\"ä¹Ÿä¸è¦æŠŠ\"å¨èƒè¦åšY\"ç†è§£ä¸º\"å·²ç»åšäº†Y\"\n",
    "3. æå–äº‹ä»¶çš„åŒæ—¶éœ€è¦æ ‡æ³¨äº‹ä»¶æ¥æº\n",
    "\n",
    "è¾“å‡ºæ ¼å¼ï¼š\n",
    "[\n",
    "  {\"description\":\"äº‹ä»¶æè¿°1\",\"reference\":\"chapter 1:æ–‡æœ¬åŸæ–‡\"},\n",
    "  {\"description\":\"äº‹ä»¶æè¿°2\",\"reference\":\"chapter 2:æ–‡æœ¬åŸæ–‡\"},\n",
    "  ...\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3994c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "response1 = generate_response([\n",
    "        {\"role\": \"user\", \"content\":sys_prompt},\n",
    "    {\"role\": \"user\", \"content\": f\"extract the key events base on the following story plot:\\n\\n{concat_story_plot}\"}\n",
    "    ], model=\"gpt-4.1\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20c0842e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. å°çº¢å¸½èº«ç©¿çº¢è‰²æ™ºèƒ½åˆ¶æœèµ°å…¥å¤ªç©ºæ¸¯ä¸»æ§å¤§å…\n",
      "2. æ—åšå£«é€’ä¸Šæœ€åçš„è®¸å¯æ–‡ä»¶å¹¶å®å˜±å°çº¢å¸½æ³¨æ„å®‰å…¨\n",
      "3. å°çº¢å¸½ç‚¹å¤´,å‡†å¤‡è¸ä¸Šæ˜Ÿé™…ä»»åŠ¡\n",
      "4. é£èˆ¹AIå°æ™ºå¯åŠ¨æ¬¢è¿ç¨‹åº\n",
      "5. å°çº¢å¸½é©¾é©¶é£èˆ¹è½½ç¥–æ¯å’Œå°ç™½ç©¿è¡Œå¤ªç©ºè·ƒè¿é€šé“\n",
      "6. å°ç™½è°ƒè¯•åŒ»ç–—è®¾å¤‡,ç¥–æ¯å¾®ç¬‘\n",
      "7. å°çº¢å¸½ä¸å°æ™ºåä½œå…³æ³¨å¯¼èˆªä¸é˜²å¾¡ç³»ç»Ÿ\n",
      "8. æœºæ¢°ç‹¼æ½œä¼å¤–éƒ¨è¯•å›¾é»‘å…¥é£èˆ¹\n",
      "9. å°æ™ºå‘å‡ºè­¦æŠ¥,å°çº¢å¸½å¯åŠ¨é˜²å¾¡åè®®å¹¶æ²Ÿé€šåº”å¯¹å±æœº\n",
      "10. å°çº¢å¸½é©¾é©¶æ‚¬æµ®æ»‘æ¿ç©¿æ¢­æš®è‰²æ£®æ—\n",
      "11. æœºæ¢°ç‹¼æ‹¦ä½å°çº¢å¸½,å¨èƒè¦æ±‚äº¤å‡ºåŒ»ç–—èŠ¯ç‰‡\n",
      "12. å°çº¢å¸½å‘¼å«å°æ™ºæ”¯æ´,åˆ©ç”¨æ»‘æ¿å‘¨æ—‹æœºæ¢°ç‹¼\n",
      "13. å°çº¢å¸½å°è¯•ç ´è§£æœºæ¢°ç‹¼æ§åˆ¶ä¿¡å·äº‰å–é€ƒè„±æ—¶é—´\n",
      "14. ç¥–æ¯ä¼‘æ¯,å°ç™½æ£€æŸ¥ç”Ÿå‘½ä½“å¾\n",
      "15. æ™ºèƒ½å±…ä½ç³»ç»Ÿè­¦æŠ¥,é—¨é”è‡ªåŠ¨è§£é™¤\n",
      "16. æœºæ¢°ç‹¼ä¼ªè£…ç»´ä¿®å‘˜é—¯å…¥èˆ±å†…,è¯•å›¾é»‘å…¥åŒ»ç–—èŠ¯ç‰‡\n",
      "17. å°çº¢å¸½æ¥åˆ°å°æ™ºé€šçŸ¥,èµ¶å›å±…ä½èˆ±ä¸æœºæ¢°ç‹¼æ•°æ®å¯¹æŠ—\n",
      "18. ç¥–æ¯ååŠ©å°çº¢å¸½å’Œå°ç™½é˜²å¾¡æœºæ¢°ç‹¼\n",
      "19. æœºæ¢°ç‹¼è¯•å›¾çªƒå–åŒ»ç–—æ•°æ®,æœ€ç»ˆè¢«è¿«æ’¤é€€\n",
      "20. ç¥–æ¯å®‰æ…°å°çº¢å¸½,å±‹å†…æ¢å¤å¹³é™\n",
      "21. ç¥–æ¯åŒ»ç–—èˆ±è¢«é»‘å®¢å…¥ä¾µ,è­¦æŠ¥ç¯é—ªçƒ\n",
      "22. æœºæ¢°ç‹¼è¯•å›¾åŠ«æŒåŒ»ç–—ç³»ç»Ÿ,å¤ºå–åŒ»ç–—èŠ¯ç‰‡\n",
      "23. å°çº¢å¸½å’Œå°æ™ºååˆ¶,è°ƒåŠ¨å®‰ä¿ç³»ç»Ÿä¸è™šæ‹Ÿç©ºé—´ä½œæˆ˜å·¥å…·\n",
      "24. å°ç™½å®ˆåœ¨ç¥–æ¯èº«ä¾§å‡†å¤‡åº”æ€¥æŠ¤ç†\n",
      "25. æœºæ¢°ç‹¼ä¸å°æ™ºåœ¨è™šæ‹Ÿç©ºé—´æ¿€çƒˆå¯¹æŠ—,é»‘å®¢ä¸»è„‘æŒ‡æŒ¥\n",
      "26. æ—åšå£«å¸¦å®‰ä¿å°é˜Ÿèµ¶æ¥å¢æ´\n",
      "27. å°çº¢å¸½åˆ©ç”¨æ™ºèƒ½é˜²å¾¡ä¸AIååŒåå‡»,é€æ­¥å¤ºå›æ§åˆ¶æƒ\n",
      "28. å°çº¢å¸½é©¾é©¶é£èˆ¹é™è½ç¥–æ¯å±…æ‰€å¤–,æ­¥å…¥èˆ±é—¨\n",
      "29. ç¥–æ¯è¿æ¥å°çº¢å¸½,å°ç™½å¿™ç¢Œåœ¨æ—\n",
      "30. æœºæ¢°ç‹¼ä¼ªè£…ç»´ä¿®å·¥é—¯å…¥,è¯•å›¾çªƒå–èŠ¯ç‰‡\n",
      "31. å°çº¢å¸½å’Œå°æ™ºè¯†ç ´æœºæ¢°ç‹¼ä¼ªè£…,ååŒä½œæˆ˜\n",
      "32. å°ç™½å®ˆæŠ¤ç¥–æ¯,å‡†å¤‡åº”æ€¥åŒ»ç–—å¤„ç†\n",
      "33. å°çº¢å¸½æˆåŠŸå°†èŠ¯ç‰‡æ¤å…¥ç¥–æ¯ä½“å†…,æœºæ¢°ç‹¼è¢«å‡»é€€\n",
      "34. å±…æ‰€æ¢å¤å¹³é™,ç¥–æ¯å®‰å¿ƒå¾®ç¬‘\n",
      "35. å°çº¢å¸½è¸å…¥åŒ»ç–—ç«™,ä¸ç¥–æ¯ç›¸æ‹¥,é€’äº¤åŒ»ç–—èŠ¯ç‰‡\n",
      "36. æ—åšå£«æ£€æŸ¥å®‰å…¨,å¯Ÿè§‰å¼‚å¸¸\n",
      "37. å°ç™½å‡†å¤‡æ‰‹æœ¯æ—¶,æœºæ¢°ç‹¼æš´éœ²èº«ä»½ä¼å›¾å¤ºå–èŠ¯ç‰‡\n",
      "38. å°æ™ºå¯åŠ¨å®‰ä¿ç¨‹åº,ä¸æœºæ¢°ç‹¼è™šæ‹Ÿç©ºé—´å¯¹æŠ—\n",
      "39. æ—åšå£«ä¸å°çº¢å¸½å°é”åŒ»ç–—ç«™å‡ºå£\n",
      "40. ç¥–æ¯æ¿€åŠ±å°çº¢å¸½åˆ©ç”¨é»‘å®¢æŠ€èƒ½é€†è½¬å±€åŠ¿\n",
      "41. å°çº¢å¸½ä¸å°æ™ºåˆåŠ›å‡»é€€æœºæ¢°ç‹¼,èŠ¯ç‰‡æˆåŠŸæ¤å…¥ç¥–æ¯ä½“å†…\n",
      "42. åŒ»ç–—ç«™æ¢å¤å®‰å…¨,ä¼—äººé‡è·å¸Œæœ›\n",
      "\n"
     ]
    }
   ],
   "source": [
    "event = \"\"\n",
    "for i,j in enumerate(eval(response1)):\n",
    "    event += f\"{i+1}. {j['description']}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6bea53ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. å°çº¢å¸½èº«ç©¿çº¢è‰²æ™ºèƒ½åˆ¶æœèµ°å…¥å¤ªç©ºæ¸¯ä¸»æ§å¤§å…\\n2. æ—åšå£«é€’ä¸Šæœ€åçš„è®¸å¯æ–‡ä»¶å¹¶å®å˜±å°çº¢å¸½æ³¨æ„å®‰å…¨\\n3. å°çº¢å¸½ç‚¹å¤´,å‡†å¤‡è¸ä¸Šæ˜Ÿé™…ä»»åŠ¡\\n4. é£èˆ¹AIå°æ™ºå¯åŠ¨æ¬¢è¿ç¨‹åº\\n5. å°çº¢å¸½é©¾é©¶é£èˆ¹è½½ç¥–æ¯å’Œå°ç™½ç©¿è¡Œå¤ªç©ºè·ƒè¿é€šé“\\n6. å°ç™½è°ƒè¯•åŒ»ç–—è®¾å¤‡,ç¥–æ¯å¾®ç¬‘\\n7. å°çº¢å¸½ä¸å°æ™ºåä½œå…³æ³¨å¯¼èˆªä¸é˜²å¾¡ç³»ç»Ÿ\\n8. æœºæ¢°ç‹¼æ½œä¼å¤–éƒ¨è¯•å›¾é»‘å…¥é£èˆ¹\\n9. å°æ™ºå‘å‡ºè­¦æŠ¥,å°çº¢å¸½å¯åŠ¨é˜²å¾¡åè®®å¹¶æ²Ÿé€šåº”å¯¹å±æœº\\n10. å°çº¢å¸½é©¾é©¶æ‚¬æµ®æ»‘æ¿ç©¿æ¢­æš®è‰²æ£®æ—\\n11. æœºæ¢°ç‹¼æ‹¦ä½å°çº¢å¸½,å¨èƒè¦æ±‚äº¤å‡ºåŒ»ç–—èŠ¯ç‰‡\\n12. å°çº¢å¸½å‘¼å«å°æ™ºæ”¯æ´,åˆ©ç”¨æ»‘æ¿å‘¨æ—‹æœºæ¢°ç‹¼\\n13. å°çº¢å¸½å°è¯•ç ´è§£æœºæ¢°ç‹¼æ§åˆ¶ä¿¡å·äº‰å–é€ƒè„±æ—¶é—´\\n14. ç¥–æ¯ä¼‘æ¯,å°ç™½æ£€æŸ¥ç”Ÿå‘½ä½“å¾\\n15. æ™ºèƒ½å±…ä½ç³»ç»Ÿè­¦æŠ¥,é—¨é”è‡ªåŠ¨è§£é™¤\\n16. æœºæ¢°ç‹¼ä¼ªè£…ç»´ä¿®å‘˜é—¯å…¥èˆ±å†…,è¯•å›¾é»‘å…¥åŒ»ç–—èŠ¯ç‰‡\\n17. å°çº¢å¸½æ¥åˆ°å°æ™ºé€šçŸ¥,èµ¶å›å±…ä½èˆ±ä¸æœºæ¢°ç‹¼æ•°æ®å¯¹æŠ—\\n18. ç¥–æ¯ååŠ©å°çº¢å¸½å’Œå°ç™½é˜²å¾¡æœºæ¢°ç‹¼\\n19. æœºæ¢°ç‹¼è¯•å›¾çªƒå–åŒ»ç–—æ•°æ®,æœ€ç»ˆè¢«è¿«æ’¤é€€\\n20. ç¥–æ¯å®‰æ…°å°çº¢å¸½,å±‹å†…æ¢å¤å¹³é™\\n21. ç¥–æ¯åŒ»ç–—èˆ±è¢«é»‘å®¢å…¥ä¾µ,è­¦æŠ¥ç¯é—ªçƒ\\n22. æœºæ¢°ç‹¼è¯•å›¾åŠ«æŒåŒ»ç–—ç³»ç»Ÿ,å¤ºå–åŒ»ç–—èŠ¯ç‰‡\\n23. å°çº¢å¸½å’Œå°æ™ºååˆ¶,è°ƒåŠ¨å®‰ä¿ç³»ç»Ÿä¸è™šæ‹Ÿç©ºé—´ä½œæˆ˜å·¥å…·\\n24. å°ç™½å®ˆåœ¨ç¥–æ¯èº«ä¾§å‡†å¤‡åº”æ€¥æŠ¤ç†\\n25. æœºæ¢°ç‹¼ä¸å°æ™ºåœ¨è™šæ‹Ÿç©ºé—´æ¿€çƒˆå¯¹æŠ—,é»‘å®¢ä¸»è„‘æŒ‡æŒ¥\\n26. æ—åšå£«å¸¦å®‰ä¿å°é˜Ÿèµ¶æ¥å¢æ´\\n27. å°çº¢å¸½åˆ©ç”¨æ™ºèƒ½é˜²å¾¡ä¸AIååŒåå‡»,é€æ­¥å¤ºå›æ§åˆ¶æƒ\\n28. å°çº¢å¸½é©¾é©¶é£èˆ¹é™è½ç¥–æ¯å±…æ‰€å¤–,æ­¥å…¥èˆ±é—¨\\n29. ç¥–æ¯è¿æ¥å°çº¢å¸½,å°ç™½å¿™ç¢Œåœ¨æ—\\n30. æœºæ¢°ç‹¼ä¼ªè£…ç»´ä¿®å·¥é—¯å…¥,è¯•å›¾çªƒå–èŠ¯ç‰‡\\n31. å°çº¢å¸½å’Œå°æ™ºè¯†ç ´æœºæ¢°ç‹¼ä¼ªè£…,ååŒä½œæˆ˜\\n32. å°ç™½å®ˆæŠ¤ç¥–æ¯,å‡†å¤‡åº”æ€¥åŒ»ç–—å¤„ç†\\n33. å°çº¢å¸½æˆåŠŸå°†èŠ¯ç‰‡æ¤å…¥ç¥–æ¯ä½“å†…,æœºæ¢°ç‹¼è¢«å‡»é€€\\n34. å±…æ‰€æ¢å¤å¹³é™,ç¥–æ¯å®‰å¿ƒå¾®ç¬‘\\n35. å°çº¢å¸½è¸å…¥åŒ»ç–—ç«™,ä¸ç¥–æ¯ç›¸æ‹¥,é€’äº¤åŒ»ç–—èŠ¯ç‰‡\\n36. æ—åšå£«æ£€æŸ¥å®‰å…¨,å¯Ÿè§‰å¼‚å¸¸\\n37. å°ç™½å‡†å¤‡æ‰‹æœ¯æ—¶,æœºæ¢°ç‹¼æš´éœ²èº«ä»½ä¼å›¾å¤ºå–èŠ¯ç‰‡\\n38. å°æ™ºå¯åŠ¨å®‰ä¿ç¨‹åº,ä¸æœºæ¢°ç‹¼è™šæ‹Ÿç©ºé—´å¯¹æŠ—\\n39. æ—åšå£«ä¸å°çº¢å¸½å°é”åŒ»ç–—ç«™å‡ºå£\\n40. ç¥–æ¯æ¿€åŠ±å°çº¢å¸½åˆ©ç”¨é»‘å®¢æŠ€èƒ½é€†è½¬å±€åŠ¿\\n41. å°çº¢å¸½ä¸å°æ™ºåˆåŠ›å‡»é€€æœºæ¢°ç‹¼,èŠ¯ç‰‡æˆåŠŸæ¤å…¥ç¥–æ¯ä½“å†…\\n42. åŒ»ç–—ç«™æ¢å¤å®‰å…¨,ä¼—äººé‡è·å¸Œæœ›\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee43d407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval(response1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78bba3f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (story_evaluator.py, line 723)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py:3526\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 1\u001b[0;36m\n\u001b[0;31m    from src.analysis.story_evaluator import validate_events_against_source\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/Story/src/analysis/story_evaluator.py:723\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"\"\")ghbvh\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def extract_events_no_hallucination(story_data, model=\"gpt-4.1\", temperature=None):\n",
    "    \"\"\"\n",
    "    æ— å¹»è§‰ç‰ˆæœ¬ï¼šå…ˆåˆ†å¥ç¼–å·ï¼Œå†è®©LLMé€‰æ‹©\n",
    "    temperature: Noneä½¿ç”¨é»˜è®¤å€¼ï¼Œ0è¡¨ç¤ºå›ºå®šæ¨¡å¼ï¼Œ>0è¡¨ç¤ºéšæœºæ¨¡å¼\n",
    "    \"\"\"\n",
    "    from src.utils.utils import split_plot_into_sentences\n",
    "    \n",
    "    # ç¬¬ä¸€æ­¥ï¼šé¢„å¤„ç†åŸæ–‡ï¼Œç»™æ¯ä¸ªå¥å­ç¼–å·\n",
    "    all_sentences = []\n",
    "    sentence_map = {}\n",
    "    sentence_counter = 0\n",
    "    \n",
    "    for ch in story_data:\n",
    "        chapter_id = ch.get('chapter_id', '')\n",
    "        plot = ch.get('plot', '')\n",
    "        sentences = split_plot_into_sentences(plot)\n",
    "        \n",
    "        for sent in sentences:\n",
    "            sentence_map[sentence_counter] = {\n",
    "                \"sentence\": sent,\n",
    "                \"chapter\": chapter_id\n",
    "            }\n",
    "            all_sentences.append(f\"{sentence_counter}: {sent}\")\n",
    "            sentence_counter += 1\n",
    "    \n",
    "    # å‡†å¤‡ç¼–å·å¥å­åˆ—è¡¨\n",
    "    numbered_sentences = \"\\n\".join(all_sentences)\n",
    "    double_newline = \"\\n\\n\"\n",
    "\n",
    "    print(\"  ç¬¬ä¸€æ­¥ï¼šæå–äº‹ä»¶...\")\n",
    "    # ç¬¬äºŒæ­¥ï¼šæå–äº‹ä»¶\n",
    "    step1_prompt = f\"\"\"\n",
    "è¯·ä»ä»¥ä¸‹æ•…äº‹ä¸­æå–æ‰€æœ‰å…³é”®äº‹ä»¶ã€‚\n",
    "\n",
    "è¦æ±‚ï¼š\n",
    "1. æ¯ä¸ªäº‹ä»¶ç”¨10-20å­—ç®€æ´æè¿°\n",
    "2. æŒ‰æ—¶é—´é¡ºåºæ’åˆ—\n",
    "\n",
    "é‡è¦é™åˆ¶ï¼š\n",
    "1. åªæå–æ¯ä¸ªç« èŠ‚å†…æ˜ç¡®æè¿°å‘ç”Ÿçš„äº‹ä»¶, ä¸è¦æ·»åŠ ä»»ä½•å‡è®¾æˆ–æœªæ˜ç¡®æè¿°çš„äº‹ä»¶, ä¸è¦æ¨æ–­ç« èŠ‚ä¹‹é—´å‘ç”Ÿäº†ä»€ä¹ˆ\n",
    "2. å‡†ç¡®æè¿°åŠ¨ä½œçš„æ€§è´¨, ä¿æŒåŠ¨ä½œæè¿°çš„å‡†ç¡®æ€§ï¼Œä¸è¦å¤¸å¤§æˆ–æ”¹å˜å…¶æ€§è´¨,æ¯”å¦‚ä¸è¦æŠŠ\"å‡†å¤‡åšX\"ç†è§£ä¸º\"å·²ç»å®ŒæˆX\"ä¹Ÿä¸è¦æŠŠ\"å¨èƒè¦åšY\"ç†è§£ä¸º\"å·²ç»åšäº†Y\"\n",
    "\n",
    "è¾“å‡ºæ ¼å¼ï¼š\n",
    "[\n",
    "  \"äº‹ä»¶æè¿°1\",\n",
    "  \"äº‹ä»¶æè¿°2\"\n",
    "]\n",
    "\n",
    "æ•…äº‹æ–‡æœ¬ï¼š\n",
    "{double_newline.join([f\"ã€{ch.get('chapter_id', '')}ã€‘{ch.get('plot', '')}\" for ch in story_data])}\n",
    "\"\"\"\n",
    "    \n",
    "    # æ ¹æ®temperatureå‚æ•°è°ƒç”¨\n",
    "    if temperature is not None:\n",
    "        response1 = generate_response([{\"role\": \"user\", \"content\": step1_prompt}], model=model, temperature=temperature)\n",
    "    else:\n",
    "        response1 = generate_response([{\"role\": \"user\", \"content\": step1_prompt}], model=model)\n",
    "    \n",
    "    try:\n",
    "        from src.utils.utils import convert_json\n",
    "        events_only = convert_json(response1)\n",
    "        if not isinstance(events_only, list):\n",
    "            print(f\"âš ï¸ äº‹ä»¶æå–å¤±è´¥\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ äº‹ä»¶æå–å¤±è´¥ï¼š{e}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"  âœ… æå–åˆ° {len(events_only)} ä¸ªäº‹ä»¶\")\n",
    "    print(\"  ç¬¬äºŒæ­¥ï¼šåŒ¹é…åŸæ–‡å¥å­...\")\n",
    "    \n",
    "    # ç¬¬ä¸‰æ­¥ï¼šè®©LLMä¸ºæ¯ä¸ªäº‹ä»¶é€‰æ‹©å¥å­ç¼–å·\n",
    "    step2_prompt = f\"\"\"\n",
    "ç»™å®šäº‹ä»¶åˆ—è¡¨å’Œç¼–å·çš„åŸæ–‡å¥å­ï¼Œè¯·ä¸ºæ¯ä¸ªäº‹ä»¶é€‰æ‹©æœ€åŒ¹é…çš„å¥å­ç¼–å·ã€‚\n",
    "\n",
    "äº‹ä»¶åˆ—è¡¨ï¼š\n",
    "{json.dumps(events_only, ensure_ascii=False, indent=2)}\n",
    "\n",
    "ç¼–å·çš„åŸæ–‡å¥å­ï¼š\n",
    "{numbered_sentences}\n",
    "\n",
    "è¦æ±‚ï¼š\n",
    "1. ä¸ºæ¯ä¸ªäº‹ä»¶é€‰æ‹©ä¸€ä¸ªæœ€åŒ¹é…çš„å¥å­ç¼–å·\n",
    "2. å¦‚æœæ‰¾ä¸åˆ°åŒ¹é…çš„å¥å­ï¼Œç¼–å·å¡«å†™-1\n",
    "3. åªèƒ½é€‰æ‹©å·²ç»™å‡ºçš„ç¼–å·ï¼Œä¸èƒ½å¡«å†™å…¶ä»–æ•°å­—\n",
    "\n",
    "è¾“å‡ºæ ¼å¼ï¼š\n",
    "[\n",
    "  {{\n",
    "    \"event\": \"äº‹ä»¶æè¿°\",\n",
    "    \"sentence_number\": ç¼–å·æ•°å­—,\n",
    "    \"confidence\": \"high/medium/low\"\n",
    "  }}\n",
    "]\n",
    "\"\"\"\n",
    "    \n",
    "    # æ ¹æ®temperatureå‚æ•°è°ƒç”¨\n",
    "    if temperature is not None:\n",
    "        response2 = generate_response([{\"role\": \"user\", \"content\": step2_prompt}], model=model, temperature=temperature)\n",
    "    else:\n",
    "        response2 = generate_response([{\"role\": \"user\", \"content\": step2_prompt}], model=model)\n",
    "    \n",
    "    try:\n",
    "        matches = convert_json(response2)\n",
    "        if not isinstance(matches, list):\n",
    "            print(f\"âš ï¸ åŒ¹é…å¤±è´¥\")\n",
    "            return []\n",
    "        \n",
    "        # æ„å»ºæœ€ç»ˆç»“æœ\n",
    "        final_events = []\n",
    "        filtered_count = 0\n",
    "        \n",
    "        for match in matches:\n",
    "            sentence_num = match.get(\"sentence_number\", -1)\n",
    "            \n",
    "            if sentence_num == -1 or sentence_num not in sentence_map:\n",
    "                filtered_count += 1\n",
    "                print(f\"  âš ï¸ è¿‡æ»¤äº‹ä»¶ï¼ˆæ— åŒ¹é…å¥å­ï¼‰ï¼š{match.get('event', '')}\")\n",
    "                continue\n",
    "            \n",
    "            sentence_info = sentence_map[sentence_num]\n",
    "            final_events.append({\n",
    "                \"event\": match.get(\"event\", \"\"),\n",
    "                \"source\": sentence_info[\"sentence\"],\n",
    "                \"chapter\": sentence_info[\"chapter\"],\n",
    "                \"confidence\": match.get(\"confidence\", \"unknown\")\n",
    "            })\n",
    "        \n",
    "        print(f\"  âœ… åŒ¹é…å®Œæˆï¼Œè¿‡æ»¤äº† {filtered_count} ä¸ªæ— åŒ¹é…äº‹ä»¶\")\n",
    "\n",
    "        validated_events = validate_events_against_source(final_events, model=model, temperature=temperature)\n",
    "        return validated_events\n",
    "\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ åŒ¹é…å¤±è´¥ï¼š{e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f809bf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ç¬¬ä¸€æ­¥ï¼šæå–äº‹ä»¶...\n",
      "åŸå§‹ content: [\n",
      "  \"å°çº¢å¸½èµ°å…¥å¤ªç©ºæ¸¯ä¸»æ§å¤§å…\",\n",
      "  \"æ—åšå£«é€’ä¸Šè®¸å¯æ–‡ä»¶å¹¶å®å˜±å°çº¢å¸½æ³¨æ„é»‘å®¢è¢­å‡»\",\n",
      "  \"å°çº¢å¸½ä¸æ—åšå£«ä½å£°äº¤è°ˆ\",\n",
      "  \"å°çº¢å¸½é©¾é©¶é£èˆ¹ç©¿è¶Šå¤ªç©ºè·ƒè¿é€šé“\",\n",
      "  \"ç¥–æ¯åœ¨é£èˆ¹å†…ç—…é‡ä¼‘æ¯ï¼Œå°ç™½è°ƒè¯•åŒ»ç–—è®¾å¤‡\",\n",
      "  \"å°çº¢å¸½ä¸å°æ™ºåä½œå…³æ³¨å¯¼èˆªä¸é˜²å¾¡ç³»ç»Ÿ\",\n",
      "  \"æœºæ¢°ç‹¼æ½œä¼åœ¨é£èˆ¹å¤–è¯•å›¾é»‘å…¥é£èˆ¹å±éšœ\",\n",
      "  \"å°æ™ºå‘å‡ºè­¦æŠ¥ï¼Œå°çº¢å¸½å¯åŠ¨é˜²å¾¡åè®®å¹¶æ²Ÿé€šåº”å¯¹å±æœº\",\n",
      "  \"å°çº¢å¸½é©¾é©¶æ‚¬æµ®æ»‘æ¿ç©¿æ¢­æš®è‰²æ£®æ—\",\n",
      "  \"æœºæ¢°ç‹¼æ‹¦ä½å°çº¢å¸½ï¼Œå¨èƒè¦æ±‚äº¤å‡ºåŒ»ç–—èŠ¯ç‰‡\",\n",
      "  \"å°çº¢å¸½å‘¼å«å°æ™ºæ”¯æ´å¹¶ä¸æœºæ¢°ç‹¼å‘¨æ—‹\",\n",
      "  \"å°çº¢å¸½å°è¯•ç ´è§£æœºæ¢°ç‹¼æ§åˆ¶ä¿¡å·äº‰å–é€ƒè„±æ—¶é—´\",\n",
      "  \"ç¥–æ¯åœ¨åŒ»ç–—åºŠä¼‘æ¯ï¼Œå°ç™½æ£€æŸ¥ç”Ÿå‘½ä½“å¾\",\n",
      "  \"æ™ºèƒ½å±…ä½ç³»ç»Ÿå‘å‡ºè­¦æŠ¥ï¼Œé—¨é”è‡ªåŠ¨è§£é™¤\",\n",
      "  \"æœºæ¢°ç‹¼ä¼ªè£…ç»´ä¿®å‘˜é—¯å…¥èˆ±å†…è¯•å›¾é»‘å…¥åŒ»ç–—èŠ¯ç‰‡\",\n",
      "  \"å°çº¢å¸½æ¥åˆ°å°æ™ºé€šçŸ¥èµ¶å›å±…ä½èˆ±\",\n",
      "  \"å°çº¢å¸½ä¸æœºæ¢°ç‹¼å±•å¼€æ•°æ®å¯¹æŠ—\",\n",
      "  \"ç¥–æ¯ååŠ©å°ç™½é‡‡å–é˜²å¾¡æªæ–½\",\n",
      "  \"æœºæ¢°ç‹¼è¯•å›¾çªƒå–åŒ»ç–—æ•°æ®åè¢«è¿«æ’¤é€€\",\n",
      "  \"ç¥–æ¯å®‰æ…°å°çº¢å¸½ï¼Œå±‹å†…æ¢å¤å¹³é™\",\n",
      "  \"ç¥–æ¯çš„åŒ»ç–—èˆ±è¢«é»‘å®¢åŠ¿åŠ›å…¥ä¾µ\",\n",
      "  \"æœºæ¢°ç‹¼è¯•å›¾åŠ«æŒåŒ»ç–—ç³»ç»Ÿå¤ºå–åŒ»ç–—èŠ¯ç‰‡\",\n",
      "  \"å°çº¢å¸½ä¸å°æ™ºåä½œååˆ¶é»‘å®¢æ”»å‡»\",\n",
      "  \"å°ç™½å®ˆåœ¨ç¥–æ¯èº«ä¾§å‡†å¤‡åº”æ€¥æŠ¤ç†\",\n",
      "  \"æœºæ¢°ç‹¼ä¸å°æ™ºåœ¨è™šæ‹Ÿç©ºé—´å¯¹æŠ—\",\n",
      "  \"æ—åšå£«å¸¦å®‰ä¿å°é˜Ÿèµ¶æ¥å¢æ´\",\n",
      "  \"å°çº¢å¸½åˆ©ç”¨æ™ºèƒ½é˜²å¾¡ä¸AIååŒåå‡»\",\n",
      "  \"æœºæ¢°ç‹¼è¢«è¿«æ’¤é€€ï¼Œç¥–æ¯å®‰ç„¶æ— æ™\",\n",
      "  \"å°çº¢å¸½é©¾é©¶é£èˆ¹é™è½ç¥–æ¯å±…æ‰€å¤–\",\n",
      "  \"å°çº¢å¸½å¸¦ç€åŒ»ç–—èŠ¯ç‰‡æ­¥å…¥èˆ±é—¨\",\n",
      "  \"æœºæ¢°ç‹¼ä¼ªè£…ç»´ä¿®å·¥é—¯å…¥è¯•å›¾çªƒå–èŠ¯ç‰‡\",\n",
      "  \"å°çº¢å¸½å’Œå°æ™ºè¯†ç ´æœºæ¢°ç‹¼ä¼ªè£…å¹¶ååŒä½œæˆ˜\",\n",
      "  \"å°ç™½å®ˆæŠ¤ç¥–æ¯å‡†å¤‡åº”æ€¥åŒ»ç–—å¤„ç†\",\n",
      "  \"å°çº¢å¸½æˆåŠŸå°†èŠ¯ç‰‡æ¤å…¥ç¥–æ¯ä½“å†…\",\n",
      "  \"æœºæ¢°ç‹¼è¢«å‡»é€€ï¼Œå±…æ‰€æ¢å¤å¹³é™\",\n",
      "  \"å°çº¢å¸½è¸å…¥åŒ»ç–—ç«™ä¸ç¥–æ¯ç›¸æ‹¥\",\n",
      "  \"å°çº¢å¸½å°†åŒ»ç–—èŠ¯ç‰‡é€’äº¤å°ç™½å‡†å¤‡æ¤å…¥\",\n",
      "  \"æ—åšå£«æ£€æŸ¥å®‰å…¨å¹¶å¯Ÿè§‰å¼‚å¸¸\",\n",
      "  \"æœºæ¢°ç‹¼æš´éœ²èº«ä»½ä¼å›¾å¤ºå–åŒ»ç–—èŠ¯ç‰‡\",\n",
      "  \"å°æ™ºå¯åŠ¨å®‰ä¿ç¨‹åºä¸æœºæ¢°ç‹¼å¯¹æŠ—\",\n",
      "  \"æ—åšå£«ä¸å°çº¢å¸½å°é”åŒ»ç–—ç«™å‡ºå£\",\n",
      "  \"ç¥–æ¯æ¿€åŠ±å°çº¢å¸½åˆ©ç”¨é»‘å®¢æŠ€èƒ½é€†è½¬å±€åŠ¿\",\n",
      "  \"å°çº¢å¸½ä¸å°æ™ºåˆåŠ›å‡»é€€æœºæ¢°ç‹¼\",\n",
      "  \"åŒ»ç–—èŠ¯ç‰‡æˆåŠŸæ¤å…¥ç¥–æ¯ä½“å†…\"\n",
      "]...\n",
      "  âœ… æå–åˆ° 44 ä¸ªäº‹ä»¶\n",
      "  ç¬¬äºŒæ­¥ï¼šåŒ¹é…åŸæ–‡å¥å­...\n",
      "åŸå§‹ content: [\n",
      "  {\"event\": \"å°çº¢å¸½èµ°å…¥å¤ªç©ºæ¸¯ä¸»æ§å¤§å…\", \"sentence_number\": 0, \"confidence\": \"high\"},\n",
      "  {\"event\": \"æ—åšå£«é€’ä¸Šè®¸å¯æ–‡ä»¶å¹¶å®å˜±å°çº¢å¸½æ³¨æ„é»‘å®¢è¢­å‡»\", \"sentence_number\": 2, \"confidence\": \"high\"},\n",
      "  {\"event\": \"å°çº¢å¸½ä¸æ—åšå£«ä½å£°äº¤è°ˆ\", \"sentence_number\": 2, \"confidence\": \"high\"},\n",
      "  {\"event\": \"å°çº¢å¸½é©¾é©¶é£èˆ¹ç©¿è¶Šå¤ªç©ºè·ƒè¿é€šé“\", \"sentence_number\": 6, \"confidence\": \"high\"},\n",
      "  {\"event\": \"ç¥–æ¯åœ¨é£èˆ¹å†…ç—…é‡ä¼‘æ¯,å°ç™½è°ƒè¯•åŒ»ç–—è®¾å¤‡\", \"sentence_number\": 7, \"confidence\": \"high\"},\n",
      "  {\"event\": \"å°çº¢å¸½ä¸å°æ™ºåä½œå…³æ³¨å¯¼èˆªä¸é˜²å¾¡ç³»ç»Ÿ\", \"sentence_number\": 8, \"confidence\": \"high\"},\n",
      "  {\"event\": \"æœºæ¢°ç‹¼æ½œä¼åœ¨é£èˆ¹å¤–è¯•å›¾é»‘å…¥é£èˆ¹å±éšœ\", \"sentence_number\": 8, \"confidence\": \"high\"},\n",
      "  {\"event\": \"å°æ™ºå‘å‡ºè­¦æŠ¥,å°çº¢å¸½å¯åŠ¨é˜²å¾¡åè®®å¹¶æ²Ÿé€šåº”å¯¹å±æœº\", \"sentence_number\": 9, \"confidence\": \"high\"},\n",
      "  {\"event\": \"å°çº¢å¸½é©¾é©¶æ‚¬æµ®æ»‘æ¿ç©¿æ¢­æš®è‰²æ£®æ—\", \"sentence_number\": 10, \"confidence\": \"high\"},\n",
      "  {\"event\": \"æœºæ¢°ç‹¼æ‹¦ä½å°çº¢å¸½,å¨èƒè¦æ±‚äº¤å‡ºåŒ»ç–—èŠ¯ç‰‡\", \"sentence_number\": 13, \"confidence\": \"high\"},\n",
      "  {\"event\": \"å°çº¢å¸½å‘¼å«å°æ™ºæ”¯æ´å¹¶ä¸æœºæ¢°ç‹¼å‘¨æ—‹\", \"sentence_number\": 14, \"confidence\": \"high\"},\n",
      "  {\"event\": \"å°çº¢å¸½å°è¯•ç ´è§£æœºæ¢°ç‹¼æ§åˆ¶ä¿¡å·äº‰å–é€ƒè„±æ—¶é—´\", \"sentence_number\": 15, \"confidence\": \"high\"},\n",
      "  {\"event\": \"ç¥–æ¯åœ¨åŒ»ç–—åºŠä¼‘æ¯,å°ç™½æ£€æŸ¥ç”Ÿå‘½ä½“å¾\", \"sentence_number\": 17, \"confidence\": \"high\"},\n",
      "  {\"event\": \"æ™ºèƒ½å±…ä½ç³»ç»Ÿå‘å‡ºè­¦æŠ¥,é—¨é”è‡ªåŠ¨è§£é™¤\", \"sentence_number\": 18, \"confidence\": \"high\"},\n",
      "  {\"event\": \"æœºæ¢°ç‹¼ä¼ªè£…ç»´ä¿®å‘˜é—¯å…¥èˆ±å†…è¯•å›¾é»‘å…¥åŒ»ç–—èŠ¯ç‰‡\", \"sentence_number\": 19, \"confidence\": \"high\"},\n",
      "  {\"event\": \"å°çº¢å¸½æ¥åˆ°å°æ™ºé€šçŸ¥èµ¶å›å±…ä½èˆ±\", \"sentence_number\": 20, \"confidence\": \"high\"},\n",
      "  {\"event\": \"å°çº¢å¸½ä¸æœºæ¢°ç‹¼å±•å¼€æ•°æ®å¯¹æŠ—\", \"sentence_number\": 21, \"confidence\": \"high\"},\n",
      "  {\"event\": \"ç¥–æ¯ååŠ©å°ç™½é‡‡å–é˜²å¾¡æªæ–½\", \"sentence_number\": 22, \"confidence\": \"high\"},\n",
      "  {\"event\": \"æœºæ¢°ç‹¼è¯•å›¾çªƒå–åŒ»ç–—æ•°æ®åè¢«è¿«æ’¤é€€\", \"sentence_number\": 23, \"confidence\": \"high\"},\n",
      "  {\"event\": \"ç¥–æ¯å®‰æ…°å°çº¢å¸½,å±‹å†…æ¢å¤å¹³é™\", \"sentence_number\": 24, \"confidence\": \"high\"},\n",
      "  {\"event\": \"ç¥–æ¯çš„åŒ»ç–—èˆ±è¢«é»‘å®¢åŠ¿åŠ›å…¥ä¾µ\", \"sentence_number\": 25, \"confidence\": \"high\"},\n",
      "  {\"event\": \"æœºæ¢°ç‹¼è¯•å›¾åŠ«æŒåŒ»ç–—ç³»ç»Ÿå¤ºå–åŒ»ç–—èŠ¯ç‰‡\", \"sentence_number\": 26, \"confidence\": \"high\"},\n",
      "  {\"event\": \"å°çº¢å¸½ä¸å°æ™ºåä½œååˆ¶é»‘å®¢æ”»å‡»\", \"sentence_number\": 27, \"confidence\": \"high\"},\n",
      "  {\"event\": \"å°ç™½å®ˆåœ¨ç¥–æ¯èº«ä¾§å‡†å¤‡åº”æ€¥æŠ¤ç†\", \"sentence_number\": 28, \"confidence\": \"high\"},\n",
      "  {\"event\": \"æœºæ¢°ç‹¼ä¸å°æ™ºåœ¨è™šæ‹Ÿç©ºé—´å¯¹æŠ—\", \"sentence_number\": 29, \"confidence\": \"high\"},\n",
      "  {\"event\": \"æ—åšå£«å¸¦å®‰ä¿å°é˜Ÿèµ¶æ¥å¢æ´\", \"sentence_number\": 30, \"confidence\": \"high\"},\n",
      "  {\"event\": \"å°çº¢å¸½åˆ©ç”¨æ™ºèƒ½é˜²å¾¡ä¸AIååŒåå‡»\", \"sentence_number\": 31, \"confidence\": \"high\"},\n",
      "  {\"event\": \"æœºæ¢°ç‹¼è¢«è¿«æ’¤é€€,ç¥–æ¯å®‰ç„¶æ— æ™\", \"sentence_number\": 31, \"confidence\": \"high\"},\n",
      "  {\"event\": \"å°çº¢å¸½é©¾é©¶é£èˆ¹é™è½ç¥–æ¯å±…æ‰€å¤–\", \"sentence_number\": 32, \"confidence\": \"high\"},\n",
      "  {\"event\": \"å°çº¢å¸½å¸¦ç€åŒ»ç–—èŠ¯ç‰‡æ­¥å…¥èˆ±é—¨\", \"sentence_number\": 33, \"confidence\": \"high\"},\n",
      "  {\"event\": \"æœºæ¢°ç‹¼ä¼ªè£…ç»´ä¿®å·¥é—¯å…¥è¯•å›¾çªƒå–èŠ¯ç‰‡\", \"sentence_number\": 34, \"confidence\": \"high\"},\n",
      "  {\"event\": \"å°çº¢å¸½å’Œå°æ™ºè¯†ç ´æœºæ¢°ç‹¼ä¼ªè£…å¹¶ååŒä½œæˆ˜\", \"sentence_number\": 35, \"confidence\": \"high\"},\n",
      "  {\"event\": \"å°ç™½å®ˆæŠ¤ç¥–æ¯å‡†å¤‡åº”æ€¥åŒ»ç–—å¤„ç†\", \"sentence_number\": 36, \"confidence\": \"high\"},\n",
      "  {\"event\": \"å°çº¢å¸½æˆåŠŸå°†èŠ¯ç‰‡æ¤å…¥ç¥–æ¯ä½“å†…\", \"sentence_number\": 37, \"confidence\": \"high\"},\n",
      "  {\"event\": \"æœºæ¢°ç‹¼è¢«å‡»é€€,å±…æ‰€æ¢å¤å¹³é™\", \"sentence_number\": 38, \"confidence\": \"high\"},\n",
      "  {\"event\": \"å°çº¢å¸½è¸å…¥åŒ»ç–—ç«™ä¸ç¥–æ¯ç›¸æ‹¥\", \"sentence_number\": 39, \"confidence\": \"high\"},\n",
      "  {\"event\": \"å°çº¢å¸½å°†åŒ»ç–—èŠ¯ç‰‡é€’äº¤å°ç™½å‡†å¤‡æ¤å…¥\", \"sentence_number\": 40, \"confidence\": \"high\"},\n",
      "  {\"event\": \"æ—åšå£«æ£€æŸ¥å®‰å…¨å¹¶å¯Ÿè§‰å¼‚å¸¸\", \"sentence_number\": 41, \"confidence\": \"high\"},\n",
      "  {\"event\": \"æœºæ¢°ç‹¼æš´éœ²èº«ä»½ä¼å›¾å¤ºå–åŒ»ç–—èŠ¯ç‰‡\", \"sentence_number\": 42, \"confidence\": \"high\"},\n",
      "  {\"event\": \"å°æ™ºå¯åŠ¨å®‰ä¿ç¨‹åºä¸æœºæ¢°ç‹¼å¯¹æŠ—\", \"sentence_number\": 43, \"confidence\": \"high\"},\n",
      "  {\"event\": \"æ—åšå£«ä¸å°çº¢å¸½å°é”åŒ»ç–—ç«™å‡ºå£\", \"sentence_number\": 44, \"confidence\": \"high\"},\n",
      "  {\"event\": \"ç¥–æ¯æ¿€åŠ±å°çº¢å¸½åˆ©ç”¨é»‘å®¢æŠ€èƒ½é€†è½¬å±€åŠ¿\", \"sentence_number\": 45, \"confidence\": \"high\"},\n",
      "  {\"event\": \"å°çº¢å¸½ä¸å°æ™ºåˆåŠ›å‡»é€€æœºæ¢°ç‹¼\", \"sentence_number\": 46, \"confidence\": \"high\"},\n",
      "  {\"event\": \"åŒ»ç–—èŠ¯ç‰‡æˆåŠŸæ¤å…¥ç¥–æ¯ä½“å†…\", \"sentence_number\": 46, \"confidence\": \"high\"}\n",
      "]...\n",
      "  âœ… åŒ¹é…å®Œæˆï¼Œè¿‡æ»¤äº† 0 ä¸ªæ— åŒ¹é…äº‹ä»¶\n",
      "âš ï¸ åŒ¹é…å¤±è´¥ï¼šname 'validate_events_against_source' is not defined\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_events_no_hallucination(story_data, model=\"gpt-4.1\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e83dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
