#!/usr/bin/env python3
"""
å•ç‹¬è¿è¡Œbaselineæ–‡ä»¶çš„è¯­ä¹‰è¿ç»­æ€§åˆ†æ
å¤„ç†baseline_s1.md, baseline_s2.md, baseline_s3.mdä¸‰ä¸ªæ–‡ä»¶
è¾“å‡ºç»“æœåˆ°analysis_testç›®å½•
"""

import os
import sys
import json
from pathlib import Path

def run_semantic_continuity_analysis():
    """è¿è¡Œè¯­ä¹‰è¿ç»­æ€§åˆ†æ"""
    try:
        print("å¼€å§‹æ‰€æœ‰baselineæ–‡ä»¶çš„è¯­ä¹‰è¿ç»­æ€§åˆ†æ...")
        
        # å¯¼å…¥è¯­ä¹‰è¿ç»­æ€§åˆ†æå™¨
        sys.path.append('/Users/haha/Story/src/analysis')
        from hred_coherence_evaluator import HREDSemanticContinuityEvaluator
        
        # å®šä¹‰baselineæ–‡ä»¶
        baseline_files = {
            'baseline_s1': '/Users/haha/Story/baseline_s1.md',
            'baseline_s2': '/Users/haha/Story/baseline_s2.md', 
            'baseline_s3': '/Users/haha/Story/baseline_s3.md'
        }
        
        results = {}
        
        for baseline_name, story_file in baseline_files.items():
            print(f"\n{'='*60}")
            print(f"ğŸ” åˆ†æ {baseline_name}: {story_file}")
            print(f"{'='*60}")
            
            if not os.path.exists(story_file):
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {story_file}")
                continue
                
            # è¯»å–æ•…äº‹æ–‡ä»¶
            with open(story_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # è§£æmarkdownä¸ºç« èŠ‚
            chapters = []
            current_chapter = None
            lines = content.split('\n')
            
            for line in lines:
                if line.startswith('# Chapter '):
                    if current_chapter:
                        chapters.append(current_chapter)
                    current_chapter = {
                        'title': line[2:].strip(),
                        'plot': ''
                    }
                elif current_chapter and line.strip():
                    current_chapter['plot'] += line.strip() + ' '
            
            if current_chapter:
                chapters.append(current_chapter)
            
            # æ¸…ç†plotå­—æ®µ
            for chapter in chapters:
                chapter['plot'] = chapter['plot'].strip()
            
            print(f"è§£æå‡º {len(chapters)} ä¸ªç« èŠ‚")
            
            # åˆ›å»ºè¯­ä¹‰è¿ç»­æ€§åˆ†æå™¨ï¼ˆæ¯æ¬¡é‡æ–°åˆ›å»ºä»¥ç¡®ä¿æ¸…æ´çŠ¶æ€ï¼‰
            print("åˆ›å»ºè¯­ä¹‰è¿ç»­æ€§åˆ†æå™¨...")
            evaluator = HREDSemanticContinuityEvaluator()
            
            # åˆ†æ
            print("å¼€å§‹åˆ†æ...")
            result = evaluator.evaluate_story_semantic_continuity(chapters)
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_dir = f"/Users/haha/Story/data/analysis_test/{baseline_name}_analysis"
            Path(output_dir).mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜ç»“æœ
            output_file = os.path.join(output_dir, 'hred_semantic_continuity_analysis.json')
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            results[baseline_name] = result
            
            print(f"âœ… {baseline_name} åˆ†æå®Œæˆï¼")
            print(f"ğŸ“ ç»“æœä¿å­˜è‡³: {output_file}")
            
            # æ‰“å°å…³é”®æŒ‡æ ‡
            continuity_eval = result.get('HRED_semantic_continuity_evaluation', {})
            if 'average_semantic_continuity' in continuity_eval:
                print(f"ğŸ“Š å¹³å‡è¯­ä¹‰è¿ç»­æ€§: {continuity_eval['average_semantic_continuity']:.4f}")
            if 'total_sentences' in continuity_eval:
                print(f"ğŸ“ åˆ†æå¥å­æ•°: {continuity_eval['total_sentences']}")
            
            print("âš ï¸  æ³¨æ„: æ­¤æŒ‡æ ‡ä»…æµ‹é‡ç›¸é‚»å¥å­è¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œä¸ä»£è¡¨å®Œæ•´æ•…äº‹è¿è´¯æ€§")
        
        print(f"\n{'='*60}")
        print("ğŸ‰ æ‰€æœ‰baselineæ–‡ä»¶åˆ†æå®Œæˆï¼")
        print(f"{'='*60}")
        print("ğŸ“Š ç»“æœæ±‡æ€»:")
        for name, result in results.items():
            continuity_eval = result.get('HRED_semantic_continuity_evaluation', {})
            avg_continuity = continuity_eval.get('average_semantic_continuity', 'N/A')
            sentence_count = continuity_eval.get('total_sentences', 'N/A')
            
            if isinstance(avg_continuity, (int, float)):
                avg_str = f"{avg_continuity:.4f}"
            else:
                avg_str = str(avg_continuity)
            
            print(f"  {name}: è¯­ä¹‰è¿ç»­æ€§={avg_str}, å¥å­æ•°={sentence_count}")
        
        return results
        
    except Exception as e:
        print(f"è¯­ä¹‰è¿ç»­æ€§åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def main():
    print("="*60)
    print("å•ç‹¬è¿è¡Œbaselineè¯­ä¹‰è¿ç»­æ€§åˆ†æ")
    print("="*60)
    
    results = run_semantic_continuity_analysis()
    
    if results:
        print("\nâœ… è¯­ä¹‰è¿ç»­æ€§åˆ†ææˆåŠŸå®Œæˆï¼")
        return True
    else:
        print("\nâŒ è¯­ä¹‰è¿ç»­æ€§åˆ†æå¤±è´¥")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)