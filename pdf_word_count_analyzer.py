#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿè®¡extracted_horror_pdfsæ–‡ä»¶å¤¹ä¸­æ¯ä¸ªPDFæ–‡ä»¶çš„å­—æ•°
ä½¿ç”¨ç±»ä¼¼Wordçš„è®¡æ•°æ–¹æ³•
"""

import os
import re
import json
import statistics
from pathlib import Path
from typing import List, Dict
import PyPDF2

def count_words_like_word(text: str) -> int:
    """
    ä½¿ç”¨ç±»ä¼¼Microsoft Wordçš„è®¡æ•°æ–¹æ³•è®¡ç®—è‹±æ–‡å­—æ•°
    Wordçš„è®¡æ•°æ–¹æ³•ï¼š
    1. å•è¯ç”±ç©ºæ ¼ã€æ ‡ç‚¹ç¬¦å·åˆ†éš”
    2. è¿å­—ç¬¦è¿æ¥çš„è¯ç®—ä½œä¸€ä¸ªè¯
    3. æ•°å­—åºåˆ—ç®—ä½œä¸€ä¸ªè¯
    4. æ ‡ç‚¹ç¬¦å·ä¸è®¡å…¥å­—æ•°
    """
    if not text:
        return 0
    
    # ç§»é™¤å¤šä½™çš„ç©ºç™½è¡Œå’Œç©ºæ ¼
    text = re.sub(r'\n+', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    
    # åˆ†å‰²æˆå•è¯ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å•è¯è¾¹ç•Œ
    # åŒ…æ‹¬å­—æ¯ã€æ•°å­—ã€è¿å­—ç¬¦çš„ç»„åˆ
    words = re.findall(r'\b[a-zA-Z0-9]+(?:-[a-zA-Z0-9]+)*\b', text)
    
    return len(words)

def extract_text_from_pdf(pdf_path: Path) -> str:
    """ä»PDFæ–‡ä»¶ä¸­æå–æ–‡æœ¬"""
    try:
        with open(pdf_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            text = ""
            
            for page_num in range(len(pdf_reader.pages)):
                page = pdf_reader.pages[page_num]
                text += page.extract_text() + "\n"
            
            return text
    except Exception as e:
        print(f"é”™è¯¯ï¼šæ— æ³•è¯»å–PDFæ–‡ä»¶ {pdf_path}: {str(e)}")
        return ""

def analyze_pdf_file(pdf_path: Path) -> Dict:
    """åˆ†æå•ä¸ªPDFæ–‡ä»¶"""
    try:
        # æå–æ–‡æœ¬
        text = extract_text_from_pdf(pdf_path)
        
        if not text:
            return {
                'file_name': pdf_path.name,
                'word_count': 0,
                'char_count': 0,
                'status': 'error: æ— æ³•æå–æ–‡æœ¬'
            }
        
        # è®¡ç®—å­—æ•°
        word_count = count_words_like_word(text)
        char_count = len(text)
        
        return {
            'file_name': pdf_path.name,
            'word_count': word_count,
            'char_count': char_count,
            'status': 'success'
        }
        
    except Exception as e:
        return {
            'file_name': pdf_path.name,
            'word_count': 0,
            'char_count': 0,
            'status': f'error: {str(e)}'
        }

def get_statistics(word_counts: List[int]) -> Dict:
    """è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
    if not word_counts:
        return {}
    
    return {
        'count': len(word_counts),
        'mean': round(statistics.mean(word_counts), 2),
        'median': round(statistics.median(word_counts), 2),
        'mode': statistics.mode(word_counts) if len(set(word_counts)) < len(word_counts) else 'no mode',
        'std_dev': round(statistics.stdev(word_counts), 2) if len(word_counts) > 1 else 0,
        'min': min(word_counts),
        'max': max(word_counts),
        'range': max(word_counts) - min(word_counts),
        'sum': sum(word_counts)
    }

def parse_file_name(file_name: str) -> dict:
    """è§£ææ–‡ä»¶åï¼Œæå–å‚æ•°ä¿¡æ¯"""
    # æ ¼å¼: linear_T0.3_s1.pdf
    name_without_ext = file_name.replace('.pdf', '')
    parts = name_without_ext.split('_')
    
    if len(parts) >= 3:
        return {
            'structure': parts[0],  # linear or nonlinear
            'temperature': parts[1],  # T0.3, T0.7, T0.9
            'seed': parts[2]  # s1, s2, s3
        }
    return {}

def group_by_parameter(results: list) -> dict:
    """æŒ‰ä¸åŒå‚æ•°åˆ†ç»„ç»Ÿè®¡"""
    groups = {
        'by_structure': {},
        'by_temperature': {},
        'by_seed': {}
    }
    
    for result in results:
        if result['status'] != 'success':
            continue
            
        file_info = parse_file_name(result['file_name'])
        if not file_info:
            continue
            
        word_count = result['word_count']
        
        # æŒ‰ç»“æ„åˆ†ç»„
        structure = file_info['structure']
        if structure not in groups['by_structure']:
            groups['by_structure'][structure] = []
        groups['by_structure'][structure].append(word_count)
        
        # æŒ‰æ¸©åº¦åˆ†ç»„
        temp = file_info['temperature']
        if temp not in groups['by_temperature']:
            groups['by_temperature'][temp] = []
        groups['by_temperature'][temp].append(word_count)
        
        # æŒ‰ç§å­åˆ†ç»„
        seed = file_info['seed']
        if seed not in groups['by_seed']:
            groups['by_seed'][seed] = []
        groups['by_seed'][seed].append(word_count)
    
    return groups

def calculate_group_stats(group_data: dict) -> dict:
    """è®¡ç®—åˆ†ç»„ç»Ÿè®¡ä¿¡æ¯"""
    stats = {}
    for key, values in group_data.items():
        if values:
            stats[key] = {
                'count': len(values),
                'mean': round(statistics.mean(values), 2),
                'median': round(statistics.median(values), 2),
                'std_dev': round(statistics.stdev(values), 2) if len(values) > 1 else 0,
                'min': min(values),
                'max': max(values),
                'range': max(values) - min(values)
            }
    return stats

def analyze_folder(folder_path: str, folder_name: str):
    """åˆ†ææŒ‡å®šæ–‡ä»¶å¤¹ä¸­çš„PDFæ–‡ä»¶"""
    pdf_dir = Path(folder_path)
    
    if not pdf_dir.exists():
        print(f"é”™è¯¯ï¼šç›®å½• {pdf_dir} ä¸å­˜åœ¨")
        return
    
    print(f"å¼€å§‹åˆ†æ{folder_name}æ–‡ä»¶å¤¹ä¸­çš„PDFæ–‡ä»¶...")
    print("=" * 60)
    
    # æŸ¥æ‰¾æ‰€æœ‰PDFæ–‡ä»¶
    pdf_files = list(pdf_dir.glob("*.pdf"))
    
    if not pdf_files:
        print("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•PDFæ–‡ä»¶")
        return
    
    print(f"æ‰¾åˆ° {len(pdf_files)} ä¸ªPDFæ–‡ä»¶")
    print()
    
    # åˆ†ææ¯ä¸ªæ–‡ä»¶
    results = []
    word_counts = []
    
    for pdf_file in sorted(pdf_files):
        print(f"æ­£åœ¨åˆ†æ: {pdf_file.name}")
        result = analyze_pdf_file(pdf_file)
        results.append(result)
        
        if result['status'] == 'success':
            word_counts.append(result['word_count'])
            print(f"  å­—æ•°: {result['word_count']:,}")
        else:
            print(f"  é”™è¯¯: {result['status']}")
    
    print()
    print("=" * 60)
    print("ç»Ÿè®¡ç»“æœ:")
    print("=" * 60)
    
    if word_counts:
        stats = get_statistics(word_counts)
        
        print(f"æ–‡ä»¶æ€»æ•°: {stats['count']}")
        print(f"æ€»å­—æ•°: {stats['sum']:,}")
        print(f"å¹³å‡å­—æ•°: {stats['mean']:,}")
        print(f"ä¸­ä½æ•°: {stats['median']:,}")
        print(f"ä¼—æ•°: {stats['mode']}")
        print(f"æ ‡å‡†å·®: {stats['std_dev']:,}")
        print(f"æœ€å°å­—æ•°: {stats['min']:,}")
        print(f"æœ€å¤§å­—æ•°: {stats['max']:,}")
        print(f"å­—æ•°èŒƒå›´: {stats['range']:,}")
        
        print()
        print("ğŸ“ˆ æŒ‰ç»“æ„ç±»å‹åˆ†ç»„ç»Ÿè®¡:")
        print("-" * 40)
        groups = group_by_parameter(results)
        structure_stats = calculate_group_stats(groups['by_structure'])
        for structure, stats in structure_stats.items():
            print(f"{structure.upper():<15} æ–‡ä»¶æ•°: {stats['count']:>2} | å¹³å‡: {stats['mean']:>7,} | æ ‡å‡†å·®: {stats['std_dev']:>7,} | èŒƒå›´: {stats['min']:>5,}-{stats['max']:>5,}")
        
        print()
        print("ğŸŒ¡ï¸ æŒ‰æ¸©åº¦å‚æ•°åˆ†ç»„ç»Ÿè®¡:")
        print("-" * 40)
        temp_stats = calculate_group_stats(groups['by_temperature'])
        for temp, stats in temp_stats.items():
            print(f"{temp:<15} æ–‡ä»¶æ•°: {stats['count']:>2} | å¹³å‡: {stats['mean']:>7,} | æ ‡å‡†å·®: {stats['std_dev']:>7,} | èŒƒå›´: {stats['min']:>5,}-{stats['max']:>5,}")
        
        print()
        print("ğŸ² æŒ‰éšæœºç§å­åˆ†ç»„ç»Ÿè®¡:")
        print("-" * 40)
        seed_stats = calculate_group_stats(groups['by_seed'])
        for seed, stats in seed_stats.items():
            print(f"{seed:<15} æ–‡ä»¶æ•°: {stats['count']:>2} | å¹³å‡: {stats['mean']:>7,} | æ ‡å‡†å·®: {stats['std_dev']:>7,} | èŒƒå›´: {stats['min']:>5,}-{stats['max']:>5,}")
        
        print()
        print("ğŸ“‹ å„æ–‡ä»¶è¯¦ç»†ç»Ÿè®¡:")
        print("-" * 60)
        print(f"{'æ–‡ä»¶å':<30} {'å­—æ•°':>8} {'å­—ç¬¦æ•°':>8}")
        print("-" * 60)
        
        for result in sorted(results, key=lambda x: x['word_count'], reverse=True):
            if result['status'] == 'success':
                print(f"{result['file_name']:<30} {result['word_count']:>8,} {result['char_count']:>8,}")
            else:
                print(f"{result['file_name']:<30} {'ERROR':>8} {'ERROR':>8}")
        
        # ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
        output_data = {
            'summary': stats,
            'file_results': results,
            'group_stats': {
                'by_structure': structure_stats,
                'by_temperature': temp_stats,
                'by_seed': seed_stats
            },
            'analysis_timestamp': str(Path().cwd())
        }
        
        output_file = Path(f"/Users/haha/Story/{folder_name}_pdf_word_count_analysis.json")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        print()
        print(f"è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
    else:
        print("æ²¡æœ‰æˆåŠŸåˆ†æä»»ä½•æ–‡ä»¶")
    
    return results, word_counts

def main():
    """ä¸»å‡½æ•°"""
    folders_to_analyze = [
        ("/Users/haha/Story/extracted_romantic_pdfs", "romantic"),
        ("/Users/haha/Story/Sci-Fi_pdfs", "scifi")
    ]
    
    all_results = {}
    
    for folder_path, folder_name in folders_to_analyze:
        print(f"\n{'='*80}")
        print(f"åˆ†æ {folder_name.upper()} æ–‡ä»¶å¤¹")
        print(f"{'='*80}")
        
        results, word_counts = analyze_folder(folder_path, folder_name)
        all_results[folder_name] = {
            'results': results,
            'word_counts': word_counts
        }
    
    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    print(f"\n{'='*80}")
    print("å¯¹æ¯”åˆ†ææŠ¥å‘Š")
    print(f"{'='*80}")
    
    for folder_name, data in all_results.items():
        if data['word_counts']:
            stats = get_statistics(data['word_counts'])
            print(f"\n{folder_name.upper()} æ–‡ä»¶å¤¹:")
            print(f"  å¹³å‡å­—æ•°: {stats['mean']:,}")
            print(f"  ä¸­ä½æ•°: {stats['median']:,}")
            print(f"  æ–‡ä»¶æ•°: {stats['count']}")
            print(f"  æ€»å­—æ•°: {stats['sum']:,}")
            print(f"  å­—æ•°èŒƒå›´: {stats['min']:,} - {stats['max']:,}")

if __name__ == "__main__":
    main()
