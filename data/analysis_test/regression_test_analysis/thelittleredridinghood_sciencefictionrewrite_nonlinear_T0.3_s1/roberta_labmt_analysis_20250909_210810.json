{
  "metadata": {
    "total_chapters": 7,
    "primary_method": "RoBERTa",
    "validation_method": "LabMT-en-v1",
    "analysis_timestamp": "2025-09-09T21:08:10.468337"
  },
  "chapter_analysis": [
    {
      "chapter_num": 5,
      "title": "Confrontation in the Core",
      "roberta_score": 0.0532,
      "labmt_score": 0.1257,
      "content_length": 6958
    },
    {
      "chapter_num": 1,
      "title": "Red Receives the Transmission",
      "roberta_score": -0.236,
      "labmt_score": 0.1595,
      "content_length": 1512
    },
    {
      "chapter_num": 4,
      "title": "Grandmotherâ€™s Hideout",
      "roberta_score": -0.048,
      "labmt_score": 0.1934,
      "content_length": 6660
    },
    {
      "chapter_num": 2,
      "title": "Checkpoint Confrontation",
      "roberta_score": -0.4394,
      "labmt_score": 0.0905,
      "content_length": 2129
    },
    {
      "chapter_num": 3,
      "title": "The Sabotaged Corridor",
      "roberta_score": -0.5076,
      "labmt_score": 0.1068,
      "content_length": 4866
    },
    {
      "chapter_num": 6,
      "title": "Upload and Escape",
      "roberta_score": 0.0656,
      "labmt_score": 0.2045,
      "content_length": 22946
    },
    {
      "chapter_num": 7,
      "title": "Aftermath and Alliance",
      "roberta_score": 0.7067,
      "labmt_score": 0.2707,
      "content_length": 5373
    }
  ],
  "primary_analysis": {
    "method": "RoBERTa",
    "scores": [
      0.05317707459131877,
      -0.2359905242919922,
      -0.04796274503072103,
      -0.4393619894981384,
      -0.5076406319936116,
      0.06563243865966797,
      0.7067185918490092
    ],
    "reagan_classification": {
      "method": "RoBERTa",
      "best_match": "Oedipus",
      "confidence": 0.6907,
      "all_similarities": {
        "Rags to riches": 0.1916,
        "Tragedy": 0,
        "Man in a hole": 0.3399,
        "Icarus": 0,
        "Cinderella": 0,
        "Oedipus": 0.6907
      },
      "reagan_category": "OE"
    }
  },
  "validation_analysis": {
    "method": "LabMT",
    "scores": [
      0.12573033707865067,
      0.15951219512195114,
      0.1933810572687209,
      0.09051136363636392,
      0.10680803571428621,
      0.20453825857519203,
      0.27066011235954957
    ],
    "reagan_classification": {
      "method": "LabMT",
      "best_match": "Rags to riches",
      "confidence": 0.7634,
      "all_similarities": {
        "Rags to riches": 0.7634,
        "Tragedy": 0.4969,
        "Man in a hole": 0.1522,
        "Icarus": 0,
        "Cinderella": 0,
        "Oedipus": 0.3657
      },
      "reagan_category": "RR"
    }
  },
  "correlation_analysis": {
    "pearson_correlation": {
      "r": 0.8883,
      "p_value": 0.0075,
      "significance": "Significant"
    },
    "spearman_correlation": {
      "r": 0.8571,
      "p_value": 0.0137
    },
    "direction_consistency": 0.6667,
    "consistency_level": "High",
    "interpretation": "RoBERTa and LabMT correlation coefficient is 0.888, belongs to strong correlation"
  },
  "comparison_analysis": {
    "disagreement_points": [
      {
        "chapter": 2,
        "roberta_score": -0.2359905242919922,
        "labmt_score": 0.15951219512195114,
        "difference": 0.3955
      },
      {
        "chapter": 4,
        "roberta_score": -0.4393619894981384,
        "labmt_score": 0.09051136363636392,
        "difference": 0.5299
      },
      {
        "chapter": 5,
        "roberta_score": -0.5076406319936116,
        "labmt_score": 0.10680803571428621,
        "difference": 0.6144
      },
      {
        "chapter": 7,
        "roberta_score": 0.7067185918490092,
        "labmt_score": 0.27066011235954957,
        "difference": 0.4361
      }
    ],
    "method_advantages": {
      "RoBERTa": {
        "strengths": [
          "Deep learning model with better contextual understanding",
          "Suitable for modern text and dialogue",
          "High sensitivity to sci-fi and technical texts"
        ],
        "classification": "Oedipus",
        "confidence": 0.6907
      },
      "LabMT": {
        "strengths": [
          "Fully consistent with Reagan's original method",
          "Based on large-scale human annotation",
          "Suitable for traditional literary analysis"
        ],
        "classification": "Rags to riches",
        "confidence": 0.7634
      }
    },
    "consistency_assessment": {
      "classification_agreement": false,
      "major_disagreements": 4,
      "recommendation": "Two methods differ significantly, recommend detailed analysis of difference causes, may need more in-depth text feature analysis"
    }
  },
  "final_conclusion": "RoBERTa + LabMT Dual-Method Analysis Conclusion:\n\nCorrelation Analysis:\n- Pearson correlation coefficient: r = 0.888 (High)\n- Consistency level: RoBERTa and LabMT correlation coefficient is 0.888, belongs to strong correlation\n\nClassification Results:\n- RoBERTa (primary): Oedipus\n- LabMT (validation): Rags to riches\n\nMethodological Notes:\nThis study uses RoBERTa as the primary analysis method (modern deep learning model),\nwith LabMT for cross-validation (consistent with Reagan et al. 2016).\nThe correlation coefficient is 0.888, showing high consistency between the two methods.\n\nRecommendation: Use RoBERTa results as primary, with LabMT as academic benchmark validation."
}