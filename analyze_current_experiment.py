#!/usr/bin/env python3
"""
åˆ†æå½“å‰å®éªŒçš„å‰§æƒ…æŒ‡æ ‡
åŸºäºç°æœ‰æ•°æ®è¿›è¡Œåˆ†æ
"""

import os
import json
from pathlib import Path

def load_json(path):
    with open(path, 'r', encoding='utf-8') as f:
        return json.load(f)

def analyze_role_state_complexity(role_state_data):
    """åˆ†æè§’è‰²çŠ¶æ€å¤æ‚åº¦"""
    total_states = 0
    role_count = 0
    role_complexity = {}
    
    for chapter_id, roles in role_state_data.items():
        for role_name, states in roles.items():
            if role_name not in role_complexity:
                role_complexity[role_name] = []
            role_complexity[role_name].extend(states)
            total_states += len(states)
            
    role_count = len(role_complexity)
    
    # è®¡ç®—æ¯ä¸ªè§’è‰²çš„çŠ¶æ€ç»Ÿè®¡
    role_stats = {}
    for role_name, all_states in role_complexity.items():
        unique_states = len(set(all_states))
        total_appearances = len(all_states)
        role_stats[role_name] = {
            'unique_states': unique_states,
            'total_appearances': total_appearances,
            'state_diversity': unique_states / total_appearances if total_appearances > 0 else 0
        }
    
    return {
        'total_roles': role_count,
        'total_states': total_states,
        'avg_states_per_role': total_states / role_count if role_count > 0 else 0,
        'role_details': role_stats
    }

def analyze_behavior_trace(behavior_trace_data):
    """åˆ†æè¡Œä¸ºè½¨è¿¹"""
    timeline = behavior_trace_data.get('timeline', [])
    character_arcs = behavior_trace_data.get('character_arcs', {})
    
    return {
        'total_behavior_records': len(timeline),
        'characters_with_behavior': len(character_arcs),
        'avg_behaviors_per_character': len(timeline) / len(character_arcs) if character_arcs else 0,
        'behavior_distribution': {
            char: len(arc) for char, arc in character_arcs.items()
        }
    }

def analyze_story_structure(story_data):
    """åˆ†ææ•…äº‹ç»“æ„"""
    chapter_count = len(story_data)
    total_plot_length = sum(len(ch.get('plot', '')) for ch in story_data)
    avg_chapter_length = total_plot_length / chapter_count if chapter_count > 0 else 0
    
    # åˆ†æå­—ç¬¦ç»„æˆ
    total_chars = sum(len(ch.get('plot', '')) for ch in story_data)
    total_sentences = 0
    
    import re
    for ch in story_data:
        plot = ch.get('plot', '')
        sentences = re.split(r'[.!?]+', plot.strip())
        total_sentences += len([s for s in sentences if s.strip()])
    
    return {
        'chapter_count': chapter_count,
        'total_plot_chars': total_chars,
        'total_sentences': total_sentences,
        'avg_chapter_length': avg_chapter_length,
        'avg_sentence_length': total_chars / total_sentences if total_sentences > 0 else 0
    }

def analyze_dialogue_quality(dialogue_data):
    """åˆ†æå¯¹è¯è´¨é‡"""
    total_dialogues = 0
    total_dialogue_chars = 0
    speakers = set()
    
    for item in dialogue_data:
        if isinstance(item, dict) and 'dialogue' in item:
            dialogues = item['dialogue']
            if isinstance(dialogues, list):
                for dialogue in dialogues:
                    if isinstance(dialogue, dict):
                        total_dialogues += 1
                        content = dialogue.get('dialogue', '')
                        total_dialogue_chars += len(content)
                        speaker = dialogue.get('speaker', '')
                        if speaker:
                            speakers.add(speaker)
    
    return {
        'total_dialogue_count': total_dialogues,
        'unique_speakers': len(speakers),
        'avg_dialogue_length': total_dialogue_chars / total_dialogues if total_dialogues > 0 else 0,
        'speakers_list': list(speakers)
    }

def main():
    """ä¸»åˆ†æå‡½æ•°"""
    experiment_dir = Path("data/output/theuglyduckling_abo_nonlinear_T0.7_s2")
    
    print(f"ğŸ“Š åˆ†æå®éªŒ: {experiment_dir.name}")
    print("=" * 50)
    
    analysis_results = {}
    
    # 1. è§’è‰²çŠ¶æ€åˆ†æ
    role_state_path = experiment_dir / "role_state.json"
    if role_state_path.exists():
        print("ğŸ­ è§’è‰²çŠ¶æ€å¤æ‚åº¦åˆ†æ...")
        role_state_data = load_json(role_state_path)
        role_analysis = analyze_role_state_complexity(role_state_data)
        analysis_results['role_complexity'] = role_analysis
        
        print(f"   æ€»è§’è‰²æ•°: {role_analysis['total_roles']}")
        print(f"   æ€»çŠ¶æ€æ•°: {role_analysis['total_states']}")
        print(f"   å¹³å‡çŠ¶æ€/è§’è‰²: {role_analysis['avg_states_per_role']:.2f}")
    
    # 2. è¡Œä¸ºè½¨è¿¹åˆ†æ  
    behavior_trace_path = experiment_dir / "behavior_trace.json"
    if behavior_trace_path.exists():
        print("\nğŸ¯ è¡Œä¸ºè½¨è¿¹åˆ†æ...")
        behavior_trace_data = load_json(behavior_trace_path)
        behavior_analysis = analyze_behavior_trace(behavior_trace_data)
        analysis_results['behavior_analysis'] = behavior_analysis
        
        print(f"   è¡Œä¸ºè®°å½•æ€»æ•°: {behavior_analysis['total_behavior_records']}")
        print(f"   æœ‰è¡Œä¸ºçš„è§’è‰²: {behavior_analysis['characters_with_behavior']}")
        print(f"   å¹³å‡è¡Œä¸º/è§’è‰²: {behavior_analysis['avg_behaviors_per_character']:.2f}")
    
    # 3. æ•…äº‹ç»“æ„åˆ†æ
    story_path = experiment_dir / "story_updated.json"
    if story_path.exists():
        print("\nğŸ“– æ•…äº‹ç»“æ„åˆ†æ...")
        story_data = load_json(story_path)
        structure_analysis = analyze_story_structure(story_data)
        analysis_results['story_structure'] = structure_analysis
        
        print(f"   ç« èŠ‚æ•°: {structure_analysis['chapter_count']}")
        print(f"   æ€»å­—ç¬¦æ•°: {structure_analysis['total_plot_chars']}")
        print(f"   å¹³å‡ç« èŠ‚é•¿åº¦: {structure_analysis['avg_chapter_length']:.0f}")
        print(f"   å¹³å‡å¥å­é•¿åº¦: {structure_analysis['avg_sentence_length']:.1f}")
    
    # 4. å¯¹è¯è´¨é‡åˆ†æ
    dialogue_path = experiment_dir / "dialogue_updated.json"
    if dialogue_path.exists():
        print("\nğŸ’¬ å¯¹è¯è´¨é‡åˆ†æ...")
        dialogue_data = load_json(dialogue_path)
        dialogue_analysis = analyze_dialogue_quality(dialogue_data)
        analysis_results['dialogue_quality'] = dialogue_analysis
        
        print(f"   å¯¹è¯æ€»æ•°: {dialogue_analysis['total_dialogue_count']}")
        print(f"   è¯´è¯è€…æ•°é‡: {dialogue_analysis['unique_speakers']}")
        print(f"   å¹³å‡å¯¹è¯é•¿åº¦: {dialogue_analysis['avg_dialogue_length']:.1f}")
    
    # 5. ä¿å­˜åˆ†æç»“æœ
    output_path = experiment_dir / "plot_metrics_analysis.json"
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(analysis_results, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… å‰§æƒ…æŒ‡æ ‡åˆ†æå®Œæˆï¼")
    print(f"ğŸ“„ è¯¦ç»†ç»“æœä¿å­˜è‡³: {output_path}")
    
    return analysis_results

if __name__ == "__main__":
    main()
