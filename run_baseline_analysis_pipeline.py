#!/usr/bin/env python3
"""
ä¸€é”®è¿è¡Œå®Œæ•´çš„baselineåˆ†ææµç¨‹
1. è¿è¡Œç»¼åˆåˆ†æ (å¤šæ ·æ€§ã€æµç•…æ€§ã€è¿è´¯æ€§ã€æƒ…æ„Ÿã€ç»“æ„)
2. æ›´æ–°metrics_master_clean.csv
"""

import os
import sys
import time
from datetime import datetime

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.append('/Users/haha/Story')

def run_command_with_output(description, command_func):
    """è¿è¡Œå‘½ä»¤å¹¶æ˜¾ç¤ºè¾“å‡º"""
    print(f"\n{'='*80}")
    print(f"ğŸš€ {description}")
    print(f"{'='*80}")
    print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    start_time = time.time()
    
    try:
        result = command_func()
        elapsed_time = time.time() - start_time
        
        print(f"\nâœ… {description} - å®Œæˆ!")
        print(f"â±ï¸  è€—æ—¶: {elapsed_time:.1f} ç§’")
        return True, result
        
    except Exception as e:
        elapsed_time = time.time() - start_time
        print(f"\nâŒ {description} - å¤±è´¥!")
        print(f"ğŸ’¥ é”™è¯¯: {e}")
        print(f"â±ï¸  è€—æ—¶: {elapsed_time:.1f} ç§’")
        
        # æ‰“å°è¯¦ç»†é”™è¯¯ä¿¡æ¯
        import traceback
        traceback.print_exc()
        
        return False, None

def check_baseline_files():
    """æ£€æŸ¥baselineæ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    baseline_files = {
        'baseline_s1': '/Users/haha/Story/baseline_s1.md',
        'baseline_s2': '/Users/haha/Story/baseline_s2.md', 
        'baseline_s3': '/Users/haha/Story/baseline_s3.md'
    }
    
    print("ğŸ“ æ£€æŸ¥baselineæ–‡ä»¶...")
    missing_files = []
    
    for name, path in baseline_files.items():
        if os.path.exists(path):
            file_size = os.path.getsize(path)
            print(f"   âœ… {name}: {path} ({file_size:,} bytes)")
        else:
            print(f"   âŒ {name}: {path} - æ–‡ä»¶ä¸å­˜åœ¨!")
            missing_files.append((name, path))
    
    if missing_files:
        print(f"\nâŒ å‘ç° {len(missing_files)} ä¸ªæ–‡ä»¶ç¼ºå¤±:")
        for name, path in missing_files:
            print(f"   â€¢ {name}: {path}")
        print("\nè¯·ç¡®ä¿æ‰€æœ‰baselineæ–‡ä»¶éƒ½å­˜åœ¨åå†è¿è¡Œ!")
        return False
    
    print(f"âœ… æ‰€æœ‰ {len(baseline_files)} ä¸ªbaselineæ–‡ä»¶æ£€æŸ¥é€šè¿‡!")
    return True

def run_comprehensive_analysis():
    """è¿è¡Œç»¼åˆåˆ†æ"""
    from comprehensive_baseline_analyzer import ComprehensiveBaselineAnalyzer
    
    analyzer = ComprehensiveBaselineAnalyzer()
    results = analyzer.run_all_analysis()
    return results

def update_metrics_csv():
    """æ›´æ–°metrics CSV"""
    from update_metrics_with_baselines import BaselineMetricsUpdater
    
    updater = BaselineMetricsUpdater()
    df = updater.update_metrics_csv()
    return df

def show_final_summary(analysis_results, csv_df):
    """æ˜¾ç¤ºæœ€ç»ˆæ€»ç»“"""
    print(f"\n{'='*80}")
    print("ğŸ‰ BASELINEåˆ†ææµç¨‹å®Œæˆæ€»ç»“")
    print(f"{'='*80}")
    
    # åˆ†æç»“æœæ€»ç»“
    if analysis_results:
        print(f"\nğŸ“Š åˆ†æç»“æœ:")
        success_count = len(analysis_results)
        total_count = 3
        print(f"   âœ… æˆåŠŸåˆ†æ: {success_count}/{total_count} ä¸ªbaselineæ–‡ä»¶")
        
        for baseline_name, result in analysis_results.items():
            if 'text_features' in result:
                features = result['text_features']
                print(f"   ğŸ“ {baseline_name}:")
                print(f"       - æ€»è¯æ•°: {features.get('total_words', 'N/A'):,}")
                print(f"       - ç« èŠ‚æ•°: {features.get('chapter_count', 'N/A')}")
                print(f"       - å¥å­æ•°: {features.get('total_sentences', 'N/A'):,}")
    
    # CSVæ›´æ–°æ€»ç»“
    if csv_df is not None:
        print(f"\nğŸ“ˆ CSVæ›´æ–°ç»“æœ:")
        baseline_count = len(csv_df[csv_df['is_baseline'] == 1])
        total_count = len(csv_df)
        print(f"   ğŸ“Š æ€»è¡Œæ•°: {total_count}")
        print(f"   ğŸ¯ baselineè¡Œæ•°: {baseline_count}")
        print(f"   ğŸ“ æ–‡ä»¶è·¯å¾„: /Users/haha/Story/metrics_master_clean.csv")
    
    # æä¾›ä¸‹ä¸€æ­¥å»ºè®®
    print(f"\nğŸ” æ¥ä¸‹æ¥å¯ä»¥åšä»€ä¹ˆ:")
    print("   1. æŸ¥çœ‹è¯¦ç»†åˆ†æç»“æœ:")
    print("      ğŸ“‚ /Users/haha/Story/baseline_analysis_results/")
    print("   2. æ£€æŸ¥æ›´æ–°åçš„CSV:")
    print("      ğŸ“Š /Users/haha/Story/metrics_master_clean.csv")
    print("   3. è¿è¡Œè¿›ä¸€æ­¥çš„ç»Ÿè®¡åˆ†ææˆ–å¯è§†åŒ–")
    
    print(f"\nâœ¨ åˆ†æç»´åº¦å®Œæˆæƒ…å†µ:")
    dimensions = [
        "âœ… å¤šæ ·æ€§åˆ†æ (distinct_avg, diversity_group_score)",
        "â­ï¸  æµç•…æ€§åˆ†æ (pseudo_ppl, err_per_100w) - è·³è¿‡ï¼Œä½¿ç”¨GPUå•ç‹¬è¿è¡Œ", 
        "âœ… è¯­ä¹‰è¿ç»­æ€§åˆ†æ (avg_semantic_continuity, semantic_continuity_std)",
        "âœ… æƒ…æ„Ÿåˆ†æ (roberta_avg_score, correlation_coefficient)",
        "âœ… ç»“æ„åˆ†æ (chapter_count, tp_coverage, li_function_diversity)",
        "âœ… åŸºæœ¬ç»Ÿè®¡ (total_words, total_sentences)"
    ]
    
    for dim in dimensions:
        print(f"   {dim}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ BASELINEç»¼åˆåˆ†ææµç¨‹")
    print("=" * 80)
    print("å°†ä¸º3ä¸ªbaselineæ–‡ä»¶ç”Ÿæˆå®Œæ•´çš„metricsæ•°æ®:")
    print("â€¢ baseline_s1.md (baselineå°çº¢å¸½1)")
    print("â€¢ baseline_s2.md (baselineå°çº¢å¸½2)")  
    print("â€¢ baseline_s3.md (baselineå°çº¢å¸½3)")
    print()
    print("åˆ†æç»´åº¦åŒ…æ‹¬:")
    print("â€¢ å¤šæ ·æ€§ (Diversity)")
    print("â€¢ è¯­ä¹‰è¿ç»­æ€§ (Semantic Continuity)")
    print("â€¢ æƒ…æ„Ÿå¼§ (Emotional Arc)")  
    print("â€¢ ç»“æ„å®Œæ•´æ€§ (Structure)")
    print("â€¢ æµç•…æ€§ (Fluency) - âš ï¸  è·³è¿‡ï¼Œç”¨æˆ·å°†ä½¿ç”¨GPUå•ç‹¬è¿è¡Œ")
    print("=" * 80)
    
    # æ£€æŸ¥æ–‡ä»¶
    if not check_baseline_files():
        return False
    
    # è¯¢é—®ç”¨æˆ·ç¡®è®¤
    try:
        confirm = input("\nğŸ¤” ç¡®è®¤å¼€å§‹åˆ†æå—? (y/N): ").strip().lower()
        if confirm not in ['y', 'yes', 'æ˜¯']:
            print("âŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            return False
    except KeyboardInterrupt:
        print("\nâŒ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        return False
    
    print("\nğŸš€ å¼€å§‹æ‰§è¡Œåˆ†ææµç¨‹...")
    
    # æ€»è®¡æ—¶å™¨
    total_start_time = time.time()
    
    analysis_results = None
    csv_df = None
    
    # æ­¥éª¤1: è¿è¡Œç»¼åˆåˆ†æ
    success1, analysis_results = run_command_with_output(
        "æ­¥éª¤1: è¿è¡Œç»¼åˆåˆ†æ (å¤šæ ·æ€§+è¯­ä¹‰è¿ç»­æ€§+æƒ…æ„Ÿ+ç»“æ„ï¼Œè·³è¿‡æµç•…æ€§)",
        run_comprehensive_analysis
    )
    
    if not success1:
        print("âŒ ç»¼åˆåˆ†æå¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ")
        return False
    
    # æ­¥éª¤2: æ›´æ–°CSV
    success2, csv_df = run_command_with_output(
        "æ­¥éª¤2: æ›´æ–°metrics_master_clean.csv",
        update_metrics_csv
    )
    
    if not success2:
        print("âŒ CSVæ›´æ–°å¤±è´¥ï¼Œä½†åˆ†æç»“æœå·²ä¿å­˜")
    
    # è®¡ç®—æ€»æ—¶é—´
    total_time = time.time() - total_start_time
    
    # æ˜¾ç¤ºæœ€ç»ˆæ€»ç»“
    show_final_summary(analysis_results, csv_df)
    
    print(f"\nâ±ï¸  æ€»æ‰§è¡Œæ—¶é—´: {total_time:.1f} ç§’ ({total_time/60:.1f} åˆ†é’Ÿ)")
    print(f"ğŸ“… å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    if success1 and success2:
        print("\nğŸ‰ æ‰€æœ‰æ­¥éª¤æ‰§è¡ŒæˆåŠŸ! âœ¨")
        return True
    elif success1:
        print("\nâš ï¸  åˆ†æå®Œæˆï¼Œä½†CSVæ›´æ–°æœ‰é—®é¢˜")
        return True
    else:
        print("\nâŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯")
        return False

if __name__ == "__main__":
    try:
        success = main()
        exit_code = 0 if success else 1
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\n\nâŒ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nğŸ’¥ ç¨‹åºå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
