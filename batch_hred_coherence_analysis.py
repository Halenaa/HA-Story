"""
æ‰¹é‡HREDè¿è´¯æ€§åˆ†æè„šæœ¬
éå†regression_testæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰Markdownæ–‡ä»¶ï¼Œè¿è¡ŒHREDè¿è´¯æ€§è¯„ä¼°
å°†ç»“æœæ±‡æ€»åˆ°CSVè¡¨æ ¼ä¸­
"""

import os
import json
import pandas as pd
import re
from datetime import datetime
import sys

# æ·»åŠ è·¯å¾„ä»¥ä¾¿å¯¼å…¥åˆ†ææ¨¡å—
sys.path.append('.')

# å¯¼å…¥HREDè¿è´¯æ€§è¯„ä¼°å™¨
try:
    from src.analysis.hred_coherence_evaluator import HREDCoherenceEvaluator
    print("âœ… æˆåŠŸå¯¼å…¥HREDè¿è´¯æ€§è¯„ä¼°å™¨")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿src/analysis/hred_coherence_evaluator.pyå­˜åœ¨")
    sys.exit(1)

def parse_folder_name(folder_name):
    """
    è§£ææ–‡ä»¶å¤¹åç§°ï¼Œæå–å®éªŒå‚æ•°
    ä¾‹ï¼šthelittleredridinghood_sciencefictionrewrite_linear_T0.7_s2
    """
    parts = folder_name.split('_')
    
    # æŸ¥æ‰¾æ¨¡å¼æ ‡è¯†
    mode_part = None
    temp_part = None
    seed_part = None
    
    for part in parts:
        if part in ['linear', 'nonlinear']:
            mode_part = part
        elif part.startswith('T') and '.' in part:
            temp_part = part
        elif part.startswith('s') and part[1:].isdigit():
            seed_part = part
    
    # æ„å»ºç»“æœ
    result = {
        'folder_name': folder_name,
        'topic': 'Little Red Riding Hood',  # ä»æ–‡ä»¶å¤¹åæ¨æ–­
        'style': 'Science Fiction Rewrite',  # ä»æ–‡ä»¶å¤¹åæ¨æ–­
        'mode': mode_part if mode_part else 'unknown',
        'temperature': float(temp_part[1:]) if temp_part else 0.0,
        'seed': int(seed_part[1:]) if seed_part else 0
    }
    
    return result

def parse_markdown_to_story_data(markdown_content):
    """
    å°†Markdownå†…å®¹è§£æä¸ºç±»ä¼¼JSON storyçš„æ ¼å¼
    """
    chapters = []
    
    # æŒ‰ç« èŠ‚åˆ†å‰²
    chapter_sections = re.split(r'\n# ', markdown_content)
    
    # å¤„ç†ç¬¬ä¸€ä¸ªç« èŠ‚ï¼ˆå¯èƒ½æ²¡æœ‰å‰å¯¼æ¢è¡Œç¬¦ï¼‰
    if chapter_sections[0].startswith('# '):
        chapter_sections[0] = chapter_sections[0][2:]  # ç§»é™¤å¼€å¤´çš„'# '
    
    for i, section in enumerate(chapter_sections):
        if not section.strip():
            continue
            
        lines = section.strip().split('\n')
        if not lines:
            continue
            
        # ç¬¬ä¸€è¡Œæ˜¯æ ‡é¢˜
        title = lines[0].strip()
        
        # å…¶ä½™éƒ¨åˆ†æ˜¯å†…å®¹
        content_lines = lines[1:]
        content = '\n'.join(content_lines).strip()
        
        # ç§»é™¤markdownè¯­æ³•æ ‡è®°ï¼ˆç®€å•å¤„ç†ï¼‰
        content = re.sub(r'\*\*([^*]+)\*\*', r'\1', content)  # ç²—ä½“
        content = re.sub(r'\*([^*]+)\*', r'\1', content)      # æ–œä½“  
        content = re.sub(r'`([^`]+)`', r'\1', content)        # ä»£ç 
        content = re.sub(r'---+', '', content)               # åˆ†éš”çº¿
        
        # åˆ›å»ºç±»ä¼¼JSONçš„ç»“æ„
        chapter = {
            'chapter_id': f"Chapter {i+1}",
            'title': title,
            'plot': content
        }
        chapters.append(chapter)
    
    return chapters

def run_batch_hred_analysis(base_dir="/Users/haha/Story/data/output/regression_test"):
    """
    æ‰¹é‡è¿è¡ŒHREDè¿è´¯æ€§åˆ†æ
    """
    print("ğŸš€ å¼€å§‹æ‰¹é‡HREDè¿è´¯æ€§åˆ†æ...")
    print(f"æ‰«æç›®å½•: {base_dir}")
    
    # æ‰«ææ‰€æœ‰æ–‡ä»¶å¤¹
    if not os.path.exists(base_dir):
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {base_dir}")
        return None
    
    folders = [f for f in os.listdir(base_dir) 
              if os.path.isdir(os.path.join(base_dir, f)) and not f.startswith('.')]
    
    print(f"ğŸ“ å‘ç° {len(folders)} ä¸ªå®éªŒæ–‡ä»¶å¤¹")
    
    # å­˜å‚¨æ‰€æœ‰ç»“æœ
    all_results = []
    success_count = 0
    failed_files = []
    
    # åˆå§‹åŒ–HREDè¯„ä¼°å™¨ï¼ˆåªåˆå§‹åŒ–ä¸€æ¬¡ï¼Œæé«˜æ•ˆç‡ï¼‰
    print("ğŸ”„ åˆå§‹åŒ–HREDè¿è´¯æ€§è¯„ä¼°å™¨...")
    try:
        evaluator = HREDCoherenceEvaluator(model_name="all-mpnet-base-v2")
        print("âœ… HREDè¯„ä¼°å™¨åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ HREDè¯„ä¼°å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return None
    
    # éå†æ¯ä¸ªæ–‡ä»¶å¤¹
    for i, folder in enumerate(folders, 1):
        print(f"\n{'='*60}")
        print(f"[{i}/{len(folders)}] å¤„ç†æ–‡ä»¶å¤¹: {folder}")
        
        # è§£ææ–‡ä»¶å¤¹å‚æ•°
        folder_params = parse_folder_name(folder)
        print(f"å‚æ•°: {folder_params['mode']} | T{folder_params['temperature']} | s{folder_params['seed']}")
        
        # æ„å»ºMDæ–‡ä»¶è·¯å¾„
        md_file_path = os.path.join(base_dir, folder, "enhanced_story_dialogue_updated.md")
        
        if not os.path.exists(md_file_path):
            print(f"âš ï¸ MDæ–‡ä»¶ä¸å­˜åœ¨: {md_file_path}")
            failed_files.append({
                'folder': folder,
                'reason': 'MDæ–‡ä»¶ä¸å­˜åœ¨',
                'path': md_file_path
            })
            continue
        
        try:
            # è¯»å–Markdownæ–‡ä»¶
            print("ğŸ“– è¯»å–Markdownæ–‡ä»¶...")
            with open(md_file_path, 'r', encoding='utf-8') as f:
                markdown_content = f.read()
            
            # è§£æä¸ºstoryæ ¼å¼
            print("ğŸ”„ è§£æMarkdownä¸ºæ•…äº‹æ ¼å¼...")
            story_data = parse_markdown_to_story_data(markdown_content)
            
            if not story_data:
                print("âŒ Markdownè§£æå¤±è´¥ï¼Œæ²¡æœ‰æ‰¾åˆ°ç« èŠ‚")
                failed_files.append({
                    'folder': folder,
                    'reason': 'Markdownè§£æå¤±è´¥',
                    'path': md_file_path
                })
                continue
            
            print(f"âœ… è§£æåˆ° {len(story_data)} ä¸ªç« èŠ‚")
            
            # è¿è¡ŒHREDè¿è´¯æ€§åˆ†æ
            print("ğŸ”„ è¿è¡ŒHREDè¿è´¯æ€§åˆ†æ...")
            coherence_result = evaluator.evaluate_story_coherence(story_data, include_details=True)
            
            if 'HREDè¿è´¯æ€§è¯„ä»·' not in coherence_result:
                print("âŒ HREDåˆ†æå¤±è´¥")
                failed_files.append({
                    'folder': folder,
                    'reason': 'HREDåˆ†æè¿”å›æ ¼å¼é”™è¯¯',
                    'path': md_file_path
                })
                continue
            
            # æå–å…³é”®æŒ‡æ ‡
            hred_main = coherence_result['HREDè¿è´¯æ€§è¯„ä»·']
            detailed = coherence_result.get('è¯¦ç»†åˆ†æ', {})
            stats = detailed.get('åŸºæœ¬ç»Ÿè®¡', {})
            
            # æ„å»ºç»“æœè®°å½•
            result_record = {
                # å®éªŒå‚æ•°
                'folder_name': folder,
                'topic': folder_params['topic'],
                'style': folder_params['style'],
                'mode': folder_params['mode'],
                'temperature': folder_params['temperature'],
                'seed': folder_params['seed'],
                
                # HREDè¿è´¯æ€§åˆ†æç»“æœ
                'model_name': hred_main['æ¨¡å‹åç§°'],
                'sentence_count': hred_main['å¥å­æ€»æ•°'],
                'adjacent_pairs': hred_main['ç›¸é‚»å¯¹æ•°'],
                'avg_coherence': hred_main['å¹³å‡è¿è´¯æ€§'],
                
                # è¯¦ç»†ç»Ÿè®¡
                'coherence_std': stats.get('è¿è´¯æ€§æ ‡å‡†å·®', None),
                'max_coherence': stats.get('æœ€é«˜è¿è´¯æ€§', None),
                'min_coherence': stats.get('æœ€ä½è¿è´¯æ€§', None),
                'median_coherence': stats.get('è¿è´¯æ€§ä¸­ä½æ•°', None),
                
                # è¿è´¯æ€§æ–­ç‚¹å’Œé«˜è¿è´¯æ®µè½
                'low_coherence_points': len(detailed.get('è¿è´¯æ€§æ–­ç‚¹', [])),
                'high_coherence_segments': len(detailed.get('é«˜è¿è´¯æ€§æ®µè½', [])),
                
                # æ–‡ä»¶è·¯å¾„
                'source_file': md_file_path,
                
                # åˆ†ææ—¶é—´
                'analysis_timestamp': datetime.now().isoformat()
            }
            
            all_results.append(result_record)
            success_count += 1
            
            print(f"âœ… æˆåŠŸå®Œæˆåˆ†æ")
            print(f"   å¹³å‡è¿è´¯æ€§: {result_record['avg_coherence']:.4f}")
            print(f"   å¥å­æ•°é‡: {result_record['sentence_count']}")
            print(f"   ç›¸é‚»å¯¹æ•°: {result_record['adjacent_pairs']}")
            
        except Exception as e:
            print(f"âŒ åˆ†æå¼‚å¸¸: {str(e)}")
            failed_files.append({
                'folder': folder,
                'reason': f'å¼‚å¸¸: {str(e)}',
                'path': md_file_path
            })
    
    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    print(f"\n{'='*60}")
    print("ğŸ“Š æ‰¹é‡HREDåˆ†æå®Œæˆæ±‡æ€»:")
    print(f"âœ… æˆåŠŸåˆ†æ: {success_count}/{len(folders)} ä¸ªæ–‡ä»¶")
    print(f"âŒ å¤±è´¥æ–‡ä»¶: {len(failed_files)} ä¸ª")
    
    if failed_files:
        print("\nå¤±è´¥æ–‡ä»¶åˆ—è¡¨:")
        for failure in failed_files:
            print(f"  - {failure['folder']}: {failure['reason']}")
    
    if all_results:
        # ä¿å­˜ç»“æœåˆ°CSV
        df = pd.DataFrame(all_results)
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs('output/batch_hred_results', exist_ok=True)
        
        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        csv_filename = f'output/batch_hred_results/batch_hred_coherence_analysis_{timestamp}.csv'
        json_filename = f'output/batch_hred_results/batch_hred_coherence_analysis_{timestamp}.json'
        
        # ä¿å­˜ä¸ºCSV
        df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
        print(f"ğŸ“Š CSVç»“æœå·²ä¿å­˜: {csv_filename}")
        
        # ä¿å­˜ä¸ºJSONï¼ˆåŒ…å«å®Œæ•´æ•°æ®ï¼‰
        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump({
                'metadata': {
                    'analysis_date': datetime.now().isoformat(),
                    'total_experiments': len(folders),
                    'successful_analyses': success_count,
                    'failed_analyses': len(failed_files),
                    'failed_files': failed_files,
                    'hred_model': 'all-mpnet-base-v2'
                },
                'results': all_results
            }, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“„ JSONç»“æœå·²ä¿å­˜: {json_filename}")
        
        # æ˜¾ç¤ºåŸºæœ¬ç»Ÿè®¡
        print(f"\nğŸ“ˆ HREDè¿è´¯æ€§ç»Ÿè®¡:")
        print(f"æ¸©åº¦åˆ†å¸ƒ: {df['temperature'].value_counts().to_dict()}")
        print(f"æ¨¡å¼åˆ†å¸ƒ: {df['mode'].value_counts().to_dict()}")
        print(f"å¹³å‡è¿è´¯æ€§èŒƒå›´: {df['avg_coherence'].min():.4f} - {df['avg_coherence'].max():.4f}")
        print(f"æ•´ä½“å¹³å‡è¿è´¯æ€§: {df['avg_coherence'].mean():.4f}")
        print(f"å¹³å‡å¥å­æ•°é‡: {df['sentence_count'].mean():.1f}")
        
        # æ‰¾å‡ºæœ€è¿è´¯å’Œæœ€ä¸è¿è´¯çš„æ•…äº‹
        best_coherence = df.loc[df['avg_coherence'].idxmax()]
        worst_coherence = df.loc[df['avg_coherence'].idxmin()]
        
        print(f"\nğŸ† æœ€è¿è´¯çš„æ•…äº‹:")
        print(f"   {best_coherence['mode']} T{best_coherence['temperature']} s{best_coherence['seed']}: {best_coherence['avg_coherence']:.4f}")
        
        print(f"ğŸ”» æœ€ä¸è¿è´¯çš„æ•…äº‹:")
        print(f"   {worst_coherence['mode']} T{worst_coherence['temperature']} s{worst_coherence['seed']}: {worst_coherence['avg_coherence']:.4f}")
        
        return {
            'csv_file': csv_filename,
            'json_file': json_filename,
            'dataframe': df,
            'success_count': success_count,
            'failed_count': len(failed_files),
            'failed_files': failed_files
        }
    
    return None

if __name__ == "__main__":
    print("ğŸ¯ æ‰¹é‡HREDè¿è´¯æ€§åˆ†æå·¥å…·")
    print("å°†åˆ†ææ‰€æœ‰regression_testå®éªŒç»“æœçš„Markdownæ–‡ä»¶")
    
    result_summary = run_batch_hred_analysis()
    
    if result_summary:
        print(f"\nğŸ‰ æ‰¹é‡HREDåˆ†æå®Œæˆï¼")
        print(f"ğŸ“Š CSVæ–‡ä»¶: {result_summary['csv_file']}")
        print(f"ğŸ“„ JSONæ–‡ä»¶: {result_summary['json_file']}")
        print(f"âœ… æˆåŠŸ: {result_summary['success_count']} ä¸ª")
        print(f"âŒ å¤±è´¥: {result_summary['failed_count']} ä¸ª")
        
        print(f"\nğŸ’¡ ç»“æœè§£è¯»:")
        print(f"HREDè¿è´¯æ€§åˆ†æ•°èŒƒå›´0-1ï¼Œè¶Šæ¥è¿‘1è¡¨ç¤ºç›¸é‚»å¥å­è¯­ä¹‰è¶Šç›¸ä¼¼")
        print(f"è¿™ä¸ªæŒ‡æ ‡èƒ½å¤Ÿè¡¡é‡æ•…äº‹çš„è¯­ä¹‰æµç•…åº¦å’Œé€»è¾‘è¿è´¯æ€§")
    else:
        print(f"\nâŒ æ‰¹é‡HREDåˆ†ææœªäº§ç”Ÿç»“æœ")
